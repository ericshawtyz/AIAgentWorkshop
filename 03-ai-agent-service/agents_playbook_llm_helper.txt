################################################################################  01-agent-basics\01.1-azure_ai_agents_foundry_sdk_tutorial.ipynb  ################################################################################
# %% [markdown]
# Azure AI Agents - Complete Beginner's Tutorial

🎯 **Welcome to your first Azure AI Agents experience!**

This tutorial will guide you through everything you need to know to get started with Azure AI Agents. We'll cover:

1. **What are Azure AI Agents?** - Understanding the basics
2. **Setup and Prerequisites** - Getting your environment ready
3. **Your First Agent** - Creating and managing agents
4. **Conversations with Threads** - Understanding how conversations work
5. **Advanced Operations** - Streamlined workflows

**No prior experience required!** We'll start from the very beginning and build up your knowledge step by step.

---

# %% [markdown]
## 🤖 What are Azure AI Agents?

Think of Azure AI Agents as your **AI-powered assistants** that can:
- Have conversations with users
- Remember what was discussed (through "threads")
- Perform tasks and use tools
- Maintain context across multiple interactions

### Key Concepts (Don't worry, we'll see these in action!):

- **Agent**: Your AI assistant with specific instructions and capabilities
- **Thread**: A conversation session (like a chat conversation)
- **Message**: Individual messages within a conversation
- **Run**: The process of the agent thinking and responding

Let's dive in! 🚀

# %% [markdown]
## 📋 Prerequisites and Setup

Before we start coding, you'll need:

### 1. Azure AI Foundry Project
- An Azure subscription
- An Azure AI Foundry project with a deployed model

### 2. Environment Variables
You'll need to set these environment variables:
- `PROJECT_ENDPOINT`: Your Azure AI Project endpoint
- `MODEL_DEPLOYMENT_NAME`: The name of your deployed AI model

### 3. Python Packages
We'll install the required packages in the next cell, if you haven't prepared the environment.

### 4. Azure CLI installed and logged in


**Don't worry if this seems overwhelming - we'll guide you through each step!**

# %% [markdown]
![Single Agent](images/single_agent.gif)

# %% [code]
# If you haven't created the environment and installed the requirements, install the required packages
# This might take a minute or two

# !pip install azure-ai-agents azure-identity

# Check if the required packages are installed
import importlib.metadata
for package in ["azure-ai-agents", "azure-identity"]:
    try:
        version = importlib.metadata.version(package)
        print(f"✅ {package} is installed (version {version}).")
    except importlib.metadata.PackageNotFoundError:
        print(f"❌ {package} is NOT installed.")

# %% [code]
# Let's import everything we need and set up our environment
import os
import time
from azure.ai.agents import AgentsClient
from azure.ai.agents.models import (
    AgentThreadCreationOptions, 
    ThreadMessageOptions, 
    ListSortOrder
)
from azure.identity import DefaultAzureCredential

print("📦 All packages imported successfully!")
print("\n🔧 Now let's check your environment variables...")

# Check if environment variables are set

# If you need to set environment variables manually, uncomment and fill in these lines:
# os.environ['PROJECT_ENDPOINT'] = 'https://your-project.cognitiveservices.azure.com/'
# os.environ['MODEL_DEPLOYMENT_NAME'] = 'your-model-deployment-name'

required_vars = ['PROJECT_ENDPOINT', 'MODEL_DEPLOYMENT_NAME']
missing_vars = []

for var in required_vars:
    if var not in os.environ:
        missing_vars.append(var)
    else:
        print(f"✅ {var} is set")

if missing_vars:
    print(f"\n❌ Missing environment variables: {missing_vars}")
    print("\n🔧 Please set them using:")
    for var in missing_vars:
        print(f"   os.environ['{var}'] = 'your_value_here'")
else:
    print("\n🎉 All environment variables are properly configured!")

# %% [code]
# Check if Azure CLI is logged in
import subprocess
import shutil
import json

def is_az_logged_in():
    az_path = shutil.which("az")
    if not az_path:
        print("❌ Azure CLI (az) not found in PATH.")
        return False

    try:
        result = subprocess.run(
            [az_path, "account", "show", "--output", "json"],
            capture_output=True,
            text=True,
            check=True
        )
        account_info = json.loads(result.stdout)
        print(f"✅ Logged in as: {account_info['user']['name']}")
        return True
    except subprocess.CalledProcessError:
        print("❌ Not logged in or error during az call. Please log in using 'az login' from the terminal.")
        return False

_ = is_az_logged_in()

# %% [markdown]
## 🔐 Step 1: Create Your Azure AI Agents Client

The **AgentsClient** is your main tool for interacting with Azure AI Agents. Think of it as your "remote control" for managing agents, conversations, and messages.

**What's happening here:**
- We connect to your Azure AI project using your endpoint
- We use Azure's default authentication (handles the security for us)
- This client will be used for all our agent operations

# %% [code]
# Create our Azure AI Agents client
# This is our main interface to the Azure AI Agents service

def create_agents_client():
    try:
        agents_client = AgentsClient(
            endpoint=os.environ["PROJECT_ENDPOINT"],
            credential=DefaultAzureCredential()
        )
        print("🎉 Successfully connected to Azure AI Agents!")
        print("Your client is ready to create and manage AI agents.")
        return agents_client
        
    except Exception as e:
        print(f"❌ Error creating client: {e}")
        print("Please check your environment variables and Azure credentials.")
        return None
    
# Create the client
agents_client = create_agents_client()    

# %% [markdown]
## 🤖 Step 2: Create Your First AI Agent

Now for the exciting part - creating your first AI agent! 

**An agent is like hiring a specialized assistant.** You give it:
- **Instructions**: What role should it play? (e.g., "You are a helpful coding assistant")
- **Model**: Which AI model should power it?
- **Name**: A friendly name to identify it

Let's create a joke-telling agent to start with something fun! 😄

# %% [code]
# Create the agent
agent = agents_client.create_agent(
    model=os.environ["MODEL_DEPLOYMENT_NAME"],  # The AI model to use
    name="joke-master-3000",                    # A friendly name
    instructions="You are a helpful and funny assistant that loves telling programming jokes and general jokes. Keep responses light and entertaining!"
)

print(f"🎉 Agent created successfully!")
print(f"🆔 Agent ID: {agent.id}")
print(f"📝 Agent Name: {agent.name}")
print(f"🧠 Model: {agent.model}")

# Store the agent ID for later use
agent_id = agent.id

# %% [markdown]
## 💬 Step 3: Understanding Threads (Conversations)

Before we can chat with our agent, we need to understand **threads**.

**A thread is like a conversation session:**
- It keeps track of all messages in a conversation
- The agent remembers what was said earlier
- You can have multiple threads (multiple conversations) with the same agent
- Each thread is independent

**Think of it like this:**
- Thread 1: A conversation about Python programming
- Thread 2: A conversation about cooking recipes
- The agent remembers the context within each thread separately!

Let's create our first thread:

# %% [code]
# Create a new conversation thread
thread = agents_client.threads.create()

print(f"💬 New conversation thread created!")
print(f"🆔 Thread ID: {thread.id}")
print(f"\n📚 This thread will remember our entire conversation with the agent.")

# Store the thread ID for later use
thread_id = thread.id

# %% [markdown]
## ✉️ Step 4: Sending Your First Message

Now let's add a message to our thread! 

**Messages have two key parts:**
- **Role**: Who sent it? (`"user"` for you, `"assistant"` for the agent)
- **Content**: The actual message text

We'll send a message asking for a joke. The message gets added to our thread, but the agent hasn't responded yet - that comes in the next step!

# %% [code]
# Add our first message to the thread
message = agents_client.messages.create(
    thread_id=thread.id,
    role="user",
    content="Hello! Can you tell me a funny programming joke?"
)

print(f"✉️ Message sent successfully!")
print(f"🆔 Message ID: {message.id}")
print(f"👤 Role: {message.role}")
print(f"💭 Content: {message.content[0].text.value}")
print(f"\n📝 The message is now in our thread, waiting for the agent to respond!")

# %% [markdown]
## 🏃‍♂️ Step 5: Creating a Run (Making the Agent Think!)

Now comes the magic! We need to create a **"run"** to make our agent process the conversation and respond.

**What's a run?**
- It's like pressing "send" in a chat app
- The agent reads all messages in the thread
- It thinks about what to say (this can take a few seconds)
- It generates a response and adds it to the thread

**Run statuses you might see:**
- `"queued"`: Waiting in line to be processed
- `"in_progress"`: The agent is thinking
- `"completed"`: Done! The agent has responded
- `"failed"`: Something went wrong

Let's create a run and watch it work:

# %% [code]
# Create a run to make the agent process our message and respond
run = agents_client.runs.create(
    thread_id=thread.id,
    agent_id=agent.id
)

print(f"🏃‍♂️ Run created! Agent is starting to think...")
print(f"🆔 Run ID: {run.id}")
print(f"📊 Initial status: {run.status}")

# Poll the run status until it's complete
print(f"\n⏳ Waiting for the agent to respond...")

while run.status in ["queued", "in_progress", "requires_action"]:
    time.sleep(1)  # Wait 1 second before checking again
    run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)
    print(f"   Status: {run.status}")

print(f"\n🎉 Run completed with status: {run.status}")

if run.status == "failed":
    print(f"❌ Error: {run.last_error}")
else:
    print(f"✅ Success! The agent has responded.")

# %% [markdown]
## 📖 Step 6: Reading the Conversation

Now let's see the complete conversation! We'll retrieve all messages from our thread and display them in order.

**What we'll see:**
1. Our original message (role: "user")
2. The agent's response (role: "assistant")

Let's check out what our joke-telling agent came up with! 🤞

# %% [code]
# Get all messages from the thread, in chronological order
messages = agents_client.messages.list(
    thread_id=thread.id, 
    order=ListSortOrder.ASCENDING  # Oldest first
)

print(f"💬 Complete Conversation:")
print(f"═" * 50) 

for i, msg in enumerate(messages, 1):
    if msg.text_messages:  # Check if the message has text content
        last_text = msg.text_messages[-1]  # Get the text content
        role_emoji = "👤" if msg.role == "user" else "🤖"
        print(f"\n{i}. {role_emoji} {msg.role.upper()}:")
        print(f"   {last_text.text.value}")

print(f"\n" + "═" * 50)
print(f"🎉 Conversation complete! Your first Azure AI Agent interaction was successful!")

# %% [code]
# Clean up: Delete the agent when we're done
# (In real applications, you might want to keep agents around for reuse)
agents_client.delete_agent(agent.id)
print(f"\n🧹 Cleanup: Agent '{agent.name}' has been deleted.")
print(f"💭 The thread and messages still exist and could be used with other agents.")

# %% [markdown]
---

## 🚀 Level Up: Streamlined Approach

Now that you understand the fundamentals, let's learn about **shortcuts**!

Azure AI Agents provides convenience methods that combine multiple steps:

### Method 1: `create_thread_and_run()`
- Creates a thread AND starts a run in one call
- Still requires polling for completion
- Good when you want to start a new conversation quickly

### Method 2: `create_thread_and_process_run()`
- Creates thread, starts run, AND waits for completion
- Returns the final result immediately
- Perfect for simple request-response scenarios

Let's try both approaches:

# %% [code]
# Approach 1: create_thread_and_run() - Create + Run, but we still poll

# Create the client
agents_client = create_agents_client()   


with agents_client:
    # Create a new agent for this example
    agent = agents_client.create_agent(
        model=os.environ["MODEL_DEPLOYMENT_NAME"],
        name="quick-helper",
        instructions="You are a helpful assistant that provides quick, concise answers."
    )
    
    print(f"🤖 Created agent: {agent.name}")
    
    # Create thread and run in one call!
    initial_message = ThreadMessageOptions(
        role="user", 
        content="What's the difference between a list and a tuple in Python?"
    )
    
    run = agents_client.create_thread_and_run(
        agent_id=agent.id,
        thread=AgentThreadCreationOptions(messages=[initial_message])
    )
    
    print(f"⚡ Thread created and run started in one call!")
    print(f"🆔 Thread ID: {run.thread_id}")
    print(f"🆔 Run ID: {run.id}")
    
    # We still need to poll for completion
    print(f"\n⏳ Polling for completion...")
    while run.status in ["queued", "in_progress", "requires_action"]:
        time.sleep(1)
        run = agents_client.runs.get(thread_id=run.thread_id, run_id=run.id)
        print(f"   Status: {run.status}")
    
    print(f"\n✅ Run completed!")
    
    # Get and display the conversation
    messages = agents_client.messages.list(
        thread_id=run.thread_id, 
        order=ListSortOrder.ASCENDING
    )
    
    print(f"\n💬 Quick Conversation:")
    print(f"─" * 40)
    for msg in messages:
        if msg.text_messages:
            last_text = msg.text_messages[-1]
            role_emoji = "👤" if msg.role == "user" else "🤖"
            print(f"\n{role_emoji} {msg.role.upper()}:")
            print(f"{last_text.text.value}")
    
    # Cleanup
    agents_client.delete_agent(agent.id)
    print(f"\n🧹 Agent deleted.")

# %% [code]
# Approach 2: create_thread_and_process_run() - The ultimate shortcut!
# This does EVERYTHING: creates thread, runs, polls, and returns final result

# Create the client
agents_client = create_agents_client()   

with agents_client:
    # Create another agent
    agent = agents_client.create_agent(
        model=os.environ["MODEL_DEPLOYMENT_NAME"],
        name="instant-responder",
        instructions="You are a witty assistant that explains complex topics in simple terms with a touch of humor."
    )
    
    print(f"🤖 Created agent: {agent.name}")
    
    # This ONE call does everything!
    run = agents_client.create_thread_and_process_run(
        agent_id=agent.id,
        thread=AgentThreadCreationOptions(
            messages=[ThreadMessageOptions(
                role="user", 
                content="Explain what an API is, but pretend I'm 5 years old."
            )]
        )
    )
    
    print(f"🚀 Everything completed in one call!")
    print(f"📊 Final status: {run.status}")
    
    if run.status == "failed":
        print(f"❌ Error: {run.last_error}")
    else:
        # Get and display the conversation
        messages = agents_client.messages.list(
            thread_id=run.thread_id, 
            order=ListSortOrder.ASCENDING
        )
        
        print(f"\n💬 Instant Conversation:")
        print(f"─" * 40)
        for msg in messages:
            if msg.text_messages:
                last_text = msg.text_messages[-1]
                role_emoji = "👤" if msg.role == "user" else "🤖"
                print(f"\n{role_emoji} {msg.role.upper()}:")
                print(f"{last_text.text.value}")
    
    # Cleanup
    agents_client.delete_agent(agent.id)
    print(f"\n🧹 Agent deleted.")
    print(f"\n🎯 This approach is perfect for simple question-answer scenarios!")

# %% [markdown]
---

## 🎓 Congratulations! You're Now an Azure AI Agents Developer!

### What You've Learned:

✅ **Core Concepts:**
- What Azure AI Agents are and how they work
- The relationship between agents, threads, messages, and runs

✅ **Practical Skills:**
- Setting up the Azure AI Agents client
- Creating and configuring AI agents
- Managing conversation threads
- Sending messages and processing responses
- Monitoring run status and handling results

✅ **Development Approaches:**
- **Step-by-step**: Full control over each operation
- **Streamlined**: Convenience methods for common patterns
- **Best practices**: Proper resource cleanup and error handling

### 🚀 Next Steps:

Now that you understand the basics, you can explore:

1. **Function Calling**: Let your agents use tools and APIs
2. **File Attachments**: Send images and documents to your agents
3. **Streaming Responses**: Get real-time responses as they're generated
4. **Advanced Threading**: Manage multiple ongoing conversations
5. **Production Deployment**: Scale your agents for real applications

### 💡 Key Takeaways:

- **Agents are reusable**: Create once, use for multiple conversations
- **Threads maintain context**: Each conversation remembers its history
- **Runs process requests**: Always monitor run status for best results
- **Cleanup matters**: Delete agents when you're done to manage costs

**Happy coding with Azure AI Agents!** 🎉

# %% [markdown]
---

## 🔧 Troubleshooting Common Issues

### Authentication Problems
**Error**: `DefaultAzureCredential failed to retrieve a token`
**Solution**: 
- Make sure you're logged into Azure CLI: `az login`
- Or set environment variables: `AZURE_CLIENT_ID`, `AZURE_CLIENT_SECRET`, `AZURE_TENANT_ID`

### Environment Variables
**Error**: `KeyError: 'PROJECT_ENDPOINT'`
**Solution**: Double-check your environment variables are set correctly

### Run Failures
**Error**: Run status shows `"failed"`
**Solution**: Check `run.last_error` for details. Common causes:
- Model deployment issues
- Insufficient quotas
- Network connectivity problems

### Timeout Issues
**Problem**: Runs taking too long
**Solution**: 
- Add timeout logic to your polling loops
- Check your model's performance and quotas
- Consider using shorter prompts for testing

**Need help?** Check the [Azure AI Agents documentation](https://docs.microsoft.com/azure/ai-services/) for more details!

################################################################################  01-agent-basics\01.2-azure_ai_agents_semantic_kernel_tutorial.ipynb  ################################################################################
# %% [markdown]
# Azure AI Agents with Semantic Kernel - Complete Beginner's Tutorial

🎯 **Welcome to your first Azure AI Agents experience using Semantic Kernel!**

This tutorial will guide you through everything you need to know to get started with Azure AI Agents using the Semantic Kernel SDK. We'll cover:

1. **What are Azure AI Agents?** - Understanding the basics
2. **Setup and Prerequisites** - Getting your environment ready
3. **Creating Your First Agent** - Step-by-step agent creation
4. **Simple Conversations** - Basic agent interactions
5. **Adding Plugins** - Extending agent capabilities with custom functions
6. **Advanced Features** - Streaming and complex interactions
7. **Best Practices** - Cleanup and production patterns

**No prior experience required!** We'll start from the very beginning and build up your knowledge step by step.

---

# %% [markdown]
## 🤖 What are Azure AI Agents with Semantic Kernel?

Think of Azure AI Agents with Semantic Kernel as your **AI-powered assistants** that can:
- Have conversations with users
- Remember what was discussed (through "threads")
- Use plugins and tools to extend their capabilities
- Maintain context across multiple interactions
- Leverage the power of Semantic Kernel's orchestration

### Key Concepts (Don't worry, we'll see these in action!):

- **Agent**: Your AI assistant powered by Azure AI and orchestrated by Semantic Kernel
- **Thread**: A conversation session (like a chat conversation)
- **Message**: Individual messages within a conversation
- **Plugin**: Additional capabilities your agent can use (like calling APIs or processing data)
- **Client**: The connection to Azure AI services

### Why Semantic Kernel?
- **Rich Plugin System**: Easily extend agent capabilities
- **Async Support**: Better performance for real-world applications
- **Enterprise Ready**: Built for production scenarios
- **Cross-Platform**: Works across different platforms and languages

Let's dive in! 🚀

# %% [markdown]
## 📋 Prerequisites and Setup

Before we start coding, you'll need:

### 1. Azure AI Services
- An Azure subscription
- An Azure OpenAI resource or Azure AI Services resource
- A deployed model (like GPT-4, GPT-3.5-turbo, etc.)

### 2. Environment Variables or Configuration
You can configure authentication in several ways:
- **Azure Default Credentials** (recommended for Azure-hosted apps)
- **Environment variables** for local development
- **Direct configuration** in code (for learning purposes)

### 3. Python Packages
We'll install the required Semantic Kernel packages in the next cell.

### 4. Azure CLI installed and logged in

**Don't worry if this seems overwhelming - we'll guide you through each step!**

# %% [markdown]
![Single Agent with SK Wrapper](images/single_agent_with_sk.gif)

# %% [code]
# If you haven't created the environment and installed the requirements, install the required packages
# This might take a minute or two

# !pip install azure-ai-agents azure-identity

# Check if the required packages are installed
import importlib.metadata
for package in ["semantic-kernel", "azure-identity"]:
    try:
        version = importlib.metadata.version(package)
        print(f"✅ {package} is installed (version {version}).")
    except importlib.metadata.PackageNotFoundError:
        print(f"❌ {package} is NOT installed.")

# %% [code]
# Let's import everything we need and set up our environment
import asyncio
import os
from typing import Annotated

from azure.identity.aio import DefaultAzureCredential
from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings, AzureAIAgentThread
from semantic_kernel.functions import kernel_function

print("📦 All packages imported successfully!")
print("\n🔧 Environment check:")

# Check if we're in a Jupyter environment for async handling
try:
    # Check if we're in Jupyter
    get_ipython()
    print("✅ Jupyter environment detected - async code will work properly")
except NameError:
    print("ℹ️  Running outside Jupyter - using asyncio.run() for async functions")

print("\n🎉 Setup complete! Ready to create your first agent.")

# %% [code]
# Configuration for Azure AI Services
# You can set these environment variables or modify them directly here for learning

# Option 1: Use environment variables (recommended for production)
# os.environ['AZURE_OPENAI_ENDPOINT'] = 'https://your-resource.openai.azure.com/'
# os.environ['AZURE_OPENAI_API_KEY'] = 'your-api-key-here'  # Only if not using managed identity
# os.environ['AZURE_OPENAI_DEPLOYMENT_NAME'] = 'your-deployment-name'

# Option 2: Direct configuration (for learning and testing)
# We'll use Azure's default settings which work with properly configured Azure resources

print("🔧 Configuration Options:")
print("1. Azure Default Credentials (recommended) - automatically detects Azure authentication")
print("2. Environment variables - set AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT_NAME, AZURE_OPENAI_API_KEY for semantic kernel")
print("3. Environment variables - set PROJECT_ENDPOINT, MODEL_DEPLOYMENT_NAME for Foundry SDK")
print("4. Direct configuration - modify the code above")
print("\n✅ Using Azure Default Credentials for this tutorial")
print("ℹ️  This works automatically when running in Azure or when logged in via Azure CLI")

# %% [code]
required_vars = ['AZURE_OPENAI_ENDPOINT', 'AZURE_OPENAI_API_KEY', 'AZURE_OPENAI_DEPLOYMENT_NAME', 'PROJECT_ENDPOINT', 'MODEL_DEPLOYMENT_NAME']
missing_vars = []

for var in required_vars:
    if var not in os.environ:
        missing_vars.append(var)
    else:
        print(f"✅ {var} is set")

if missing_vars:
    print(f"\n❌ Missing environment variables: {missing_vars}")
    print("\n🔧 Please set them using:")
    for var in missing_vars:
        print(f"   os.environ['{var}'] = 'your_value_here'")
else:
    print("\n🎉 All environment variables are properly configured!")

# %% [code]
# Check if Azure CLI is logged in
import subprocess
import shutil
import json

def is_az_logged_in():
    az_path = shutil.which("az")
    if not az_path:
        print("❌ Azure CLI (az) not found in PATH.")
        return False

    try:
        result = subprocess.run(
            [az_path, "account", "show", "--output", "json"],
            capture_output=True,
            text=True,
            check=True
        )
        account_info = json.loads(result.stdout)
        print(f"✅ Logged in as: {account_info['user']['name']}")
        return True
    except subprocess.CalledProcessError:
        print("❌ Not logged in or error during az call. Please log in using 'az login' from the terminal.")
        return False

_ = is_az_logged_in()

# %% [markdown]
## 🔐 Step 1: Create Your Azure AI Agent Client

With Semantic Kernel, we create an **AzureAIAgent** that handles both the connection to Azure AI services and the agent logic. This is different from the Foundry SDK approach - here we create the agent directly!

**What's happening here:**
- We connect to your Azure AI services using Azure's default authentication
- We create an agent definition on the Azure AI service
- We wrap it in a Semantic Kernel AzureAIAgent for enhanced capabilities
- This agent will be our main interface for conversations

# %% [code]
# Create our Azure AI Agent using Semantic Kernel
# This approach creates the agent directly with all capabilities included

async def create_azure_ai_agent():
    """
    Creates an Azure AI Agent using Semantic Kernel.
    This function demonstrates the modern approach to agent creation.
    """
    try:
        model_deployment_name = os.environ.get("MODEL_DEPLOYMENT_NAME")
        endpoint = os.environ.get("PROJECT_ENDPOINT")

        # Create credentials and client
        client = AzureAIAgent.create_client(credential=DefaultAzureCredential(), endpoint=endpoint)
                
        # Create agent definition on Azure AI service
        agent_definition = await client.agents.create_agent(
            model=model_deployment_name,
            name="joke-master-sk",
            instructions="You are a helpful and funny assistant that loves telling programming jokes and general jokes. Keep responses light and entertaining!"
        )
        
        # Create Semantic Kernel agent wrapper
        agent = AzureAIAgent(
            client=client,
            definition=agent_definition
        )
        
        print("🎉 Azure AI Agent created successfully using Semantic Kernel!")
        print(f"🆔 Agent ID: {agent.id}")
        print(f"📝 Agent Name: {agent.name}")
        print(f"🧠 Model: {agent_definition.model}")
        print("\n✨ This agent is powered by Semantic Kernel's orchestration capabilities!")
        
        return agent, client
                
    except Exception as e:
        print(f"❌ Error creating agent: {e}")
        print("\nTroubleshooting tips:")
        print("1. Make sure you're authenticated with Azure (az login)")
        print("2. Check your Azure OpenAI resource is properly configured")
        print("3. Verify your model deployment is active")
        return None, None

# Create the agent (we'll store the reference for later use)
agent_info = await create_azure_ai_agent()
agent, client = agent_info if agent_info[0] else (None, None)

# %% [markdown]
## 🤖 Step 2: Understanding Agent Architecture

With Semantic Kernel's AzureAIAgent, we have a more integrated approach compared to the Foundry SDK:

**Key Differences:**
- **Integrated Design**: The agent includes both Azure AI service connection and Semantic Kernel orchestration
- **Plugin Support**: Built-in support for Semantic Kernel plugins and functions
- **Async by Default**: Designed for high-performance async operations
- **Enhanced Capabilities**: Automatic function calling, streaming, and advanced orchestration

**Agent Lifecycle:**
1. **Create**: Define the agent on Azure AI service
2. **Wrap**: Create Semantic Kernel wrapper with enhanced capabilities
3. **Use**: Interact through high-level methods like `get_response()` or `invoke()`
4. **Cleanup**: Properly dispose of resources

Let's verify our agent was created successfully:

# %% [code]
# Verify our agent is ready and display its capabilities

if agent and client:
    print("🔍 Agent Verification:")
    print(f"✅ Agent Status: Ready")
    print(f"🆔 Agent ID: {agent.id}")
    print(f"📝 Name: {agent.name}")
    print(f"🎯 Instructions: {agent.instructions[:100]}...")
    
    print("\n🚀 Capabilities:")
    print("✅ Basic conversation")
    print("✅ Context awareness")
    print("✅ Plugin support (we'll add these later)")
    print("✅ Async operations")
    print("✅ Streaming responses")
    
    print("\n🎉 Your agent is ready for conversations!")
else:
    print("❌ Agent creation failed. Please check the previous cell for errors.")
    print("Make sure you have:")
    print("1. Valid Azure credentials")
    print("2. Access to Azure OpenAI or Azure AI services")
    print("3. A deployed model")

# %% [markdown]
## 💬 Step 3: Understanding Threads in Semantic Kernel

Semantic Kernel's approach to threads is elegant and powerful:

**Thread Concepts:**
- **Automatic Creation**: Threads can be created automatically when you first interact
- **Persistent Context**: Each thread maintains conversation history
- **Independent Sessions**: Multiple threads = multiple independent conversations
- **Integrated Management**: Thread lifecycle is managed by the agent

**Two Approaches:**
1. **Explicit Thread Creation**: Create a thread first, then use it
2. **Implicit Thread Creation**: Let the agent create threads automatically

**Think of it like this:**
- Thread 1: A conversation about Python programming
- Thread 2: A conversation about cooking recipes
- The agent remembers the context within each thread separately!

Let's see both approaches:

# %% [code]
# Approach 1: Explicit thread creation
# This gives us full control over the thread lifecycle

if agent and client:
    # Create the thread object with the agent's client
    thread =  AzureAIAgentThread(client=client)
    
    # Create a thread explicitly
    thread_id = await thread.create() 
    
    print("💬 Explicit Thread Creation:")
    print(f"✅ Thread created successfully")
    print(f"🆔 Thread ID: {thread.id if hasattr(thread, 'id') else 'Auto-generated'}")
    print(f"🆔 Thread ID - confirming: {thread_id}")
    print(f"📚 This thread will remember our entire conversation")
    
    print("\n🔄 Alternative Approach:")
    print("You can also let the agent create threads automatically!")
    print("When you call get_response() without a thread, one is created for you.")
    
    # Store thread for later use
    conversation_thread = thread
    
else:
    print("⚠️ Cannot create thread - agent not available")
    conversation_thread = None

# %% [markdown]
## ✉️ Step 4: Your First Conversation with get_response()

Now for the exciting part! Semantic Kernel's `get_response()` method is incredibly powerful:

**What get_response() does:**
- Sends your message to the agent
- Processes the conversation context
- Generates and returns a response
- Maintains conversation history automatically
- Handles all the complexity behind the scenes

**Key Features:**
- **Async by design**: Non-blocking operations for better performance
- **Context aware**: Automatically includes conversation history
- **Error handling**: Built-in retry and error management
- **Thread management**: Can create threads automatically if needed

Let's have our first conversation!

# %% [code]
# Have our first conversation using the modern Semantic Kernel approach

if agent:
    try:
        print("🎬 Starting our first conversation...")
        print("📤 User: Hello! Can you tell me a funny programming joke?")
        
        # Azure AI Agent Threads can be created automatically when you first interact
        thread: AzureAIAgentThread = None

        # The magic happens here - one simple call does everything!
        response = await agent.get_response(
            messages="Hello! Can you tell me a funny programming joke?",
            thread=conversation_thread  # Use our thread, or pass None for auto-creation
        )
        
        print(f"\n📥 {response.name}: {response}")
        
        # Update our thread reference (important for continued conversations)
        conversation_thread = response.thread
        print(f"🆔 Thread ID - confirming: {conversation_thread.id}")
        
        print("\n✨ What just happened:")
        print("1. Your message was sent to the agent")
        print("2. The agent processed it using Azure AI")
        print("3. A response was generated and returned")
        print("4. The conversation context was automatically maintained")
        print("\n🎉 Your first Semantic Kernel conversation is complete!")
        
    except Exception as e:
        print(f"❌ Error during conversation: {e}")
        print("This might be due to:")
        print("- Network connectivity issues")
        print("- Azure service quotas")
        print("- Authentication problems")
        
else:
    print("⚠️ Cannot start conversation - agent not available")

# %% [markdown]
## 🔄 Step 5: Multi-turn Conversations

One of the most powerful features of Semantic Kernel agents is **context retention**. Let's have a multi-turn conversation to see this in action!

**Context Retention Benefits:**
- The agent remembers what you talked about earlier
- You can refer to previous messages naturally
- Conversations feel more natural and flowing
- No need to repeat context in each message

**Best Practices:**
- Always use the same thread for related conversations
- Keep the thread reference updated after each response
- Handle errors gracefully to maintain conversation flow

Let's see this in action with a follow-up question:

# %% [code]
# Continue our conversation with follow-up questions
# This demonstrates context retention and natural conversation flow

if agent and conversation_thread:
    conversation_questions = [
        "That was funny! Can you explain why that joke is humorous?",
        "Do you know any jokes about Python programming specifically?",
        "What's your favorite type of programming humor?"
    ]
    
    print("🔄 Multi-turn Conversation Demo:")
    print("═" * 50)
    
    for i, question in enumerate(conversation_questions, 1):
        try:
            print(f"\n{i}. 👤 User: {question}")
            
            # Each call builds on the previous conversation
            response = await agent.get_response(
                messages=question,
                thread=conversation_thread
            )
            
            print(f"   🤖 {response.name}: {response}")
            
            # Always update the thread reference
            conversation_thread = response.thread
            
        except Exception as e:
            print(f"   ❌ Error: {e}")
            break
    
    print("\n" + "═" * 50)
    print("🎯 Notice how the agent:")
    print("✅ Remembered the previous joke")
    print("✅ Built upon previous responses")
    print("✅ Maintained conversation context")
    print("✅ Provided relevant follow-up responses")
    
else:
    print("⚠️ Cannot continue conversation - missing agent or thread")

# Step 4: Basic Chat Interaction
# The AzureAIAgent handles thread creation automatically when using get_response()

user_message = "What's the weather like today in Seattle?"

print("🤖 Asking the agent:", user_message)
print("\n" + "="*50)

# Use get_response which handles thread creation automatically
async def chat_with_agent():
    response = await agent.get_response(user_message)
    print("🧠 Agent Response:")
    print(response)
    return response

# Execute the chat
response = await chat_with_agent()
print("\n" + "="*50)
print("✅ Basic chat completed successfully!")

# %% [markdown]
## 🚀 Step 6: Advanced Method - Using invoke() for Streaming

Semantic Kernel provides another powerful method: `invoke()`. This method is particularly useful for:

**Advanced Scenarios:**
- **Streaming responses**: Get responses as they're generated (real-time feel)
- **Multiple responses**: Handle cases where agents might generate multiple responses
- **Advanced control**: More granular control over the conversation flow
- **Performance optimization**: Better for high-throughput scenarios

**Key Differences from get_response():**
- `get_response()`: Simple, single response, best for basic conversations
- `invoke()`: Advanced, streaming capable, best for complex scenarios

Let's try the invoke method with streaming-like behavior:

# %% [code]
# Demonstrate the invoke() method for advanced scenarios
# This method provides more control and can handle streaming responses

if agent:
    try:
        print("🚀 Advanced Conversation with invoke():")
        print("─" * 40)
        
        user_message = "Can you write a short poem about coding? Make it creative and fun!"
        print(f"👤 User: {user_message}")
        print("\n🤖 Agent (streaming response):")
        
        # Use invoke() for more advanced control
        # This method can handle multiple responses and streaming
        response_count = 0
        async for response in agent.invoke(
            messages=user_message,
            thread=conversation_thread
        ):
            response_count += 1
            print(f"📝 Response {response_count}: {response}")
            
            # Update thread reference
            conversation_thread = response.thread
        
        print("\n✨ Advanced Features Demonstrated:")
        print(f"✅ Used invoke() method for enhanced control")
        print(f"✅ Handled async iteration (streaming-ready)")
        print(f"✅ Processed {response_count} response(s)")
        print(f"✅ Maintained thread context throughout")
        
    except Exception as e:
        print(f"❌ Error with invoke method: {e}")
        print("This might be due to:")
        print("- Model limitations")
        print("- Network issues")
        print("- Service quotas")
        
else:
    print("⚠️ Cannot demonstrate invoke() - agent not available")

# Step 5: Multi-turn Conversation
# Continue the conversation with follow-up questions

follow_up_questions = [
    "What about the weather in New York?",
    "Can you compare the weather in both cities?",
    "What should I pack for a trip to both cities?"
]

print("🔄 Starting multi-turn conversation...")
print("\n" + "="*50)

async def multi_turn_conversation():
    for i, question in enumerate(follow_up_questions, 1):
        print(f"\n📝 Question {i}: {question}")
        print("-" * 40)
        
        # Each call to get_response maintains conversation context
        response = await agent.get_response(question)
        print(f"🤖 Agent Response: {response}")
        
        # Small delay to make the conversation feel more natural
        import time
        time.sleep(1)

# Execute the multi-turn conversation
await multi_turn_conversation()

print("\n" + "="*50)
print("✅ Multi-turn conversation completed!")

# %% [markdown]
## 🔧 Step 7: Working with Conversation History

The user can iterate through the thread to inspect the message history.

# %% [code]
# Step 6: Working with Conversation History
# The agent automatically maintains conversation context across interactions

print("💭 Exploring conversation history and context...")


# List all messages in the current thread
async for msg in client.agents.messages.list(thread_id=conversation_thread.id):
    for m in msg.content:
        print("\n" + "="*80)
        print(f"🗨️ Message ID: {msg.id}")   
        print(f" - {m.type} message:\n{m.text.value}")
        print(80 * "-", "\n")

# %% [markdown]
## 🔧 Step 8: Adding Plugins to Your Agent

One of the most powerful features of Semantic Kernel is the **plugin system**. Plugins allow your agent to:

**Plugin Capabilities:**
- **Extend functionality**: Add new skills beyond just conversation
- **Call external APIs**: Integrate with web services
- **Process data**: Perform calculations, data manipulation
- **Access tools**: File systems, databases, custom logic

**Plugin Benefits:**
- **Modular design**: Add capabilities without changing core agent logic
- **Reusable**: Same plugins can be used across different agents
- **Automatic function calling**: The agent decides when to use plugins
- **Type safety**: Full Python type support

Let's create a simple plugin and add it to our agent:

# %% [code]
# Create a sample plugin to demonstrate Semantic Kernel's plugin system
# This is one of the key advantages of using Semantic Kernel!

class MathPlugin:
    """A sample plugin that provides mathematical operations."""
    
    @kernel_function(description="Calculate the square of a number")
    def square(
        self, 
        number: Annotated[float, "The number to square"]
    ) -> Annotated[float, "The square of the input number"]:
        """Calculate the square of a number."""
        result = number ** 2
        return result
    
    @kernel_function(description="Calculate the factorial of a positive integer")
    def factorial(
        self, 
        number: Annotated[int, "The positive integer to calculate factorial for"]
    ) -> Annotated[int, "The factorial of the input number"]:
        """Calculate the factorial of a positive integer."""
        if number < 0:
            return "Error: Factorial is not defined for negative numbers"
        if number == 0 or number == 1:
            return 1
        
        result = 1
        for i in range(2, number + 1):
            result *= i
        return result
    
    @kernel_function(description="Check if a number is prime")
    def is_prime(
        self, 
        number: Annotated[int, "The number to check for primality"]
    ) -> Annotated[str, "Whether the number is prime or not"]:
        """Check if a number is prime."""
        if number < 2:
            return f"{number} is not prime"
        
        for i in range(2, int(number ** 0.5) + 1):
            if number % i == 0:
                return f"{number} is not prime (divisible by {i})"
        
        return f"{number} is prime"

print("🔧 Math Plugin Created!")
print("✅ Available functions:")
print("   - square(number): Calculate the square of a number")
print("   - factorial(number): Calculate factorial of a positive integer")
print("   - is_prime(number): Check if a number is prime")
print("\n🎯 Now let's create an agent with this plugin!")

# %% [code]
# Create a new agent with the math plugin
# This demonstrates how to add plugins during agent creation

async def create_agent_with_plugin():
    """Create an agent with the math plugin included."""
    try:
        
        client = AzureAIAgent.create_client(credential=DefaultAzureCredential(), endpoint=os.environ.get("PROJECT_ENDPOINT"))
                
        # Create agent definition
        agent_definition = await client.agents.create_agent(
            model=os.environ.get("MODEL_DEPLOYMENT_NAME"),
            name="math-assistant",
            instructions="You are a helpful math assistant. You can perform calculations and explain mathematical concepts. Use your available functions when users ask for mathematical operations."
        )
        
        # Create agent with plugin
        math_agent = AzureAIAgent(
            client=client,
            definition=agent_definition,
            plugins=[MathPlugin()]  # Add our math plugin!
        )
        
        print("🧮 Math Agent with Plugin Created!")
        print(f"🆔 Agent ID: {math_agent.id}")
        print(f"📝 Agent Name: {math_agent.name}")
        print("🔧 Plugins: MathPlugin (square, factorial, is_prime)")
        
        return math_agent, client
                
    except Exception as e:
        print(f"❌ Error creating agent with plugin: {e}")
        return None, None

# Create the math agent
math_agent_info = await create_agent_with_plugin()
math_agent, math_client = math_agent_info if math_agent_info[0] else (None, None)

# Step 7: Agent Information and Settings
# Explore the agent's configuration and capabilities

print("ℹ️ Agent Information and Settings")
print("\n" + "="*50)

# Display agent information
print("🤖 Agent Details:")
print(f"   • Agent ID: {math_agent.id}")
print(f"   • Agent Name: {math_agent.name}")
print(f"   • Description: {math_agent.definition.instructions}")
print(f"   • Model: {math_agent.definition.model}")

# You can also access the underlying Azure AI client if needed
print(f"\n🔗 Client Information:")
print(f"   • Client Type: {type(math_client).__name__}")
print(f"   • Connected: {math_client is not None}")

print("\n" + "="*50)
print("✅ Agent information displayed successfully!")

# %% [code]
# Test the agent with plugin capabilities
# Watch how the agent automatically uses the math functions!

if math_agent:
    print("🧮 Testing Agent with Math Plugin:")
    print("═" * 50)
    
    math_questions = [
        "What is the square of 12?",
        "Can you calculate the factorial of 5?",
        "Is 17 a prime number?",
        "What's the square of 8 and is that result a prime number?"
    ]
    
    math_thread = None
    
    for i, question in enumerate(math_questions, 1):
        try:
            print(f"\n{i}. 👤 User: {question}")
            
            # The agent will automatically decide whether to use plugins
            response = await math_agent.get_response(
                messages=question,
                thread=math_thread
            )
            
            print(f"   🧮 Math Agent: {response}")
            math_thread = response.thread
            
        except Exception as e:
            print(f"   ❌ Error: {e}")
            break
    
    print("\n" + "═" * 50)
    print("🎯 Plugin Features Demonstrated:")
    print("✅ Automatic function detection and calling")
    print("✅ Type-safe parameter passing")
    print("✅ Intelligent decision making (when to use plugins)")
    print("✅ Seamless integration with conversation flow")
    print("✅ Complex multi-step operations (question 4)")
    
else:
    print("⚠️ Cannot test plugin - math agent not available")

# Step 8: Resource Management and Best Practices
# Proper cleanup and resource management

print("🧹 Resource Management Best Practices")
print("\n" + "="*50)

print("✅ Current session summary:")
print("   • Agent created successfully")
print("   • Multiple conversations completed")
print("   • Context maintained across interactions")
print("   • No memory leaks or resource issues")

print("\n💡 Best Practices for Production:")
print("   • Always use async/await for better performance")
print("   • Handle exceptions gracefully")
print("   • Monitor token usage and costs")
print("   • Implement proper logging")
print("   • Use connection pooling for high-volume scenarios")

print("\n🔧 Resource Cleanup:")
print("   • The agent and client will be cleaned up automatically")
print("   • For production apps, implement proper connection management")

print("\n" + "="*50)
print("✅ Resource management overview completed!")

# %% [markdown]
---

## 🚀 Step 9: Advanced Features - Streaming and Performance

Semantic Kernel provides several advanced features for production scenarios:

### Real-time Streaming
- **Immediate feedback**: Users see responses as they're generated
- **Better UX**: No waiting for complete responses
- **Performance**: Better perceived performance

### Performance Optimizations
- **Async operations**: Non-blocking I/O for better concurrency
- **Connection pooling**: Efficient resource management
- **Context caching**: Faster subsequent requests

### Production Features
- **Error handling**: Robust error recovery
- **Monitoring**: Built-in telemetry and logging
- **Scalability**: Designed for high-throughput scenarios

Let's explore these advanced capabilities:

# %% [code]
# Demonstrate advanced features: Multiple agents working together
# This shows the scalability and flexibility of Semantic Kernel

async def demonstrate_advanced_features():
    """Demonstrate advanced Semantic Kernel features."""
    
    print("🌟 Advanced Features Demonstration:")
    print("─" * 40)
    
    # Simulate multiple concurrent operations
    if agent and math_agent:
        
        print("\n1. 🔄 Concurrent Agent Operations:")
        
        # Create tasks for concurrent execution
        joke_task = agent.get_response(
            messages="Tell me a quick joke about computers",
            thread=None  # New thread for this conversation
        )
        
        math_task = math_agent.get_response(
            messages="What's the square of 15?",
            thread=None  # New thread for this conversation
        )
        
        # Execute both operations concurrently
        try:
            joke_response, math_response = await asyncio.gather(
                joke_task, 
                math_task,
                return_exceptions=True
            )
            
            print(f"🤖 Joke Agent: {joke_response}")
            print(f"🧮 Math Agent: {math_response}")
            print("✅ Both agents responded concurrently!")
            
        except Exception as e:
            print(f"❌ Concurrent operation error: {e}")
        
        print("\n2. 📊 Performance Benefits:")
        print("✅ Non-blocking async operations")
        print("✅ Concurrent agent utilization")
        print("✅ Efficient resource management")
        print("✅ Scalable architecture")
        
    else:
        print("⚠️ Need both agents for advanced demonstration")

# Run the advanced features demo
await demonstrate_advanced_features()

# %% [markdown]
## 🧹 Step 9: Proper Cleanup and Resource Management

**Important**: Always clean up your resources properly!

**Why cleanup matters:**
- **Cost management**: Avoid unnecessary charges
- **Resource limits**: Stay within Azure quotas
- **Best practices**: Professional development habits
- **Performance**: Better system performance

**What to clean up:**
- **Agents**: Delete agent definitions from Azure AI service
- **Threads**: Clean up conversation threads (optional, they're lightweight)
- **Connections**: Properly close client connections

Let's clean up our resources:

# %% [code]
# Proper cleanup of all resources
# This is essential for production applications!

async def cleanup_resources():
    """Clean up all agents and resources properly."""
    
    print("🧹 Starting Resource Cleanup:")
    print("─" * 30)
    
    cleanup_count = 0
    
    # Clean up joke agent
    if agent and client:
        try:
            await client.agents.delete_agent(agent.id)
            print(f"✅ Deleted joke agent: {agent.name}")
            cleanup_count += 1
        except Exception as e:
            print(f"⚠️ Error deleting joke agent: {e}")
    
    # Clean up math agent
    if math_agent and math_client:
        try:
            await math_client.agents.delete_agent(math_agent.id)
            print(f"✅ Deleted math agent: {math_agent.name}")
            cleanup_count += 1
        except Exception as e:
            print(f"⚠️ Error deleting math agent: {e}")
    
    # Clean up threads (optional - they're automatically managed)
    if conversation_thread:
        try:
            await conversation_thread.delete()
            print("✅ Deleted conversation thread")
        except Exception as e:
            print(f"ℹ️ Thread cleanup: {e} (this is usually fine)")
    
    print(f"\n🎯 Cleanup Summary:")
    print(f"✅ {cleanup_count} agents cleaned up")
    print(f"✅ Connections properly closed")
    print(f"✅ Resources freed")
    
    if cleanup_count > 0:
        print("\n💡 All resources cleaned up successfully!")
        print("This prevents unnecessary charges and follows best practices.")
    else:
        print("\nℹ️ No resources to clean up.")

# Perform cleanup
await cleanup_resources()

# %% [markdown]
---

## 🎯 Practice Exercise: Create Your Own Agent with Plugins!

Now it's your turn! Use what you've learned to create a sophisticated agent with custom plugins.

**Your mission:**
1. Create a custom plugin with useful functions
2. Create an agent that uses your plugin
3. Have a conversation that demonstrates the plugin's capabilities
4. Try both `get_response()` and `invoke()` methods

**Plugin Ideas:**
- **Weather Plugin**: Mock weather information for different cities
- **Text Plugin**: Text analysis (word count, character count, etc.)
- **Date Plugin**: Date calculations and formatting
- **Conversion Plugin**: Unit conversions (temperature, distance, etc.)
- **Random Plugin**: Random number generation, dice rolling

**Exercise template is provided below - customize it!**

<details>
<summary>Click for Solution Example</summary>

```python
class WeatherPlugin:
    """A mock weather plugin for demonstration."""
    
    @kernel_function(description="Get weather for a city")
    def get_weather(
        self, 
        city: Annotated[str, "The city name"]
    ) -> Annotated[str, "Weather information"]:
        # Mock weather data
        weather_data = {
            "seattle": "Rainy, 15°C",
            "london": "Cloudy, 12°C", 
            "tokyo": "Sunny, 22°C",
            "new york": "Partly cloudy, 18°C"
        }
        return weather_data.get(city.lower(), f"Weather data not available for {city}")
```

</details>

# %% [code]
# 🎯 YOUR TURN! Create your own plugin and agent

# TODO: Create your custom plugin class here!
class MyCustomPlugin:
    """Your custom plugin - make it interesting!"""
    
    @kernel_function(description="Your custom function description")
    def my_function(
        self, 
        parameter: Annotated[str, "Parameter description"]
    ) -> Annotated[str, "Return value description"]:
        """Your custom function implementation."""
        # TODO: Implement your custom logic here
        return f"Processed: {parameter}"

# TODO: Customize these values!
YOUR_AGENT_NAME = "my-custom-agent"
YOUR_AGENT_INSTRUCTIONS = "You are a helpful assistant with custom capabilities."
YOUR_TEST_QUESTIONS = [
    "Hello! What can you help me with?",
    "Can you use your custom function?"
]

print("🎨 Custom Plugin and Agent Exercise")
print("TODO: Customize the plugin class and test questions above!")
print("\n💡 Tips:")
print("1. Make your plugin functions useful and interesting")
print("2. Use descriptive function and parameter names")
print("3. Test with questions that require your plugin's capabilities")
print("4. Try both get_response() and invoke() methods")

# %% [code]
# Implementation of your custom agent
# This cell will create and test your custom agent with plugin

async def create_and_test_custom_agent():
    """Create and test your custom agent implementation."""
    
    try:
        custom_client = AzureAIAgent.create_client(credential=DefaultAzureCredential(), endpoint=os.environ.get("PROJECT_ENDPOINT"))
                
        # Create your custom agent
        agent_definition = await custom_client.agents.create_agent(
            model=os.environ.get("MODEL_DEPLOYMENT_NAME"),
            name=YOUR_AGENT_NAME,
            instructions=YOUR_AGENT_INSTRUCTIONS
        )
        
        # Create agent with your custom plugin
        custom_agent = AzureAIAgent(
            client=custom_client,
            definition=agent_definition,
            plugins=[MyCustomPlugin()]  # Add your plugin!
        )
        
        print(f"🎨 Created custom agent: {custom_agent.name}")
        print(f"🔧 With plugin: {MyCustomPlugin.__name__}")
        
        # Test the agent with your questions
        print("\n💬 Testing Custom Agent:")
        print("═" * 40)
        
        custom_thread = None
        
        for i, question in enumerate(YOUR_TEST_QUESTIONS, 1):
            print(f"\n{i}. 👤 User: {question}")
            
            # Try get_response() method
            response = await custom_agent.get_response(
                messages=question,
                thread=custom_thread
            )
            
            print(f"   🤖 Agent: {response}")
            custom_thread = response.thread
        
        print("\n" + "═" * 40)
        print("🎉 Custom agent test completed!")
        
        # Cleanup
        await custom_client.agents.delete_agent(custom_agent.id)
        print("🧹 Custom agent cleaned up.")
                
    except Exception as e:
        print(f"❌ Error with custom agent: {e}")
        print("\nTroubleshooting:")
        print("1. Check your plugin implementation")
        print("2. Verify your agent configuration")
        print("3. Ensure Azure credentials are valid")

# Test your custom implementation
await create_and_test_custom_agent()

# Final Cleanup
# Properly close the client connection

print("🧹 Cleaning up resources...")

try:
    # Close the Azure AI client connection
    await client.aclose()
    print("✅ Client connection closed successfully")
except Exception as e:
    print(f"⚠️ Note: {e}")

print("\n🎉 Tutorial completed successfully!")
print("\n" + "="*50)
print("Summary of what we learned:")
print("• How to create an Azure AI Agent with Semantic Kernel")
print("• Basic chat interactions using get_response()")
print("• Multi-turn conversations with automatic context")
print("• Proper resource management and cleanup")
print("• Best practices for production use")
print("\n" + "="*50)

# %% [markdown]
---

## 🎓 Congratulations! You're Now a Semantic Kernel Azure AI Agents Expert!

### What You've Learned:

✅ **Core Concepts:**
- Azure AI Agents with Semantic Kernel architecture
- Advanced thread and conversation management
- Plugin system and function calling
- Async operations and performance optimization

✅ **Practical Skills:**
- Creating agents with the Semantic Kernel SDK
- Building and integrating custom plugins
- Managing complex conversations with context retention
- Using both `get_response()` and `invoke()` methods
- Proper resource management and cleanup

✅ **Advanced Features:**
- **Plugin Development**: Creating reusable agent capabilities
- **Concurrent Operations**: Running multiple agents simultaneously
- **Type Safety**: Using Python type annotations for better development
- **Production Readiness**: Error handling, cleanup, and best practices

### 🚀 Next Steps:

Now that you understand Semantic Kernel Azure AI Agents, explore:

1. **Advanced Plugins**: Integration with external APIs and services
2. **Streaming Responses**: Real-time conversation experiences
3. **Multi-Agent Orchestration**: Coordinating multiple specialized agents
4. **Enterprise Integration**: Authentication, monitoring, and scaling
5. **Custom Function Calling**: Advanced tool usage patterns

### 💡 Key Takeaways:

**Semantic Kernel Advantages:**
- **Plugin Ecosystem**: Rich, reusable functionality extensions
- **Type Safety**: Full Python type support for better development
- **Async First**: Built for high-performance scenarios
- **Enterprise Ready**: Production-grade features and patterns

**Best Practices:**
- Always use async/await for non-blocking operations
- Design plugins to be modular and reusable
- Implement proper error handling and cleanup
- Use type annotations for better code quality

**Happy coding with Semantic Kernel Azure AI Agents!** 🎉

# %% [markdown]
---

## 🔧 Troubleshooting Common Issues

### Authentication Problems
**Error**: `DefaultAzureCredential failed to retrieve a token`
**Solution**: 
- Make sure you're logged into Azure CLI: `az login`
- Or set environment variables: `AZURE_CLIENT_ID`, `AZURE_CLIENT_SECRET`, `AZURE_TENANT_ID`
- For local development: `az login --use-device-code`

### Model Configuration
**Error**: `AzureAIAgentSettings configuration issues`
**Solution**: 
- Verify your Azure OpenAI resource is properly deployed
- Check model deployment name matches your Azure configuration
- Ensure sufficient quota for your model

### Plugin Issues
**Error**: `Plugin functions not being called`
**Solution**: 
- Ensure proper `@kernel_function` decorators
- Use descriptive function descriptions
- Include proper type annotations
- Test plugin functions independently first

### Async/Await Issues
**Error**: `RuntimeError: cannot be called from a running event loop`
**Solution**: 
- Use `await` instead of `asyncio.run()` in Jupyter
- Ensure all agent methods are called with `await`
- Check for proper async context managers

### Performance Issues
**Problem**: Slow responses or timeouts
**Solution**: 
- Check your Azure region and model capacity
- Implement proper error handling with retries
- Monitor Azure service health and quotas
- Use connection pooling for high-throughput scenarios

### Resource Cleanup
**Problem**: Agents not being deleted properly
**Solution**: 
- Always use try/finally blocks for cleanup
- Check Azure portal for orphaned resources
- Implement proper context managers
- Monitor your Azure costs and usage

**Need more help?** 
- [Semantic Kernel Documentation](https://learn.microsoft.com/semantic-kernel/)
- [Azure AI Services Documentation](https://docs.microsoft.com/azure/ai-services/)
- [Azure OpenAI Documentation](https://docs.microsoft.com/azure/ai-services/openai/)

################################################################################  01-agent-basics\01.3-python_with_statement_agents_tutorial.ipynb  ################################################################################
# %% [markdown]
# Python `with` Statement and Azure AI Agents

🎯 **Understanding context management with Azure AI Agents!**

This tutorial will teach you about the Python `with` statement and how it applies to Azure AI Agents:

1. **What is the `with` statement?** - Understanding context managers
2. **Foundry SDK Examples** - Using `with` with `azure.ai.agents`
3. **Semantic Kernel Examples** - Using `with` with `semantic_kernel.agents`
4. **When to use `with` vs when NOT to use it** - Best practices

**Perfect for developers who want to write cleaner, more reliable code!** 🚀

---

# %% [markdown]
## 🧠 What is the Python `with` Statement?

The `with` statement is Python's way of handling **context management**. Think of it as an automatic "setup and cleanup" mechanism.

### 🔄 What happens with `with`:
1. **Enter**: Resources are set up (connections opened, credentials loaded)
2. **Work**: Your code runs inside the `with` block
3. **Exit**: Resources are automatically cleaned up (connections closed, credentials disposed)

### 💡 Key Benefits:
- **Automatic cleanup**: No need to remember to close connections
- **Exception safety**: Cleanup happens even if errors occur
- **Cleaner code**: Less boilerplate, more readable

### 🎯 Perfect for:
- Database connections
- File operations
- API clients (like Azure AI Agents!)
- Any resource that needs cleanup

Let's see this in action! 🚀

# %% [markdown]
## 📋 Setup and Prerequisites

Before we start, make sure you have:

### Environment Variables:
- `PROJECT_ENDPOINT`: Your Azure AI Project endpoint
- `MODEL_DEPLOYMENT_NAME`: Your deployed AI model name

### Required Packages:
We'll install both the Foundry SDK and Semantic Kernel packages.

# %% [code]
# If you haven't created the environment and installed the requirements, install the required packages
# This might take a minute or two

# !pip install azure-ai-agents azure-identity

# Check if the required packages are installed
import importlib.metadata
for package in ["semantic-kernel", "azure-identity", "azure-ai-agents"]:
    try:
        version = importlib.metadata.version(package)
        print(f"✅ {package} is installed (version {version}).")
    except importlib.metadata.PackageNotFoundError:
        print(f"❌ {package} is NOT installed.")
        
print("Now let's explore the 'with' statement with Azure AI Agents!")

# %% [code]
# Import everything we need
import os
import asyncio
from azure.ai.agents import AgentsClient
from azure.ai.agents.models import AgentThreadCreationOptions, ThreadMessageOptions
from azure.identity import DefaultAzureCredential
from azure.identity.aio import DefaultAzureCredential as AsyncDefaultAzureCredential
from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings

print("📦 All packages imported!")

# Set environment variables if needed (uncomment and fill in):
# os.environ['PROJECT_ENDPOINT'] = 'https://your-project.cognitiveservices.azure.com/'
# os.environ['MODEL_DEPLOYMENT_NAME'] = 'your-model-deployment-name'

required_vars = ['AZURE_OPENAI_ENDPOINT', 'AZURE_OPENAI_API_KEY', 'AZURE_OPENAI_DEPLOYMENT_NAME', 'PROJECT_ENDPOINT', 'MODEL_DEPLOYMENT_NAME']
missing_vars = []

for var in required_vars:
    if var not in os.environ:
        missing_vars.append(var)
    else:
        print(f"✅ {var} is set")

if missing_vars:
    print(f"\n❌ Missing environment variables: {missing_vars}")
    print("\n🔧 Please set them using:")
    for var in missing_vars:
        print(f"   os.environ['{var}'] = 'your_value_here'")
else:
    print("\n🎉 All environment variables are properly configured!")

# %% [markdown]
---

## 🔧 Example 1: Foundry SDK - Using `with` Statement

Let's start with the **recommended approach** using the `with` statement with the Foundry SDK.

### ✅ **Why use `with` here?**
- **Automatic credential cleanup**: Azure credentials are properly disposed
- **Connection management**: HTTP connections are closed automatically
- **Exception safety**: Resources cleaned up even if something goes wrong
- **Best practice**: Microsoft recommends this pattern

# %% [code]
# ✅ RECOMMENDED: Using 'with' statement with Foundry SDK

print("🔧 Example 1: Foundry SDK WITH the 'with' statement")
print("═" * 60)

# Creating the agents client 
agents_client = AgentsClient(
    endpoint=os.environ["PROJECT_ENDPOINT"],
    credential=DefaultAzureCredential()
)

# The 'with' statement automatically handles setup and cleanup
with agents_client:
    
    print("🚀 Inside the 'with' block - client is active")
    
    # Create an agent
    agent = agents_client.create_agent(
        model=os.environ["MODEL_DEPLOYMENT_NAME"],
        name="with-statement-demo",
        instructions="You are a helpful assistant that explains Python concepts clearly. Your responses should be very consise and clear."
    )
    
    print(f"🤖 Agent created: {agent.name}")
    
    # Have a quick conversation
    run = agents_client.create_thread_and_process_run(
        agent_id=agent.id,
        thread=AgentThreadCreationOptions(
            messages=[ThreadMessageOptions(
                role="user", 
                content="Explain what a context manager is in one sentence."
            )]
        )
    )
    
    if run.status == "completed":
        messages = agents_client.messages.list(thread_id=run.thread_id)
        for msg in messages:
            if msg.role == "assistant" and msg.text_messages:
                print(f"🤖 Agent response: {msg.text_messages[-1].text.value}")
                break
    
    # Cleanup agent
    agents_client.delete_agent(agent.id)
    print(f"🧹 Agent deleted")

print("✅ Exited 'with' block - client automatically cleaned up!")
print("💡 Credentials disposed, connections closed automatically")
print("\n" + "═" * 60)

# %% [markdown]
## 🚫 Example 2: Foundry SDK - WITHOUT `with` Statement

Now let's see what happens when we **don't** use the `with` statement.

### ⚠️ **Why you might avoid `with`:**
- **Long-lived applications**: When you need the client to persist across multiple functions
- **Shared clients**: When multiple parts of your app use the same client
- **Custom lifecycle management**: When you want full control over when resources are cleaned up

### ❗ **Important**: You're responsible for cleanup!

# %% [code]
# ⚠️ WITHOUT 'with' statement - Manual resource management

print("🔧 Example 2: Foundry SDK WITHOUT the 'with' statement")
print("═" * 60)

# Create client manually (no automatic cleanup)
agents_client = AgentsClient(
    endpoint=os.environ["PROJECT_ENDPOINT"],
    credential=DefaultAzureCredential()
)

print("🚀 Client created manually - we're responsible for cleanup")

try:
    # Create an agent
    agent = agents_client.create_agent(
        model=os.environ["MODEL_DEPLOYMENT_NAME"],
        name="manual-management-demo",
        instructions="You are a helpful assistant. Your responses should be very consise and clear."
    )
    
    print(f"🤖 Agent created: {agent.name}")
    
    # Quick interaction
    run = agents_client.create_thread_and_process_run(
        agent_id=agent.id,
        thread=AgentThreadCreationOptions(
            messages=[ThreadMessageOptions(
                role="user", 
                content="What's the benefit of automatic resource management?"
            )]
        )
    )
    
    if run.status == "completed":
        messages = agents_client.messages.list(thread_id=run.thread_id)
        for msg in messages:
            if msg.role == "assistant" and msg.text_messages:
                print(f"🤖 Agent response: {msg.text_messages[-1].text.value}")
                break
    
    # Manual cleanup
    agents_client.delete_agent(agent.id)
    print(f"🧹 Agent deleted manually")
    
except Exception as e:
    print(f"❌ Error occurred: {e}")
    
finally:
    # IMPORTANT: Manual cleanup of the client
    # In real code, you'd call client.close() or similar
    print("🔧 We should manually close the client here")
    print("💡 This is why 'with' is often better - it's automatic!")

print("\n" + "═" * 60) 

# %% [markdown]
---

## 🔄 Example 3: Semantic Kernel - Async `with` Statement

The Semantic Kernel approach uses **async/await** patterns, which also support the `with` statement through **async context managers**.

### 🌟 **Key differences with Semantic Kernel:**
- **Async pattern**: Uses `async with` instead of just `with`
- **Multiple context managers**: Credentials AND client both use `with`
- **More explicit**: Separate credential and client management

Let's see this in action:

# %% [code]
# ✅ RECOMMENDED: Semantic Kernel with async 'with' statements

async def semantic_kernel_with_example():
    print("🔧 Example 3: Semantic Kernel WITH async 'with' statements")
    print("═" * 60)
    
    # Notice the nested 'async with' statements!
    async with (
        AsyncDefaultAzureCredential() as creds,  # Credential context manager
        AzureAIAgent.create_client(credential=creds, endpoint=os.environ["PROJECT_ENDPOINT"]) as client,  # Client context manager
    ):
        print("🚀 Inside nested 'async with' blocks - both credential and client active")
        
        # Create agent definition
        agent_definition = await client.agents.create_agent(
            model=os.environ["MODEL_DEPLOYMENT_NAME"],
            name="semantic-kernel-demo",
            instructions="You are a helpful assistant that understands async programming. Your responses should be very consise and clear.",
        )
        
        print(f"🤖 Agent definition created: {agent_definition.name}")
        
        # Create Semantic Kernel agent wrapper
        agent = AzureAIAgent(
            client=client,
            definition=agent_definition,
        )
        
        # Have conversation
        response = await agent.get_response(
            messages="What makes async programming powerful?"
        )
        
        print(f"🤖 Agent response: {response}")
        
        # Cleanup
        if response.thread:
            await response.thread.delete()
        await client.agents.delete_agent(agent.id)
        print(f"🧹 Agent and thread cleaned up")
    
    print("✅ Exited 'async with' blocks - everything automatically cleaned up!")
    print("💡 Both credentials AND client properly disposed")
    print("\n" + "═" * 60)

# Run the async example
await semantic_kernel_with_example()

# %% [markdown]
---

## 🔄 Example 4: Semantic Kernel - Without the `with` Statement

⚠️ WITHOUT 'async with' statements - Manual resource management with Semantic Kernel

# %% [code]
print("🔧 Example 4: Semantic Kernel WITHOUT 'async with' statements")
print("═" * 60)

async def semantic_kernel_without_example():
    # Create credential and client manually (no automatic cleanup)
    credential = AsyncDefaultAzureCredential()
    client = AzureAIAgent.create_client(credential=credential, endpoint=os.environ["PROJECT_ENDPOINT"])
    
    print("🚀 Client created manually - we're responsible for cleanup")
    
    try:
        # Create agent definition
        agent_definition = await client.agents.create_agent(
            model=os.environ["MODEL_DEPLOYMENT_NAME"],
            name="sk-manual-management-demo",
            instructions="You are a helpful assistant that explains resource management. Your responses should be very consise and clear.",
        )
        
        print(f"🤖 Agent definition created: {agent_definition.name}")
        
        # Create Semantic Kernel agent wrapper
        agent = AzureAIAgent(
            client=client,
            definition=agent_definition,
        )
        
        # Have conversation
        response = await agent.get_response(
            messages="What are the risks of not cleaning up resources properly?"
        )
        
        print(f"🤖 Agent response: {response}")
        
        # Manual cleanup
        if response.thread:
            await response.thread.delete()
        await client.agents.delete_agent(agent.id)
        print(f"🧹 Agent and thread cleaned up manually")
        
    except Exception as e:
        print(f"❌ Error occurred: {e}")
        
    finally:
        # IMPORTANT: Manual cleanup of the client and credential
        await client.close()
        await credential.close()
        print("🔧 Manually closed client and credential")
        print("💡 This is why 'async with' is often better - it handles this automatically!")

print("Starting manual Semantic Kernel example...")
await semantic_kernel_without_example()
print("✅ Example completed!")
print("\n" + "═" * 60)

# %% [markdown]
---

## 🎯 When to Use `with` vs When NOT to Use It

### ✅ **USE `with` when:**

1. **Short-lived operations**: Single request-response interactions
2. **Simple scripts**: One-off tasks or utilities
3. **Clear boundaries**: When you know exactly when you're done with the client
4. **Exception safety is critical**: When you want guaranteed cleanup
5. **Following best practices**: Microsoft recommends this pattern

```python
# Perfect for 'with'
with AgentsClient(...) as client:
    agent = client.create_agent(...)
    result = client.create_thread_and_process_run(...)
    client.delete_agent(agent.id)
# Automatic cleanup happens here
```

### ⚠️ **AVOID `with` when:**

1. **Long-lived applications**: Web servers, background services
2. **Shared clients**: Multiple functions/classes need the same client
3. **Custom lifecycle**: You need precise control over when cleanup happens
4. **Performance critical**: Creating/destroying clients frequently is expensive
5. **Complex state management**: When client lifetime doesn't match your scope

```python
# Better without 'with' for long-lived apps
class ChatService:
    def __init__(self):
        self.client = AgentsClient(...)  # Lives for app lifetime
        self.agent = self.client.create_agent(...)
    
    def chat(self, message):
        return self.client.create_thread_and_process_run(...)
    
    def shutdown(self):
        self.client.close()  # Manual cleanup when app shuts down
```

# %% [markdown]
## 🏆 Best Practices Summary

### 🎯 **Golden Rules:**

1. **Default to `with`**: Use it unless you have a specific reason not to
2. **Match your pattern**: 
   - Script/utility → Use `with`
   - Long-lived app → Manual management
3. **Handle exceptions**: Always cleanup, even when errors occur
4. **Async awareness**: Use `async with` for async code

### 🔍 **Quick Decision Guide:**

**Ask yourself**: *"Does my client lifetime match this code block?"*
- **Yes** → Use `with` ✅
- **No** → Manual management ⚠️

### 🚀 **Performance Tips:**

- **Reuse clients** when possible (expensive to create)
- **Use connection pooling** for high-throughput scenarios  
- **Monitor resource usage** to catch leaks early

### 💡 **Remember:**

The `with` statement isn't just about cleanup—it's about **writing more reliable, maintainable code**. When in doubt, use `with`! 🎉

# %% [markdown]
---

## 🎓 Congratulations!

You now understand how to use the Python `with` statement effectively with Azure AI Agents!

### ✅ **What You've Learned:**

- **Context managers**: What they are and why they matter
- **Foundry SDK patterns**: Both `with` and manual approaches
- **Semantic Kernel patterns**: Async context management
- **Decision making**: When to use each approach
- **Best practices**: Writing reliable, maintainable code

### 🚀 **Next Steps:**

- Apply these patterns in your own projects
- Experiment with long-lived vs short-lived client scenarios
- Explore advanced context management patterns
- Check out Azure AI Agents function calling and streaming

### 💡 **Key Takeaway:**

**Use `with` by default** for cleaner, safer code. Only manage resources manually when you have a specific architectural need.

**Happy coding with Azure AI Agents!** 🎉✨

################################################################################  01-agent-basics\README.md  ################################################################################
# Agent Basics

This folder covers the fundamentals of Azure AI Agents. Start here if you're new to the platform.

## What's In This Folder

**[01.1 - Azure AI Agents Foundry SDK Tutorial](01.1-azure_ai_agents_foundry_sdk_tutorial.ipynb)**
Your first Azure AI Agent using Microsoft's official SDK. Learn how to create agents, manage conversations, and handle multi-turn discussions.

![Single Agent](images/single_agent.gif)

**[01.2 - Semantic Kernel Tutorial](01.2-azure_ai_agents_semantic_kernel_tutorial.ipynb)**
Build more sophisticated agents using Semantic Kernel's orchestration features. Add plugins, handle async operations, and create reusable components.

![Single Agent with SK Wrapper](images/single_agent_with_sk.gif)

**[01.3 - Python `with` Statement Tutorial](01.3-python_with_statement_agents_tutorial.ipynb)**
Learn proper resource management patterns. This tutorial covers when to use `with` statements and how to write cleaner, more reliable code.

## Learning Path

1. Start with **01.1** to understand the basics
2. Move to **01.2** for more advanced features
3. Complete **01.3** to learn best practices

## Prerequisites

### Azure Resources
- Azure subscription
- Azure AI Foundry project
- Deployed AI model (GPT-4, GPT-3.5-turbo, etc.)

### Environment Setup
- Python 3.8+
- Jupyter Notebook or VS Code
- Azure CLI (optional)

### Environment Variables
Configure your Azure AI services in the `.env` file at the project root:

```bash
# Navigate to the project root and edit the .env file
cd ../../  # Go to azure-ai-agents-playbook root
```

Update the `.env` file with your Azure AI project details:
```properties
# Required for all tutorials
PROJECT_ENDPOINT="https://your-foundry-resource.services.ai.azure.com/api/projects/your-project-name"
MODEL_DEPLOYMENT_NAME="your-model-deployment-name"

# For Semantic Kernel scenarios
AZURE_OPENAI_API_KEY="your-azure-openai-api-key"
AZURE_OPENAI_ENDPOINT="https://your-openai-resource.openai.azure.com/"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME="your-chat-deployment"
AZURE_OPENAI_DEPLOYMENT_NAME="your-deployment-name"
AZURE_OPENAI_API_VERSION="2024-12-01-preview"

# Optional: For advanced scenarios
AZURE_SUBSCRIPTION_ID="your-subscription-id"
```

**Tip**: The `.env` file already exists in the project root with example values - just update it with your details.

### Required Packages
Install the packages you need:

```bash
pip install azure-ai-agents azure-identity semantic-kernel
```

## What You'll Learn

By completing these tutorials, you'll understand:

- How to create and manage Azure AI Agents
- The difference between Foundry SDK and Semantic Kernel approaches
- Conversation management with threads and context
- Proper resource management with Python context managers
- Best practices for agent development

## Next Steps

After finishing the basics, check out:
- [02-agent-custom-functions](../02-agent-custom-functions/) - Add custom capabilities
- [03-orchestrated-agents](../03-orchestrated-agents/) - Coordinate multiple agents

################################################################################  02-agent-custom-functions\02.1-azure_ai_agents_functions_foundry_sdk_tutorial.ipynb  ################################################################################
# %% [markdown]
# Azure AI Agents with Functions - Complete Tutorial

🔧 **Supercharge your Azure AI Agents with Functions!**

This tutorial builds on the basic Azure AI Agents concepts and shows you how to give your agents **superpowers** by letting them use functions!

## What You'll Learn:

1. **Function Basics** - What are functions and why use them?
2. **Simple Functions** - Creating your first agent function
3. **Real-World Examples** - Weather, calculations, and data processing
4. **Advanced Functions** - Multiple parameters and complex logic
5. **Best Practices** - Error handling and function design

**Prerequisites:** You should have completed the basic Azure AI Agents tutorial first!

---

# %% [markdown]
## 🛠️ What are Agent Functions?

Imagine your AI agent as a **smart assistant**, but one that can actually **DO things** beyond just chatting!

### Without Functions:
- Agent can only provide text responses
- Limited to knowledge from training data
- Can't access real-time information
- Can't perform calculations or operations

### With Functions:
- Agent can call external APIs 🌐
- Perform calculations and data processing 🧮
- Access databases and files 📁
- Interact with other services 🔗
- Take actions in the real world! 🚀

### Key Concepts:

- **Function Definition**: You write Python functions with specific signatures
- **Function Registration**: You tell the agent about these functions
- **Function Calling**: The agent decides when and how to use them
- **Function Results**: The agent uses the results to provide better responses

Let's see this in action! ⚡

# %% [markdown]
## 📋 Setup and Prerequisites

Before we start, make sure you have:

1. ✅ Completed the basic Azure AI Agents tutorial
2. ✅ Environment variables set (`PROJECT_ENDPOINT`, `MODEL_DEPLOYMENT_NAME`)
3. ✅ Azure authentication configured

We'll install any additional packages we need and import everything required for function-enabled agents.

# %% [code]
# Install required packages
# !pip install azure-ai-agents azure-identity requests

# Import everything we need
import os
import time
import json
import requests
import random
from datetime import datetime
from typing import Any, Dict
from typing import Any, Callable, Set, Dict, List, Optional

from azure.ai.agents import AgentsClient
from azure.ai.agents.models import (
    FunctionTool,
    ToolSet,
    CodeInterpreterTool,
    RequiredFunctionToolCall,
    SubmitToolOutputsAction,
    ToolOutput,
    ListSortOrder
)
from azure.identity import DefaultAzureCredential

print("📦 All packages imported successfully!")
print("🔧 Ready to create function-enabled agents!")

# Verify environment variables
required_vars = ['PROJECT_ENDPOINT', 'MODEL_DEPLOYMENT_NAME']
for var in required_vars:
    if var in os.environ:
        print(f"✅ {var} is set")
    else:
        print(f"❌ {var} is missing!")

# %% [code]
# Create our Azure AI Agents client
def create_agents_client():
    try:
        agents_client = AgentsClient(
            endpoint=os.environ["PROJECT_ENDPOINT"],
            credential=DefaultAzureCredential()
        )
        print("🎉 Successfully connected to Azure AI Agents!")
        return agents_client
    except Exception as e:
        print(f"❌ Error creating client: {e}")
        return None

# Create the client
agents_client = create_agents_client()

# %% [markdown]
## 🎯 Your First Function: Simple Calculator

Let's start with something simple - a calculator function that your agent can use to perform math operations.

**What we'll do:**
1. Write a Python function that adds two numbers
2. Create a function definition that describes it to the agent
3. Register the function with our agent
4. Test it out!

**The magic:** The agent will automatically decide when to use this function based on user requests!

# %% [code]
# Step 1: Write our Python function
def add_numbers(a: float, b: float) -> float:
    """
    Adds two numbers together.
    
    Args:
        a (float): First number
        b (float): Second number
        
    Returns:
        float: The sum of a and b
    """
    result = a + b
    print(f"🧮 Calculator called: {a} + {b} = {result}")
    return result

# Step 2: Create a FunctionTool with our function
# The FunctionTool automatically handles the function registration
calculator_functions = FunctionTool(functions=[add_numbers])

print("✅ Calculator function ready!")
print(f"📝 Function definitions: {len(calculator_functions.definitions)} tool(s) available")
print(f"📝 Function name: add_numbers")
print(f"📋 Description: Adds two numbers together")

# %% [code]
# Step 4: Create an agent with our function
calculator_agent = agents_client.create_agent(
    model=os.environ["MODEL_DEPLOYMENT_NAME"],
    name="math-genius",
    instructions="You are a helpful math assistant. When users ask for calculations, use the available functions to compute accurate results. Always show your work and explain the calculation.",
    tools=calculator_functions.definitions  # Pass the function definitions
)

print(f"🤖 Created calculator agent: {calculator_agent.name}")
print(f"🛠️ Agent has {len(calculator_agent.tools)} tool(s) available")
print(f"🆔 Agent ID: {calculator_agent.id}")

# %% [markdown]
## 🚀 Testing Our Calculator Agent

Now let's test our function-enabled agent! We'll ask it to do some math and watch it automatically use our function.

**What to expect:**
1. We send a math question
2. The agent recognizes it needs to calculate something
3. The agent calls our `add_numbers` function
4. We provide the function result back to the agent
5. The agent incorporates the result into its response

**Note:** Function calling requires a bit more handling than basic conversations!

# %% [code]
# Function to handle tool calls
def handle_function_call(function_call):
    """
    Handles function calls from the agent.
    """
    function_name = function_call.name
    function_args = json.loads(function_call.arguments)
    
    print(f"🔧 Agent wants to call function: {function_name}")
    print(f"📥 With arguments: {function_args}")
    
    # Route to the appropriate function
    if function_name == "add_numbers":
        result = add_numbers(
            a=function_args.get("a"),
            b=function_args.get("b")
        )
        return str(result)
    else:
        return f"Unknown function: {function_name}"


# Create a thread and send a math question
thread = agents_client.threads.create()

message = agents_client.messages.create(
    thread_id=thread.id,
    role="user",
    content="Hi! Can you help me calculate 125 + 387? Please show me the exact result."
)

print(f"💬 Sent message: {message.content[0].text.value}")

# Create a run
run = agents_client.runs.create(
    thread_id=thread.id,
    agent_id=calculator_agent.id
)

print(f"🏃‍♂️ Started run: {run.id}")

# Poll and handle function calls
while run.status in ["queued", "in_progress", "requires_action"]:
    time.sleep(1)
    run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)
    print(f"📊 Run status: {run.status}")
    
    # Handle function calls
    if run.status == "requires_action":
        print("⚡ Agent needs to call a function!")
        
        tool_calls = run.required_action.submit_tool_outputs.tool_calls
        tool_outputs = []
        
        for tool_call in tool_calls:
            if tool_call.type == "function":
                result = handle_function_call(tool_call.function)
                tool_outputs.append({
                    "tool_call_id": tool_call.id,
                    "output": result
                })
        
        # Submit the function results back to the agent
        run = agents_client.runs.submit_tool_outputs(
            thread_id=thread.id,
            run_id=run.id,
            tool_outputs=tool_outputs
        )
        print("✅ Function results submitted to agent")

print(f"🎉 Run completed with status: {run.status}")

# %% [code]
# Display the conversation
messages = agents_client.messages.list(
    thread_id=thread.id,
    order=ListSortOrder.ASCENDING
)

print(f"\n💬 Complete Conversation:")
print(f"═" * 60)

for i, msg in enumerate(messages, 1):
    if msg.text_messages:
        last_text = msg.text_messages[-1]
        role_emoji = "👤" if msg.role == "user" else "🤖"
        print(f"\n{i}. {role_emoji} {msg.role.upper()}:")
        print(f"   {last_text.text.value}")

print(f"\n" + "═" * 60)
print(f"🎯 Amazing! The agent used our function to provide an accurate calculation!")

# Cleanup
agents_client.delete_agent(calculator_agent.id)
print(f"\n🧹 Calculator agent deleted.")

# %% [markdown]
---

## 🌟 Level Up: Real-World Functions

Now let's create more practical functions that agents can use in real scenarios:

1. **Weather Function** - Get current weather information
2. **Random Generator** - Generate random numbers or choices
3. **Date/Time Function** - Get current date and time information
4. **Text Processing** - Analyze and manipulate text

These examples show how functions can make your agents incredibly powerful!

This time we will use the `ToolSet`, which is a collection of tools that can be used by an synchronize agent.

# %% [code]
# Multiple useful functions for our agent

# 1. Weather function (mock implementation)
def get_weather(city: str) -> str:
    """
    Gets the current weather for a city (mock implementation).
    """
    # In a real implementation, you'd call a weather API
    weather_options = [
        f"Sunny and 72°F in {city}",
        f"Partly cloudy and 68°F in {city}", 
        f"Rainy and 61°F in {city}",
        f"Overcast and 65°F in {city}"
    ]
    weather = random.choice(weather_options)
    print(f"🌤️ Weather check: {weather}")
    return weather

# 2. Random number generator
def generate_random_number(min_val: int, max_val: int) -> int:
    """
    Generates a random number between min and max values.
    """
    result = random.randint(min_val, max_val)
    print(f"🎲 Generated random number: {result} (between {min_val} and {max_val})")
    return result

# 3. Current date/time function
def get_current_datetime() -> str:
    """
    Gets the current date and time.
    """
    now = datetime.now()
    formatted_time = now.strftime("%Y-%m-%d %H:%M:%S")
    print(f"🕐 Current time: {formatted_time}")
    return formatted_time

# 4. Text analysis function
def analyze_text(text: str) -> Dict[str, Any]:
    """
    Analyzes text and returns statistics.
    """
    words = text.split()
    analysis = {
        "character_count": len(text),
        "word_count": len(words),
        "sentence_count": text.count('.') + text.count('!') + text.count('?'),
        "average_word_length": round(sum(len(word) for word in words) / len(words), 2) if words else 0
    }
    print(f"📊 Text analysis complete: {analysis}")
    return analysis

print("✅ All utility functions defined!")

# %% [code]
# Create function definitions for the agent
user_functions: Set[Callable[..., Any]] = {
    get_weather,
    generate_random_number,
    get_current_datetime,
    analyze_text
}

# Create tool definitions
toolset = ToolSet()

toolset.add(FunctionTool(functions=user_functions))

# Create a list of tools
for i, tool in enumerate(toolset.definitions, 1):
    print(f"  {i}. {tool.function.name} - {tool.function.description}")

# %% [code]
# Create a super-powered agent with multiple functions
super_agent = agents_client.create_agent(
    model=os.environ["MODEL_DEPLOYMENT_NAME"],
    name="super-assistant",
    instructions="""You are a versatile AI assistant with access to multiple tools. You can:
    - Get weather information for any city
    - Generate random numbers
    - Provide current date and time
    - Analyze text statistics
    
    Always use the appropriate tools when users request these capabilities. 
    Be helpful, accurate, and explain what you're doing when you use functions.""",
    toolset=toolset,
)

print(f"🚀 Created super agent: {super_agent.name}")
print(f"🛠️ Agent has {len(super_agent.tools)} tools available:")
for i, tool in enumerate(super_agent.tools, 1):
    print(f"  {i}. {tool.function.name}")

# %% [code]
# Enhanced function handler for multiple functions
def handle_multi_function_call(function_call):
    """
    Handles multiple types of function calls from the agent.
    """
    function_name = function_call.name
    function_args = json.loads(function_call.arguments)
    
    print(f"🔧 Agent calling: {function_name}")
    print(f"📥 Arguments: {function_args}")
    
    try:
        if function_name == "get_weather":
            result = get_weather(city=function_args.get("city"))
            return result
            
        elif function_name == "generate_random_number":
            result = generate_random_number(
                min_val=function_args.get("min_val"),
                max_val=function_args.get("max_val")
            )
            return str(result)
            
        elif function_name == "get_current_datetime":
            result = get_current_datetime()
            return result
            
        elif function_name == "analyze_text":
            result = analyze_text(text=function_args.get("text"))
            return json.dumps(result)
            
        else:
            return f"Unknown function: {function_name}"
            
    except Exception as e:
        print(f"❌ Error executing function {function_name}: {e}")
        return f"Error: {str(e)}"

print("✅ Multi-function handler ready!")

# %% [code]
# Test the super agent with multiple function calls

# Create a new conversation
thread = agents_client.threads.create()

# Send a complex request that might use multiple functions
complex_message = agents_client.messages.create(
    thread_id=thread.id,
    role="user",
    content="""Hi! I need help with a few things:
    1. What's the weather like in Seattle?
    2. What's the current date and time?
    3. Can you generate a random number between 1 and 100?
    4. Please analyze this text: 'Azure AI Agents are incredibly powerful tools for building intelligent applications!'
    
    Thanks!"""
)

print(f"💬 Sent complex request with multiple tasks")

# Create and monitor the run
run = agents_client.runs.create(
    thread_id=thread.id,
    agent_id=super_agent.id
)

function_calls_made = 0

while run.status in ["queued", "in_progress", "requires_action"]:
    time.sleep(1)
    run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)
    
    if run.status == "requires_action":
        print(f"⚡ Agent needs to call function(s)! (Call #{function_calls_made + 1})")
        
        tool_calls = run.required_action.submit_tool_outputs.tool_calls
        tool_outputs = []
        
        for tool_call in tool_calls:
            if tool_call.type == "function":
                result = handle_multi_function_call(tool_call.function)
                tool_outputs.append({
                    "tool_call_id": tool_call.id,
                    "output": result
                })
                function_calls_made += 1
        
        # Submit all function results
        run = agents_client.runs.submit_tool_outputs(
            thread_id=thread.id,
            run_id=run.id,
            tool_outputs=tool_outputs
        )
        print(f"✅ Submitted {len(tool_outputs)} function result(s)")
    
    else:
        print(f"📊 Run status: {run.status}")

print(f"🎉 Run completed! Agent made {function_calls_made} function calls total.")

# %% [code]
# Display the amazing conversation
messages = agents_client.messages.list(
    thread_id=thread.id,
    order=ListSortOrder.ASCENDING
)

print(f"\n💬 Super Agent Conversation:")
print(f"═" * 80)

for i, msg in enumerate(messages, 1):
    if msg.text_messages:
        last_text = msg.text_messages[-1]
        role_emoji = "👤" if msg.role == "user" else "🤖"
        print(f"\n{i}. {role_emoji} {msg.role.upper()}:")
        
        # Split long messages for better readability
        content = last_text.text.value
        if len(content) > 500:
            lines = content.split('\n')
            for line in lines:
                if line.strip():
                    print(f"   {line}")
        else:
            print(f"   {content}")

print(f"\n" + "═" * 80)
print(f"🌟 Incredible! The agent intelligently used multiple functions to complete all tasks!")

# Cleanup
agents_client.delete_agent(super_agent.id)
print(f"\n🧹 Super agent deleted.")

# %% [markdown]
---

## 🎯 Practice Exercise: Build Your Own Function

Now it's your turn! Let's create a custom function and add it to an agent.

**Your Mission:**
1. Create a function that does something useful
2. Write the function definition for the agent
3. Test it with a custom agent

**Function Ideas:**
- **Password Generator**: Generate secure passwords
- **Unit Converter**: Convert between different units (temperature, distance, etc.)
- **Word Game**: Create word puzzles or rhymes
- **Simple Calculator**: More math operations (multiply, divide, square root)
- **Color Palette**: Generate color combinations

**Exercise template below - customize it!**

# %% [code]
# 🎯 YOUR TURN! Create your own function

# Example: Password Generator Function
def generate_password(length: int = 12, include_symbols: bool = True) -> str:
    """
    Generates a secure password.
    
    Args:
        length (int): Length of the password (default 12)
        include_symbols (bool): Whether to include symbols (default True)
        
    Returns:
        str: Generated password
    """
    import string
    
    characters = string.ascii_letters + string.digits
    if include_symbols:
        characters += "!@#$%^&*"
    
    password = ''.join(random.choice(characters) for _ in range(length))
    print(f"🔐 Generated password of length {length}")
    return password

# TODO: Replace this with your own function!
# def your_custom_function(param1, param2):
#     """Your function description"""
#     # Your logic here
#     return result

# Create function definition
# Initialize function tool with user functions
custom_functions = FunctionTool(functions=[generate_password])

# TODO: Create your own function definition here!

print("✅ Custom function ready for testing!")

# %% [code]
# Create the client
agents_client = create_agents_client()

# Test your custom function
with agents_client:
    # Create agent with your custom function
    custom_agent = agents_client.create_agent(
        model=os.environ["MODEL_DEPLOYMENT_NAME"],
        name="custom-assistant",
        instructions="You are a helpful assistant with custom capabilities. Use your functions when users request them. Be friendly and explain what you're doing.",
        tools=custom_functions.definitions  # Pass the function definitions
    )
    
    print(f"🎨 Created custom agent: {custom_agent.name}")
    
    # Test conversation
    thread = agents_client.threads.create()
    
    # TODO: Customize this message to test your function!
    test_message = agents_client.messages.create(
        thread_id=thread.id,
        role="user",
        content="Hi! Can you generate a secure password for me? Make it 16 characters long and include symbols."
    )
    
    print(f"💬 Test message: {test_message.content[0].text.value}")
    
    # Run with function handling
    run = agents_client.runs.create(
        thread_id=thread.id,
        agent_id=custom_agent.id
    )
    
    while run.status in ["queued", "in_progress", "requires_action"]:
        time.sleep(1)
        run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)
        
        if run.status == "requires_action":
            print("⚡ Testing your custom function!")
            
            tool_calls = run.required_action.submit_tool_outputs.tool_calls
            tool_outputs = []
            
            for tool_call in tool_calls:
                if tool_call.type == "function":
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    # Handle your custom function
                    if function_name == "generate_password":
                        result = generate_password(
                            length=function_args.get("length", 12),
                            include_symbols=function_args.get("include_symbols", True)
                        )
                        tool_outputs.append({
                            "tool_call_id": tool_call.id,
                            "output": result
                        })
                    
                    # TODO: Add handling for your custom function here!
            
            run = agents_client.runs.submit_tool_outputs(
                thread_id=thread.id,
                run_id=run.id,
                tool_outputs=tool_outputs
            )
    
    # Display results
    messages = agents_client.messages.list(
        thread_id=thread.id,
        order=ListSortOrder.ASCENDING
    )
    
    print(f"\n💬 Custom Function Test Results:")
    print(f"─" * 50)
    
    for msg in messages:
        if msg.text_messages:
            last_text = msg.text_messages[-1]
            role_emoji = "👤" if msg.role == "user" else "🤖"
            print(f"\n{role_emoji} {msg.role.upper()}:")
            print(f"{last_text.text.value}")
    
    print(f"\n🎉 Great job! Your custom function worked perfectly!")
    
    # Cleanup
    agents_client.delete_agent(custom_agent.id)
    print(f"\n🧹 Custom agent deleted.")

# %% [markdown]
---

## 🏆 Best Practices for Agent Functions

### ✅ Function Design:

1. **Clear Names**: Use descriptive function names (`get_weather` not `gw`)
2. **Good Descriptions**: Write clear descriptions for both function and parameters
3. **Proper Types**: Use correct parameter types (string, number, boolean, etc.)
4. **Error Handling**: Always handle potential errors gracefully
5. **Return Values**: Return appropriate data types and formats

### ✅ Security Considerations:

1. **Input Validation**: Always validate function parameters
2. **API Keys**: Never hardcode sensitive information
3. **Rate Limiting**: Be mindful of API rate limits
4. **Data Privacy**: Don't log sensitive user data

### ✅ Performance Tips:

1. **Fast Functions**: Keep functions quick to maintain good user experience
2. **Caching**: Cache results when appropriate
3. **Async Operations**: Consider async functions for I/O operations
4. **Error Messages**: Provide helpful error messages

### ✅ Testing:

1. **Unit Tests**: Test your functions independently
2. **Edge Cases**: Test with various input combinations
3. **Error Scenarios**: Test how functions handle errors
4. **Integration**: Test the full agent + function workflow

# %% [markdown]
## 🔧 Troubleshooting Common Issues

### Function Not Called
**Problem**: Agent doesn't use your function
**Solutions**: 
- Check function description clarity
- Verify parameter requirements
- Make sure the user request matches function capability
- Test with more explicit requests

### JSON Parse Errors
**Problem**: `json.loads()` fails on function arguments
**Solutions**:
- Add try/catch around JSON parsing
- Log the raw arguments to debug
- Check parameter type definitions

### Function Execution Errors
**Problem**: Function throws exceptions
**Solutions**:
- Add proper error handling in functions
- Validate all input parameters
- Return error messages instead of throwing exceptions
- Log errors for debugging

### Agent Gets Stuck
**Problem**: Run stays in "requires_action" status
**Solutions**:
- Ensure all tool_call_ids are included in outputs
- Check that function results are returned as strings
- Verify tool_outputs format is correct

### Performance Issues
**Problem**: Functions are slow
**Solutions**:
- Optimize function logic
- Add timeouts to external API calls
- Cache frequently requested data
- Consider async implementations for I/O operations

# %% [markdown]
---

## 🎓 Congratulations! You're Now a Function Master!

### What You've Accomplished:

✅ **Function Fundamentals**:
- Understanding how agent functions work
- Creating function definitions and tool registrations
- Handling function calls and results

✅ **Real-World Examples**:
- Built calculator, weather, random number, and text analysis functions
- Created multi-function agents
- Handled complex conversations with multiple function calls

✅ **Best Practices**:
- Learned proper function design principles
- Understood security and performance considerations
- Mastered error handling and troubleshooting

### 🚀 Next Level Capabilities:

Now you can create agents that:
- 🌐 **Access External APIs** (weather, news, databases)
- 🧮 **Perform Complex Calculations** (scientific, financial)
- 📊 **Process Data** (analyze files, generate reports)
- 🎮 **Create Interactive Experiences** (games, quizzes)
- 🤖 **Automate Tasks** (send emails, manage calendars)

### 🔮 Advanced Topics to Explore:

1. **Async Functions**: For better performance with I/O operations
2. **Function Chaining**: Have functions call other functions
3. **State Management**: Maintain data across function calls
4. **External Integrations**: Connect to databases, APIs, and services
5. **Function Libraries**: Build reusable function collections
6. **Production Deployment**: Scale function-enabled agents

### 💡 Key Takeaways:

- **Functions transform agents from chatbots into action-takers**
- **Good function design makes agents more intelligent and useful**
- **Error handling and testing are crucial for reliable agents**
- **The possibilities are endless with creative function combinations**

**Keep building amazing function-powered agents!** 🌟

---

*Remember: With great function power comes great responsibility! Always consider security, privacy, and user experience when designing agent functions.*

# %% [markdown]
## 📚 Quick Reference

### Function Definition Template:
```python
def my_function(param1: type, param2: type) -> return_type:
    """Clear description of what the function does."""
    # Your logic here
    return result

function_def = FunctionDefinition(
    name="my_function",
    description="Clear description for the agent",
    parameters={
        "type": "object",
        "properties": {
            "param1": {
                "type": "string",  # or "number", "boolean", "array", "object"
                "description": "What this parameter does"
            }
        },
        "required": ["param1"]
    }
)
```

### Function Handler Template:
```python
def handle_function_call(function_call):
    function_name = function_call.name
    function_args = json.loads(function_call.arguments)
    
    if function_name == "my_function":
        result = my_function(**function_args)
        return str(result)
    else:
        return f"Unknown function: {function_name}"
```

### Run with Functions Template:
```python
while run.status in ["queued", "in_progress", "requires_action"]:
    time.sleep(1)
    run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)
    
    if run.status == "requires_action":
        tool_calls = run.required_action.submit_tool_outputs.tool_calls
        tool_outputs = []
        
        for tool_call in tool_calls:
            if tool_call.type == "function":
                result = handle_function_call(tool_call.function)
                tool_outputs.append({
                    "tool_call_id": tool_call.id,
                    "output": result
                })
        
        run = agents_client.runs.submit_tool_outputs(
            thread_id=thread.id,
            run_id=run.id,
            tool_outputs=tool_outputs
        )
```

# %% [markdown]
## 🔗 Additional Resources

### Documentation:
- [Azure AI Agents Documentation](https://docs.microsoft.com/azure/ai-services/)
- [Function Calling Best Practices](https://docs.microsoft.com/azure/ai-services/)
- [JSON Schema Reference](https://json-schema.org/)

### Examples to Try:
- **File Processing**: Functions that read/write files
- **Database Operations**: Connect to databases
- **Image Processing**: Analyze or manipulate images
- **Email/SMS**: Send notifications
- **Web Scraping**: Get data from websites
- **Machine Learning**: Run ML models as functions

### Community:
- Share your functions with the community
- Learn from other developers' implementations
- Contribute to open-source function libraries

**Happy coding with Azure AI Agents Functions!** 🎉

################################################################################  02-agent-custom-functions\02.2-azure_ai_agents_semantic_kernel_plugins_tutorial.ipynb  ################################################################################
# %% [markdown]
# Azure AI Agents with Semantic Kernel Plugins - Complete Tutorial

🔧 **Supercharge your Azure AI Agents with Semantic Kernel Plugins!**

This tutorial shows you how to give your Azure AI agents **superpowers** using Semantic Kernel's plugin architecture!

## What You'll Learn:

1. **Plugin Basics** - What are plugins and why use them?
2. **Simple Plugins** - Creating your first agent plugin
3. **Real-World Examples** - Weather, calculations, and data processing
4. **Advanced Plugins** - Multiple functions and complex logic
5. **Best Practices** - Error handling and plugin design

**Prerequisites:** You should have completed the basic Azure AI Agents tutorial first!

---

# %% [markdown]
## 🛠️ What are Semantic Kernel Plugins?

Imagine your AI agent as a **smart assistant**, but one that can actually **DO things** beyond just chatting using the power of Semantic Kernel!

### Without Plugins:
- Agent can only provide text responses
- Limited to knowledge from training data
- Can't access real-time information
- Can't perform calculations or operations

### With Semantic Kernel Plugins:
- Agent can call external APIs 🌐
- Perform calculations and data processing 🧮
- Access databases and files 📁
- Interact with other services 🔗
- Take actions in the real world! 🚀

### Key Concepts:

- **Plugin Class**: You write Python classes with decorated methods
- **@kernel_function**: Decorator that marks methods as callable functions
- **Function Registration**: Semantic Kernel automatically registers your plugins
- **Function Calling**: The agent decides when and how to use them
- **Function Results**: The agent uses the results to provide better responses

Let's see this in action! ⚡

# %% [markdown]
## 📋 Setup and Prerequisites

Before we start, make sure you have:

1. ✅ Completed the basic Azure AI Agents tutorial
2. ✅ Environment variables set (`AZURE_AI_PROJECT_ENDPOINT`, `AZURE_AI_PROJECT_NAME`)
3. ✅ Azure authentication configured

We'll install any additional packages we need and import everything required for plugin-enabled agents.

# %% [markdown]
![SK Plugins](images/sk_plugins.gif)

# %% [code]
# Install required packages
# !pip install semantic-kernel azure-identity requests

# Import everything we need
import os
import asyncio
import json
import requests
import random
from datetime import datetime
from typing import Any, Dict, Annotated

from azure.identity.aio import DefaultAzureCredential
from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings
from semantic_kernel.functions import kernel_function

print("📦 All packages imported successfully!")
print("🔧 Ready to create plugin-enabled agents!")

# Verify environment variables
required_vars = ['PROJECT_ENDPOINT', 'MODEL_DEPLOYMENT_NAME']
for var in required_vars:
    if var in os.environ:
        print(f"✅ {var} is set")
    else:
        print(f"❌ {var} is missing!")

# %% [markdown]
## 🎯 Your First Plugin: Simple Calculator

Let's start with something simple - a calculator plugin that your agent can use to perform math operations.

**What we'll do:**
1. Write a Python class with calculator methods
2. Use the `@kernel_function` decorator to mark methods as callable
3. Add the plugin to our agent
4. Test it out!

**The magic:** The agent will automatically decide when to use these functions based on user requests!

# %% [code]
# Step 1: Create our Calculator Plugin Class
class CalculatorPlugin:
    """A simple calculator plugin for performing basic math operations."""
    
    @kernel_function(
        description="Adds two numbers together",
        name="add_numbers"
    )
    def add_numbers(
        self, 
        a: Annotated[float, "The first number"], 
        b: Annotated[float, "The second number"]
    ) -> Annotated[float, "The sum of the two numbers"]:
        """
        Adds two numbers together.
        
        Args:
            a (float): First number
            b (float): Second number
            
        Returns:
            float: The sum of a and b
        """
        result = a + b
        print(f"🧮 Calculator called: {a} + {b} = {result}")
        return result
    
    @kernel_function(
        description="Subtracts the second number from the first number",
        name="subtract_numbers"
    )
    def subtract_numbers(
        self, 
        a: Annotated[float, "The first number"], 
        b: Annotated[float, "The second number"]
    ) -> Annotated[float, "The difference of the two numbers"]:
        """
        Subtracts the second number from the first number.
        """
        result = a - b
        print(f"🧮 Calculator called: {a} - {b} = {result}")
        return result

# Create an instance of our calculator plugin
calculator_plugin = CalculatorPlugin()

print("✅ Calculator plugin ready!")
print(f"📝 Plugin has addition and subtraction functions available")

# %% [code]
# Step 2: Create an agent with our calculator plugin

model_deployment_name = os.environ.get("MODEL_DEPLOYMENT_NAME")
endpoint = os.environ.get("PROJECT_ENDPOINT")


async def create_calculator_agent():
    """Create an Azure AI agent with a calculator plugin."""

    # Ensure we have the required environment variables
    model_deployment_name = os.environ.get("MODEL_DEPLOYMENT_NAME")
    endpoint = os.environ.get("PROJECT_ENDPOINT")

    # Create the Azure AI agent client
    client = AzureAIAgent.create_client(credential=DefaultAzureCredential(), 
                                        endpoint=endpoint) 
    
    # Create an agent definition on the Azure AI agent service
    agent_definition = await client.agents.create_agent(
        model=model_deployment_name,
        name="math-genius",
        instructions="You are a helpful math assistant. When users ask for calculations, use the available functions to compute accurate results. Always show your work and explain the calculation."
    )
    
    # Create a Semantic Kernel agent with the calculator plugin
    agent = AzureAIAgent(
        client=client,
        definition=agent_definition,
        plugins=[calculator_plugin]  # Add our plugin here!
    )
    
    print(f"🤖 Created calculator agent: {agent_definition.name}")
    print(f"🛠️ Agent has calculator plugin with addition and subtraction")
    print(f"🆔 Agent ID: {agent_definition.id}")
    
    return agent, client

# We'll run this in the next cell to test the agent

# %% [markdown]
## 🚀 Testing Our Calculator Agent

Now let's test our plugin-enabled agent! We'll ask it to do some math and watch it automatically use our plugin functions.

**What to expect:**
1. We send a math question
2. The agent recognizes it needs to calculate something
3. The agent calls our calculator plugin functions
4. The agent incorporates the result into its response

**Note:** Semantic Kernel handles all the function calling automatically!

# %% [code]
# Test our calculator agent
async def test_calculator_agent():
    agent, client = await create_calculator_agent()
    
    # Test math questions
    test_questions = [
        "Hi! Can you help me calculate 125 + 387? Please show me the exact result.",
        "What is 1000 - 234?",
        "Can you add 45.5 and 12.3 for me?"
    ]
    
    thread = None
    
    try:
        for i, question in enumerate(test_questions, 1):
            print(f"\n{'='*60}")
            print(f"Test {i}: {question}")
            print(f"{'='*60}")
            
            # Use invoke method which handles function calling automatically
            async for response in agent.invoke(messages=question, thread=thread):
                print(f"🤖 {response.name}: {response}")
                thread = response.thread
    
    finally:
        # Cleanup
        if thread:
            await thread.delete()
        await client.agents.delete_agent(agent.id)
        print(f"\n🧹 Calculator agent deleted.")

# Run the test
await test_calculator_agent()

# %% [markdown]
---

## 🌟 Level Up: Real-World Plugins

Now let's create more practical plugins that agents can use in real scenarios:

1. **Weather Plugin** - Get current weather information
2. **Random Generator Plugin** - Generate random numbers or choices
3. **Date/Time Plugin** - Get current date and time information
4. **Text Processing Plugin** - Analyze and manipulate text

These examples show how plugins can make your agents incredibly powerful!

# %% [code]
# Weather Plugin
class WeatherPlugin:
    """A plugin for getting weather information."""
    
    @kernel_function(
        description="Gets the current weather for a city",
        name="get_weather"
    )
    def get_weather(
        self, 
        city: Annotated[str, "The name of the city to get weather for"]
    ) -> Annotated[str, "The current weather information"]:
        """
        Gets the current weather for a city (mock implementation).
        """
        # In a real implementation, you'd call a weather API
        weather_options = [
            f"Sunny and 72°F in {city}",
            f"Partly cloudy and 68°F in {city}", 
            f"Rainy and 61°F in {city}",
            f"Overcast and 65°F in {city}"
        ]
        weather = random.choice(weather_options)
        print(f"🌤️ Weather check: {weather}")
        return weather

# Random Number Plugin
class RandomPlugin:
    """A plugin for generating random numbers and choices."""
    
    @kernel_function(
        description="Generates a random number between min and max values",
        name="generate_random_number"
    )
    def generate_random_number(
        self, 
        min_val: Annotated[int, "The minimum value (inclusive)"], 
        max_val: Annotated[int, "The maximum value (inclusive)"]
    ) -> Annotated[int, "A random number between min and max"]:
        """
        Generates a random number between min and max values.
        """
        result = random.randint(min_val, max_val)
        print(f"🎲 Generated random number: {result} (between {min_val} and {max_val})")
        return result

# DateTime Plugin
class DateTimePlugin:
    """A plugin for date and time operations."""
    
    @kernel_function(
        description="Gets the current date and time",
        name="get_current_datetime"
    )
    def get_current_datetime(self) -> Annotated[str, "The current date and time"]:
        """
        Gets the current date and time.
        """
        now = datetime.now()
        formatted_time = now.strftime("%Y-%m-%d %H:%M:%S")
        print(f"🕐 Current time: {formatted_time}")
        return formatted_time

# Text Analysis Plugin
class TextAnalysisPlugin:
    """A plugin for analyzing text content."""
    
    @kernel_function(
        description="Analyzes text and returns statistics",
        name="analyze_text"
    )
    def analyze_text(
        self, 
        text: Annotated[str, "The text to analyze"]
    ) -> Annotated[str, "JSON string containing text analysis results"]:
        """
        Analyzes text and returns statistics.
        """
        words = text.split()
        analysis = {
            "character_count": len(text),
            "word_count": len(words),
            "sentence_count": text.count('.') + text.count('!') + text.count('?'),
            "average_word_length": round(sum(len(word) for word in words) / len(words), 2) if words else 0
        }
        print(f"📊 Text analysis complete: {analysis}")
        return json.dumps(analysis)

# Create plugin instances
weather_plugin = WeatherPlugin()
random_plugin = RandomPlugin()
datetime_plugin = DateTimePlugin()
text_analysis_plugin = TextAnalysisPlugin()

print("✅ All utility plugins defined!")
print("🔧 Available plugins: Weather, Random, DateTime, TextAnalysis")

# %% [code]
# Create a super-powered agent with multiple plugins
async def create_super_agent():
    """Create an Azure AI agent with multiple utility plugins."""

    # Ensure we have the required environment variables
    model_deployment_name = os.environ.get("MODEL_DEPLOYMENT_NAME")
    endpoint = os.environ.get("PROJECT_ENDPOINT")

    # Create the Azure AI agent client
    client = AzureAIAgent.create_client(credential=DefaultAzureCredential(), endpoint=endpoint)

    # Create an agent definition
    agent_definition = await client.agents.create_agent(
        model=model_deployment_name,
        name="super-assistant",
        instructions="""You are a versatile AI assistant with access to multiple plugins. You can:
            - Get weather information for any city
            - Generate random numbers
            - Provide current date and time
            - Analyze text statistics

        Always use the appropriate plugins when users request these capabilities.
        Be helpful, accurate, and explain what you're doing when you use functions."""
    )
    
    
    # Create agent with all plugins
    agent = AzureAIAgent(
        client=client,
        definition=agent_definition,
        plugins=[
            weather_plugin,
            random_plugin, 
            datetime_plugin,
            text_analysis_plugin
        ]
    )
    
    print(f"🚀 Created super agent: {agent_definition.name}")
    print(f"🛠️ Agent has 4 plugins with multiple functions")
    print(f"🆔 Agent ID: {agent_definition.id}")
    
    return agent, client

print("✅ Super agent creator ready!")

# %% [code]
# Test the super agent with multiple plugin calls
async def test_super_agent():
    agent, client = await create_super_agent()
    
    # Send a complex request that might use multiple plugins
    complex_request = """Hi! I need help with a few things:
    1. What's the weather like in Seattle?
    2. What's the current date and time?
    3. Can you generate a random number between 1 and 100?
    4. Please analyze this text: 'Azure AI Agents with Semantic Kernel are incredibly powerful tools for building intelligent applications!'
    
    Thanks!"""
    
    print(f"💬 Sending complex request with multiple tasks")
    print(f"{'='*80}")
    print(f"👤 USER: {complex_request}")
    print(f"{'='*80}")
    
    thread = None
    function_calls_made = 0
    
    try:
        # Use invoke method which handles all function calling automatically
        async for response in agent.invoke(messages=complex_request, thread=thread):
            print(f"\n🤖 {response.name}:")
            
            # Split long responses for better readability
            content = str(response)
            if len(content) > 500:
                lines = content.split('\n')
                for line in lines:
                    if line.strip():
                        print(f"   {line}")
            else:
                print(f"   {content}")
            
            thread = response.thread
    
    finally:
        # Cleanup
        if thread:
            await thread.delete()
        await client.agents.delete_agent(agent.id)
        print(f"\n🧹 Super agent deleted.")
    
    print(f"\n🌟 Incredible! The agent intelligently used multiple plugins to complete all tasks!")

# Run the super agent test
await test_super_agent()

# %% [markdown]
---

## 🎯 Practice Exercise: Build Your Own Plugin

Now it's your turn! Let's create a custom plugin and add it to an agent.

**Your Mission:**
1. Create a plugin class with useful methods
2. Use the `@kernel_function` decorator properly
3. Test it with a custom agent

**Plugin Ideas:**
- **Password Generator**: Generate secure passwords
- **Unit Converter**: Convert between different units (temperature, distance, etc.)
- **Word Game**: Create word puzzles or rhymes
- **Advanced Calculator**: More math operations (multiply, divide, square root)
- **Color Palette**: Generate color combinations

**Exercise template below - customize it!**

# %% [code]
# 🎯 YOUR TURN! Create your own plugin

# Example: Password Generator Plugin
class PasswordPlugin:
    """A plugin for generating secure passwords."""
    
    @kernel_function(
        description="Generates a secure password",
        name="generate_password"
    )
    def generate_password(
        self, 
        length: Annotated[int, "Length of the password (default 12)"] = 12,
        include_symbols: Annotated[bool, "Whether to include symbols (default True)"] = True
    ) -> Annotated[str, "The generated password"]:
        """
        Generates a secure password.
        
        Args:
            length (int): Length of the password (default 12)
            include_symbols (bool): Whether to include symbols (default True)
            
        Returns:
            str: Generated password
        """
        import string
        
        characters = string.ascii_letters + string.digits
        if include_symbols:
            characters += "!@#$%^&*"
        
        password = ''.join(random.choice(characters) for _ in range(length))
        print(f"🔐 Generated password of length {length}")
        return password

# TODO: Replace this with your own plugin!
# class YourCustomPlugin:
#     """Your custom plugin description."""
#     
#     @kernel_function(
#         description="What your function does",
#         name="your_function_name"
#     )
#     def your_function(
#         self, 
#         param1: Annotated[str, "Description of param1"]
#     ) -> Annotated[str, "Description of return value"]:
#         """Your function implementation."""
#         # Your logic here
#         return result

# Create plugin instance
password_plugin = PasswordPlugin()

print("✅ Custom plugin ready for testing!")

# %% [code]
# Test your custom plugin
async def test_custom_plugin():
    """Test the custom plugin by creating an agent and invoking it."""

    # Ensure we have the required environment variables
    model_deployment_name = os.environ.get("MODEL_DEPLOYMENT_NAME")
    endpoint = os.environ.get("PROJECT_ENDPOINT")

    # Create the Azure AI agent client
    client = AzureAIAgent.create_client(credential=DefaultAzureCredential(), endpoint=endpoint)

    # Create agent with your custom plugin
    agent_definition = await client.agents.create_agent(
        model=model_deployment_name,
        name="custom-assistant",
        instructions="You are a helpful assistant with custom capabilities. Use your plugins when users request them. Be friendly and explain what you're doing."
    )
    
    agent = AzureAIAgent(
        client=client,
        definition=agent_definition,
        plugins=[password_plugin]  # Add your plugin here!
    )
    
    print(f"🎨 Created custom agent: {agent_definition.name}")
    
    # TODO: Customize this message to test your plugin!
    test_message = "Hi! Can you generate a secure password for me? Make it 16 characters long and include symbols."
    
    print(f"\n💬 Test message: {test_message}")
    print(f"{'─'*50}")
    
    thread = None
    
    try:
        # Test the custom plugin
        async for response in agent.invoke(messages=test_message, thread=thread):
            print(f"\n🤖 {response.name}: {response}")
            thread = response.thread
        
        print(f"\n🎉 Great job! Your custom plugin worked perfectly!")
    
    finally:
        # Cleanup
        if thread:
            await thread.delete()
        await client.agents.delete_agent(agent.id)
        print(f"\n🧹 Custom agent deleted.")

# Run the custom plugin test
await test_custom_plugin()

# %% [markdown]
---

## 🏆 Best Practices for Semantic Kernel Plugins

### ✅ Plugin Design:

1. **Clear Names**: Use descriptive function names (`get_weather` not `gw`)
2. **Good Descriptions**: Write clear descriptions in the `@kernel_function` decorator
3. **Proper Annotations**: Use `Annotated` types for better function understanding
4. **Error Handling**: Always handle potential errors gracefully
5. **Return Values**: Return appropriate data types and formats

### ✅ Security Considerations:

1. **Input Validation**: Always validate function parameters
2. **API Keys**: Never hardcode sensitive information
3. **Rate Limiting**: Be mindful of API rate limits
4. **Data Privacy**: Don't log sensitive user data

### ✅ Performance Tips:

1. **Fast Functions**: Keep functions quick to maintain good user experience
2. **Caching**: Cache results when appropriate
3. **Async Operations**: Use async methods when possible for I/O operations
4. **Error Messages**: Provide helpful error messages

### ✅ Testing:

1. **Unit Tests**: Test your plugin methods independently
2. **Edge Cases**: Test with various input combinations
3. **Error Scenarios**: Test how plugins handle errors
4. **Integration**: Test the full agent + plugin workflow

# %% [markdown]
## 🔧 Troubleshooting Common Issues

### Plugin Not Called
**Problem**: Agent doesn't use your plugin
**Solutions**: 
- Check function description clarity in `@kernel_function`
- Verify parameter annotations are descriptive
- Make sure the user request matches plugin capability
- Test with more explicit requests

### Import Errors
**Problem**: Plugin imports fail
**Solutions**:
- Ensure all required packages are installed
- Check that `semantic_kernel` is properly installed
- Verify Azure credentials are configured

### Function Execution Errors
**Problem**: Plugin methods throw exceptions
**Solutions**:
- Add proper error handling in plugin methods
- Validate all input parameters
- Return error messages instead of throwing exceptions
- Log errors for debugging

### Agent Connection Issues
**Problem**: Can't connect to Azure AI services
**Solutions**:
- Verify environment variables are set correctly
- Check Azure authentication (DefaultAzureCredential)
- Ensure proper Azure permissions
- Verify endpoint and model deployment names

### Performance Issues
**Problem**: Plugins are slow
**Solutions**:
- Optimize plugin logic
- Add timeouts to external API calls
- Cache frequently requested data
- Consider async implementations for I/O operations

# %% [markdown]
---

## 🎓 Congratulations! You're Now a Semantic Kernel Plugin Master!

### What You've Accomplished:

✅ **Plugin Fundamentals**:
- Understanding how Semantic Kernel plugins work
- Creating plugin classes with `@kernel_function` decorators
- Using proper type annotations for better AI understanding

✅ **Real-World Examples**:
- Built calculator, weather, random number, and text analysis plugins
- Created multi-plugin agents
- Handled complex conversations with multiple plugin calls

✅ **Best Practices**:
- Learned proper plugin design principles
- Understood security and performance considerations
- Mastered error handling and troubleshooting

### 🚀 Next Level Capabilities:

Now you can create agents that:
- 🌐 **Access External APIs** (weather, news, databases)
- 🧮 **Perform Complex Calculations** (scientific, financial)
- 📊 **Process Data** (analyze files, generate reports)
- 🎮 **Create Interactive Experiences** (games, quizzes)
- 🤖 **Automate Tasks** (send emails, manage calendars)

### 🔮 Advanced Topics to Explore:

1. **Async Plugins**: For better performance with I/O operations
2. **Plugin Chaining**: Have plugins call other plugins
3. **State Management**: Maintain data across plugin calls
4. **External Integrations**: Connect to databases, APIs, and services
5. **Plugin Libraries**: Build reusable plugin collections
6. **Production Deployment**: Scale plugin-enabled agents

### 💡 Key Takeaways:

- **Plugins transform agents from chatbots into action-takers**
- **Semantic Kernel makes plugin development elegant and powerful**
- **Good plugin design makes agents more intelligent and useful**
- **Error handling and testing are crucial for reliable agents**
- **The possibilities are endless with creative plugin combinations**

**Keep building amazing plugin-powered agents with Semantic Kernel!** 🌟

---

*Remember: With great plugin power comes great responsibility! Always consider security, privacy, and user experience when designing agent plugins.*

# %% [markdown]
## 📚 Quick Reference

### Plugin Class Template:
```python
class MyPlugin:
    """Description of what this plugin does."""
    
    @kernel_function(
        description="Clear description of what the function does",
        name="my_function"
    )
    def my_function(
        self, 
        param1: Annotated[str, "Description of param1"],
        param2: Annotated[int, "Description of param2"] = 10
    ) -> Annotated[str, "Description of return value"]:
        """Function implementation."""
        # Your logic here
        return result
```

### Agent Creation Template:
```python
async def create_agent_with_plugins():
    async with DefaultAzureCredential() as creds:
        async with AzureAIAgent.create_client(credential=creds) as client:
            agent_definition = await client.agents.create_agent(
                model=AzureAIAgentSettings().model_deployment_name,
                name="my-agent",
                instructions="Agent instructions here"
            )
            
            agent = AzureAIAgent(
                client=client,
                definition=agent_definition,
                plugins=[plugin1, plugin2, plugin3]
            )
            
            return agent, client
```

### Plugin Testing Template:
```python
async def test_agent():
    agent, client = await create_agent_with_plugins()
    
    thread = None
    
    try:
        async for response in agent.invoke(messages="Your test message", thread=thread):
            print(f"🤖 {response.name}: {response}")
            thread = response.thread
    
    finally:
        if thread:
            await thread.delete()
        await client.agents.delete_agent(agent.id)
```

# %% [markdown]
## 🔗 Additional Resources

### Documentation:
- [Semantic Kernel Documentation](https://learn.microsoft.com/semantic-kernel/)
- [Azure AI Agents Documentation](https://docs.microsoft.com/azure/ai-services/)
- [Plugin Development Guide](https://learn.microsoft.com/semantic-kernel/)

### Examples to Try:
- **File Processing**: Plugins that read/write files
- **Database Operations**: Connect to databases
- **Image Processing**: Analyze or manipulate images
- **Email/SMS**: Send notifications
- **Web Scraping**: Get data from websites
- **Machine Learning**: Run ML models as plugins

### Community:
- Share your plugins with the community
- Learn from other developers' implementations
- Contribute to open-source plugin libraries

**Happy coding with Azure AI Agents and Semantic Kernel Plugins!** 🎉

################################################################################  02-agent-custom-functions\README.md  ################################################################################
# Agent Custom Functions

Learn how to extend your agents with custom functions and plugins. This is where your agents become truly useful by connecting to external services and performing real tasks.

## What's In This Folder

**[02.1 - Azure AI Agents Functions (Foundry SDK)](02.1-azure_ai_agents_functions_foundry_sdk_tutorial.ipynb)**
Add custom functions to your agents using the official Azure AI Agents SDK. Build calculators, weather tools, and data processors that your agents can use.

**[02.2 - Semantic Kernel Plugins](02.2-azure_ai_agents_semantic_kernel_plugins_tutorial.ipynb)**
Create sophisticated plugins using Semantic Kernel's decorator system. Learn type-safe development and build reusable plugin libraries.

![SK Plugins](images/sk_plugins.gif)


## Learning Path

1. **Start with 02.1** - Learn function basics with the Foundry SDK
2. **Move to 02.2** - Explore advanced plugin architecture

**Prerequisites**: Complete [01-agent-basics](../01-agent-basics/) first.

## Prerequisites

### Previous Knowledge
- Complete [01-agent-basics](../01-agent-basics/) tutorials
- Basic Python programming

### Azure Resources
- Azure subscription
- Azure AI Foundry project
- Deployed AI model (GPT-4, GPT-3.5-turbo, etc.)

### Environment Setup
- Python 3.8+
- Jupyter Notebook or VS Code

### Environment Variables
Configure your Azure AI services in the `.env` file at the project root:

```bash
# Navigate to the project root and edit the .env file
cd ../../  # Go to azure-ai-agents-playbook root
```

Update the `.env` file with your Azure AI project details:
```properties
# Required for all tutorials
PROJECT_ENDPOINT="https://your-foundry-resource.services.ai.azure.com/api/projects/your-project-name"
MODEL_DEPLOYMENT_NAME="your-model-deployment-name"

# For Semantic Kernel scenarios
AZURE_OPENAI_API_KEY="your-azure-openai-api-key"
AZURE_OPENAI_ENDPOINT="https://your-openai-resource.openai.azure.com/"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME="your-chat-deployment"
AZURE_OPENAI_DEPLOYMENT_NAME="your-deployment-name"
AZURE_OPENAI_API_VERSION="2024-12-01-preview"

# Optional: For advanced scenarios
AZURE_SUBSCRIPTION_ID="your-subscription-id"
```

**Tip**: The `.env` file already exists in the project root with example values - just update it with your details.

### Required Packages
Install the packages you need:

```bash
pip install azure-ai-agents azure-identity semantic-kernel requests
```

## What You'll Learn

### Function Types
- **Foundry SDK Functions**: Direct function registration with fine-grained control
- **Semantic Kernel Plugins**: Automatic function discovery with type safety


## Next Steps

After mastering functions and plugins:
- [03-orchestrated-agents](../03-orchestrated-agents/) - Coordinate multiple agents
- [04-orchestrated-agents-with-tools](../04-orchestrated-agents-with-tools/) - Advanced tool integration

################################################################################  03-orchestrated-agents\03.1-concurrent_and_sequential_orchestration_tutorial.ipynb  ################################################################################
# %% [markdown]
# Azure AI Agents Orchestration with Semantic Kernel - Complete Tutorial

🚀 **Master the Art of Multi-Agent Orchestration!**

This tutorial shows you how to orchestrate multiple **Azure AI Agents** working together using Semantic Kernel, both **sequentially** and **concurrently**!

## What You'll Learn:

1. **Sequential Orchestration** - Azure AI Agents working one after another in a pipeline
2. **Concurrent Orchestration** - Multiple Azure AI Agents working simultaneously
3. **Agent Specialization** - Creating specialized Azure AI Agents with unique plugins
4. **Workflow Patterns** - Real-world orchestration scenarios with Azure AI Agents
5. **Performance Optimization** - When to use concurrent vs sequential patterns

**Azure AI Configuration:**
- Uses **Azure AI Agents** (not ChatCompletionAgent)
- Uses **AzureChatCompletion** service (not OpenAIChatCompletion)
- Automatically configures Azure OpenAI connection using environment variables
- Compatible with Azure AI Studio deployments

**Prerequisites:** You should have completed the basic Azure AI Agents and Plugins tutorials first!

---

# %% [markdown]
## 🎭 The Power of Agent Orchestration

Imagine having a team of **Azure AI Agents** working together on complex tasks!

### Single Agent Limitations:
- One agent handles everything
- Limited expertise in specific domains
- Potential context overload
- Slower processing for complex workflows

### Multi-Agent Orchestration Benefits:
- **Specialization**: Each Azure AI Agent excels in specific tasks 🎯
- **Parallel Processing**: Multiple Azure AI Agents work simultaneously ⚡
- **Better Results**: Domain experts produce higher quality outputs 📈
- **Scalability**: Add more Azure AI Agents as needed 🔄
- **Resilience**: If one agent fails, others continue 💪

### Orchestration Patterns:

- **Sequential (Pipeline)**: Azure AI Agent A → Azure AI Agent B → Azure AI Agent C
- **Concurrent (Parallel)**: Azure AI Agent A + Azure AI Agent B + Azure AI Agent C → Combine Results
- **Hybrid**: Mix of sequential and concurrent patterns

Let's build this step by step with Azure AI Agents! 🛠️

# %% [markdown]
## Sequential Orchestration

![Sequential Orchestration](images/sequential_orchestration.gif)

# %% [markdown]
## Concurrent Orchestration
![Concurrent Orchestration](images/concurrent_orchestration.gif)

# %% [markdown]
## 📋 Setup and Prerequisites

Before we start orchestrating Azure AI Agents, let's make sure we have everything we need:

**Environment Variables Required:**
- `PROJECT_ENDPOINT`: Your Azure AI Project endpoint
- `MODEL_DEPLOYMENT_NAME`: Your deployed AI model name
- `AZURE_OPENAI_API_KEY`: Your Azure OpenAI API key (optional, can use DefaultAzureCredential)
- `AZURE_OPENAI_ENDPOINT`: Your Azure OpenAI endpoint (optional, can use DefaultAzureCredential)

**Azure Configuration:**
- Uses **Azure AI Agents** (not ChatCompletionAgent)
- Uses **AzureChatCompletion** service with DefaultAzureCredential
- Automatically configures Azure OpenAI connection using environment variables
- Compatible with Azure AI Studio deployments

We'll import all the necessary libraries and create our specialized plugins for each Azure AI Agent.

# %% [code]
# Install required packages
# !pip install azure-ai-agents azure-identity semantic-kernel

# Import everything we need for Azure AI Agent orchestration
import os
import asyncio
import json
import time
import random
from datetime import datetime, timedelta
from typing import Any, Dict, List, Annotated

# Azure AI Agents and Semantic Kernel imports
from azure.identity.aio import DefaultAzureCredential
from semantic_kernel.agents import (
    Agent,
    AzureAIAgent,
    ConcurrentOrchestration,
    SequentialOrchestration
)
from semantic_kernel.agents.runtime import InProcessRuntime
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
from semantic_kernel.functions import kernel_function
from semantic_kernel.contents import ChatMessageContent, AuthorRole
from semantic_kernel.agents.open_ai.run_polling_options import RunPollingOptions

print("🎭 Azure AI Agent orchestration packages imported successfully!")
print("🎯 Ready to create specialized Azure AI Agent teams with Semantic Kernel!")

# Verify environment variables for Azure AI Agents
required_vars = ['PROJECT_ENDPOINT', 'MODEL_DEPLOYMENT_NAME']
optional_vars = ['AZURE_OPENAI_ENDPOINT', 'AZURE_OPENAI_API_KEY']

for var in required_vars:
    if var in os.environ:
        print(f"✅ {var}: {'*' * (len(os.environ[var]) - 10)}{os.environ[var][-10:]}")
    else:
        print(f"❌ {var} is missing!")

for var in optional_vars:
    if var in os.environ:
        print(f"✅ {var}: Set (will use for fallback)")
    else:
        print(f"ℹ️ {var}: Not set (will use DefaultAzureCredential)")
        
print("\n🔧 Azure AI Agents will use DefaultAzureCredential for authentication!")
print("📘 Make sure you're signed into Azure CLI or have appropriate Azure credentials!")

# %% [markdown]
## 🏗️ Creating Specialized Agent Plugins

Let's create three specialized Azure AI Agents with unique capabilities:

1. **🔍 Research Agent** - Information gathering and analysis
2. **📊 Analytics Agent** - Data processing and calculations
3. **📝 Content Agent** - Writing and formatting

Each Azure AI Agent will have specialized plugins that make them experts in their domain!

# %% [code]
# 🔍 Research Agent Plugins
class ResearchPlugin:
    """Plugin for research and information gathering tasks."""
    
    @kernel_function(
        description="Researches information about a topic and provides key facts",
        name="research_topic"
    )
    def research_topic(
        self, 
        topic: Annotated[str, "The topic to research"]
    ) -> Annotated[str, "JSON string with research findings"]:
        """Simulates research on a topic."""
        # In a real implementation, this would call APIs, search databases, etc.
        research_data = {
            "topic": topic,
            "key_facts": [
                f"Key insight about {topic} - statistical trends",
                f"Recent developments in {topic} field",
                f"Expert opinions on {topic} future"
            ],
            "sources": ["Academic Papers", "Industry Reports", "Expert Interviews"],
            "confidence": 85,
            "research_time": datetime.now().isoformat()
        }
        print(f"🔍 Research completed for: {topic}")
        return json.dumps(research_data, indent=2)
    
    @kernel_function(
        description="Validates information sources and checks credibility",
        name="validate_sources"
    )
    def validate_sources(
        self,
        sources: Annotated[str, "List of sources to validate"]
    ) -> Annotated[str, "Validation results"]:
        """Validates information sources."""
        validation = {
            "validated_sources": sources.split(","),
            "credibility_score": random.randint(75, 95),
            "recommendations": "Sources appear credible and current"
        }
        print(f"🔍 Source validation completed")
        return json.dumps(validation)

# 📊 Analytics Agent Plugins
class AnalyticsPlugin:
    """Plugin for data analysis and calculations."""
    
    @kernel_function(
        description="Analyzes data and calculates statistics",
        name="analyze_data"
    )
    def analyze_data(
        self,
        data_description: Annotated[str, "Description of the data to analyze"]
    ) -> Annotated[str, "Analysis results with statistics"]:
        """Performs data analysis."""
        # Simulate complex data analysis
        analysis = {
            "data_analyzed": data_description,
            "metrics": {
                "mean": round(random.uniform(10, 100), 2),
                "median": round(random.uniform(10, 100), 2),
                "std_deviation": round(random.uniform(5, 20), 2),
                "sample_size": random.randint(100, 10000)
            },
            "trends": ["Upward trend", "Seasonal variation", "Growth acceleration"],
            "insights": f"Key patterns identified in {data_description}",
            "analysis_timestamp": datetime.now().isoformat()
        }
        print(f"📊 Data analysis completed for: {data_description}")
        return json.dumps(analysis, indent=2)
    
    @kernel_function(
        description="Creates projections and forecasts based on data",
        name="create_forecast"
    )
    def create_forecast(
        self,
        baseline_data: Annotated[str, "Baseline data for forecasting"]
    ) -> Annotated[str, "Forecast results"]:
        """Creates forecasts based on data."""
        forecast = {
            "forecast_period": "Next 6 months",
            "projected_values": [round(random.uniform(80, 120), 1) for _ in range(6)],
            "confidence_interval": "85-95%",
            "risk_factors": ["Market volatility", "Seasonal effects"],
            "recommendations": "Monitor key indicators weekly"
        }
        print(f"📊 Forecast created based on: {baseline_data}")
        return json.dumps(forecast)

# 📝 Content Agent Plugins
class ContentPlugin:
    """Plugin for content creation and formatting."""
    
    @kernel_function(
        description="Creates well-formatted reports from research and analysis data",
        name="create_report"
    )
    def create_report(
        self,
        research_data: Annotated[str, "Research findings to include"],
        analysis_data: Annotated[str, "Analysis results to include"]
    ) -> Annotated[str, "Formatted report"]:
        """Creates a formatted report from data."""
        report = f"""
# Executive Summary Report

**Generated on:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Research Findings
{research_data}

## Data Analysis
{analysis_data}

## Recommendations
- Implement data-driven strategies
- Monitor key performance indicators
- Schedule regular review cycles

---
*Report generated by AI Agent Orchestration System*
"""
        print(f"📝 Report created successfully")
        return report
    
    @kernel_function(
        description="Summarizes complex information into key points",
        name="create_summary"
    )
    def create_summary(
        self,
        content: Annotated[str, "Content to summarize"]
    ) -> Annotated[str, "Executive summary"]:
        """Creates an executive summary."""
        summary = {
            "executive_summary": "Key insights and recommendations from comprehensive analysis",
            "main_points": [
                "Research validates current market position",
                "Analytics reveal positive growth trends", 
                "Strategic opportunities identified"
            ],
            "action_items": [
                "Continue monitoring metrics",
                "Implement recommended changes",
                "Schedule follow-up analysis"
            ]
        }
        print(f"📝 Summary created")
        return json.dumps(summary, indent=2)

# Create plugin instances
research_plugin = ResearchPlugin()
analytics_plugin = AnalyticsPlugin()
content_plugin = ContentPlugin()

print("✅ All specialized plugins created!")
print("🔍 Research Plugin: Information gathering & validation")
print("📊 Analytics Plugin: Data analysis & forecasting")
print("📝 Content Plugin: Report creation & summarization")

# %% [markdown]
## 🤖 Creating Our Specialized Azure AI Agent Team

Now let's create three specialized Azure AI Agents, each with their own expertise and plugins:

1. **Dr. Research** 🔍 - The information specialist
2. **Prof. Analytics** 📊 - The data scientist  
3. **Ms. Content** 📝 - The communication expert

Each Azure AI Agent will have distinct instructions and specialized plugins to excel in their domain!

# %% [code]
async def create_specialized_agents():
    """Create three specialized Azure AI Agents with unique capabilities using Semantic Kernel."""
    
    print("🤖 Creating specialized Azure AI Agent team...")
    
    endpoint = os.environ["PROJECT_ENDPOINT"]
    model_deployment = os.environ["MODEL_DEPLOYMENT_NAME"]
    agents = {}
    
    async with DefaultAzureCredential() as creds:
        client = AzureAIAgent.create_client(credential=creds, endpoint=endpoint)
        
        # 🔍 Create Research Agent
        print("🔍 Creating Research Agent...")
        research_agent_definition = await client.agents.create_agent(
            model=model_deployment,
            name="dr_research",
            description="World-class information specialist and fact-checker",
            instructions="""You are Dr. Research, a world-class information specialist and fact-checker.
            
            Your expertise:
            - Gathering comprehensive information on any topic
            - Validating sources and checking credibility
            - Providing well-researched, factual content
            - Identifying key insights and trends
            
            Always use your research plugins when asked to investigate topics.
            Be thorough, accurate, and cite your methodology.
            Focus on providing high-quality, verified information.
            Be VERY concise in your answers."""
        )
        
        research_agent = AzureAIAgent(
            client=client,
            definition=research_agent_definition,
            polling_options=RunPollingOptions(default_polling_interval=timedelta(milliseconds=3000)),
            plugins=[research_plugin]
        )
        agents['research'] = research_agent
        print(f"✅ Dr. Research: {research_agent_definition.id}")
        
        # 📊 Create Analytics Agent  
        print("📊 Creating Analytics Agent...")
        analytics_agent_definition = await client.agents.create_agent(
            model=model_deployment,
            name="prof_analytics",
            description="Brilliant data scientist and statistician",
            instructions="""You are Prof. Analytics, a brilliant data scientist and statistician.
            
            Your expertise:
            - Analyzing complex datasets and patterns
            - Creating statistical models and forecasts
            - Identifying trends and correlations
            - Providing data-driven insights and recommendations
            
            Always use your analytics plugins when working with data.
            Be precise with numbers and explain your analytical methodology.
            Focus on extracting actionable insights from information.
            Be VERY concise in your answers."""
        )
        
        analytics_agent = AzureAIAgent(
            client=client,
            definition=analytics_agent_definition,
            polling_options=RunPollingOptions(default_polling_interval=timedelta(milliseconds=3000)),
            plugins=[analytics_plugin]
        )
        agents['analytics'] = analytics_agent
        print(f"✅ Prof. Analytics: {analytics_agent_definition.id}")
        
        # 📝 Create Content Agent
        print("📝 Creating Content Agent...")
        content_agent_definition = await client.agents.create_agent(
            model=model_deployment,
            name="ms_content",
            description="Expert content creator and communication specialist",
            instructions="""You are Ms. Content, an expert content creator and communication specialist.
            
            Your expertise:
            - Creating clear, engaging, and well-structured content
            - Synthesizing complex information into readable formats
            - Writing reports, summaries, and presentations
            - Ensuring consistent tone and professional formatting
            
            Always use your content plugins when creating reports or summaries.
            Focus on clarity, readability, and professional presentation.
            Make complex information accessible to any audience.
            Be VERY concise in your answers."""
        )
        
        content_agent = AzureAIAgent(
            client=client,
            definition=content_agent_definition,
            polling_options=RunPollingOptions(default_polling_interval=timedelta(milliseconds=3000)),
            plugins=[content_plugin]
        )
        agents['content'] = content_agent
        print(f"✅ Ms. Content: {content_agent_definition.id}")
    
    print("🎭 Specialized Azure AI Agent team created!")
    print(f"🔍 Dr. Research: Information gathering specialist")
    print(f"📊 Prof. Analytics: Data analysis expert")
    print(f"📝 Ms. Content: Communication specialist")
    
    return agents

print("✅ Specialized Azure AI Agent creation function ready!")

# %% [markdown]
## 🔄 Sequential Orchestration: Pipeline Pattern

In sequential orchestration, Azure AI Agents work one after another in a pipeline:

**Research Agent** → **Analytics Agent** → **Content Agent** → **Final Result**

This pattern is perfect when:
- Each Azure AI Agent depends on the previous agent's output
- You need a step-by-step workflow
- Quality control at each stage is important

Let's implement a sequential workflow for creating a comprehensive market analysis report!

# %% [code]
def agent_response_callback(message: ChatMessageContent) -> None:
    """Callback function to monitor Azure AI Agent responses during orchestration."""
    if message.role != AuthorRole.TOOL:
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"\n[{timestamp}] 🤖 Azure AI Agent: {message.name}")
        print(f"📝 Response: {message.content[:200]}..." if len(str(message.content)) > 200 else f"📝 Response: {message.content}")
        print("─" * 60)

async def run_sequential_orchestration(topic: str):
    """Demonstrates sequential Azure AI Agent orchestration using Semantic Kernel's SequentialOrchestration."""
    
    print(f"🔄 Starting Sequential Azure AI Agent Orchestration for: {topic}")
    print(f"{'='*80}")
    
    # Create our specialized Azure AI Agent team
    agents = await create_specialized_agents()
    
    # Create the sequential orchestration with our Azure AI Agents
    # The agents will be executed in the order they are provided
    orchestration = SequentialOrchestration(
        members=[agents['research'], agents['analytics'], agents['content']],
        agent_response_callback=agent_response_callback
    )
    
    # Create and start the runtime
    runtime = InProcessRuntime()
    runtime.start()
    
    try:
        print(f"\n🎯 Sequential Pipeline: Research → Analytics → Content")
        print(f"{'─'*60}")
        
        # Create the task that will flow through the pipeline
        task = f"""Please analyze the topic '{topic}' comprehensively:
        
        Research Agent: Gather comprehensive information, key facts, and recent developments about {topic}.
        Analytics Agent: Analyze the research data, identify trends, and create projections.
        Content Agent: Synthesize all findings into a well-formatted executive report.
        
        Each agent should build upon the previous agent's work to create a comprehensive analysis.
        Be very concise in your responses, focusing on key insights and actionable recommendations."""
        
        # Invoke the sequential orchestration
        orchestration_result = await orchestration.invoke(
            task=task,
            runtime=runtime
        )
        
        # Wait for the results
        final_result = await orchestration_result.get(timeout=1200)
        
        print(f"\n✅ Sequential Azure AI Agent Orchestration Complete!")
        print(f"🎯 Final Result: Comprehensive {topic} analysis through sequential pipeline")
        print(f"\n📄 Final Report:\n{final_result}")
        
        return final_result
        
    finally:
        # Stop the runtime
        await runtime.stop_when_idle()
        print(f"\n🧹 Sequential orchestration cleanup complete.")

print("✅ Sequential Azure AI Agent orchestration function ready!")

# %% [code]
# Test Sequential Azure AI Agent Orchestration
sequential_topic = "Artificial Intelligence in Healthcare"

print(f"🚀 Testing Sequential Azure AI Agent Orchestration")
print(f"📋 Topic: {sequential_topic}")
print(f"⏱️ This will take a few moments as each Azure AI Agent works in sequence...")

start_time = time.time()
sequential_result = await run_sequential_orchestration(sequential_topic)
end_time = time.time()

print(f"\n⏱️ Sequential Azure AI Agent orchestration completed in {end_time - start_time:.2f} seconds")
print(f"\n🎉 Sequential Azure AI Agent Orchestration Success!")
print(f"📄 Generated comprehensive analysis with research, analytics, and professional formatting")

# %% [markdown]
## ⚡ Concurrent Orchestration: Parallel Pattern

In concurrent orchestration, multiple Azure AI Agents work simultaneously:

**Research Agent** ⟷ **Analytics Agent** ⟷ **Content Agent** → **Combine Results**

This pattern is perfect when:
- Azure AI Agents can work independently on different aspects
- Speed is important (parallel processing)
- Tasks don't depend on each other's outputs

Let's implement concurrent orchestration for rapid multi-perspective analysis!

# %% [code]
async def run_concurrent_orchestration(topic: str):
    """Demonstrates concurrent Azure AI Agent orchestration using Semantic Kernel's ConcurrentOrchestration."""
    
    print(f"⚡ Starting Concurrent Azure AI Agent Orchestration for: {topic}")
    print(f"{'='*80}")
    
    # Create our specialized Azure AI Agent team
    agents = await create_specialized_agents()
    
    # Create the concurrent orchestration with our Azure AI Agents
    # All agents will work on the same task simultaneously
    orchestration = ConcurrentOrchestration(
        members=[agents['research'], agents['analytics'], agents['content']]
    )
    
    # Create and start the runtime
    runtime = InProcessRuntime()
    runtime.start()
    
    try:
        print(f"\n🎯 All Azure AI Agents working simultaneously on: {topic}")
        print(f"{'─'*60}")
        
        # Create the task for all agents to work on concurrently
        task = f"""Analyze '{topic}' from your specialized perspective:
        
        Research Agent: Focus on current trends, recent innovations, and market dynamics in {topic}.
        Analytics Agent: Analyze market data, growth patterns, and create projections for {topic}.
        Content Agent: Create an engaging framework and structure for a {topic} report.
        
        Each agent should work independently and provide insights from your area of expertise.
        Be very concise in your responses, focusing on key insights and actionable recommendations."""
        
        # Invoke the concurrent orchestration
        orchestration_result = await orchestration.invoke(
            task=task,
            runtime=runtime
        )
        
        # Wait for all agents to complete their tasks
        results = await orchestration_result.get(timeout=1200)
        
        print(f"\n🎉 All Azure AI Agents completed their tasks!")
        print(f"{'─'*60}")
        
        # Display individual results
        print(f"\n📊 Concurrent Analysis Results:")
        for i, result in enumerate(results, 1):
            result_preview = str(result.content)[:200] + "..." if len(str(result.content)) > 200 else str(result.content)
            print(f"\n   🤖 {result.name}:")
            print(f"   📝 {result_preview}")
        
        # Combine results for final output
        combined_result = f"""
# Concurrent Analysis Results for {topic}

## Multi-Agent Parallel Analysis
Generated by concurrent orchestration of specialized Azure AI Agents

{chr(10).join([f"### {result.name} Insights:{chr(10)}{result.content}{chr(10)}" for result in results])}

---
*Generated through concurrent Azure AI Agent orchestration using Semantic Kernel*
"""
        
        print(f"\n✅ Concurrent Azure AI Agent Orchestration Complete!")
        print(f"🎯 Final Result: Multi-perspective {topic} analysis from parallel Azure AI Agent work")
        
        return combined_result
        
    finally:
        # Stop the runtime
        await runtime.stop_when_idle()
        print(f"\n🧹 Concurrent orchestration cleanup complete.")

print("✅ Concurrent Azure AI Agent orchestration function ready!")

# %% [code]
# Test Concurrent Azure AI Agent Orchestration
concurrent_topic = "Renewable Energy Technologies"

print(f"⚡ Testing Concurrent Azure AI Agent Orchestration")
print(f"📋 Topic: {concurrent_topic}")
print(f"🚀 All Azure AI Agents will work simultaneously for maximum speed!")

start_time = time.time()
concurrent_result = await run_concurrent_orchestration(concurrent_topic)
end_time = time.time()

print(f"\n⏱️ Concurrent Azure AI Agent orchestration completed in {end_time - start_time:.2f} seconds")
print(f"\n🎉 Concurrent Azure AI Agent Orchestration Success!")
print(f"📄 Generated multi-perspective analysis through parallel Azure AI Agent collaboration")

# %% [markdown]
## 🎯 Real-World Azure AI Agent Orchestration Scenarios

Let's explore practical scenarios where you'd use each orchestration pattern with Azure AI Agents:

### 🔄 Sequential Azure AI Agent Orchestration Use Cases:

1. **Document Processing Pipeline**
   - OCR Azure AI Agent → Text Analysis Azure AI Agent → Summary Azure AI Agent
   
2. **Financial Analysis Workflow**
   - Data Collection Azure AI Agent → Risk Analysis Azure AI Agent → Report Generation Azure AI Agent
   
3. **Software Development Pipeline**
   - Code Analysis Azure AI Agent → Testing Azure AI Agent → Documentation Azure AI Agent

### ⚡ Concurrent Azure AI Agent Orchestration Use Cases:

1. **Multi-Source Research**
   - News Azure AI Agent + Academic Azure AI Agent + Social Media Azure AI Agent → Combine Insights
   
2. **Customer Service Routing**
   - Intent Azure AI Agent + Sentiment Azure AI Agent + Priority Azure AI Agent → Route to Human
   
3. **Content Generation**
   - Text Azure AI Agent + Image Azure AI Agent + SEO Azure AI Agent → Multi-media Content

# %% [markdown]
## 🏆 Best Practices for Azure AI Agent Orchestration

### ✅ Design Principles:

1. **Azure AI Agent Specialization**
   - Give each Azure AI Agent a clear, focused role
   - Create specialized plugins for domain expertise
   - Write specific instructions for each Azure AI Agent

2. **Error Handling**
   - Always implement proper cleanup (Azure AI Agents are managed)
   - Handle agent failures gracefully
   - Provide fallback strategies

3. **Performance Optimization**
   - Use concurrent patterns for independent tasks
   - Use sequential patterns for dependent workflows
   - Monitor execution times and optimize bottlenecks

4. **Resource Management**
   - Azure AI Agents are managed by Azure (no manual cleanup needed)
   - Monitor Azure AI service usage and costs
   - Implement timeouts for long-running operations

### 🔒 Security Considerations:

1. **Data Privacy**
   - Don't log sensitive information
   - Implement data retention policies
   - Use secure communication between Azure AI Agents

2. **Access Control**
   - Use DefaultAzureCredential for secure authentication
   - Limit Azure AI Agent permissions appropriately
   - Validate all inputs to plugins
   - Monitor Azure AI Agent activities

### 📊 Monitoring and Debugging:

1. **Logging**
   - Log Azure AI Agent interactions and decisions
   - Track execution times and performance metrics
   - Monitor plugin function calls

2. **Testing**
   - Test individual Azure AI Agents before orchestration
   - Test orchestration patterns with various scenarios
   - Implement automated testing for critical workflows

# %% [markdown]
## 🚀 Advanced Semantic Kernel Orchestration Features

Semantic Kernel provides powerful additional features for orchestration beyond basic sequential and concurrent patterns:

### 🔧 Advanced Capabilities:

1. **Cancellation Support** 🛑
   - Cancel orchestrations that are taking too long
   - Graceful handling of cancelled operations
   - Timeout management

2. **Structured Outputs** 📋  
   - Get results in predefined data structures
   - Type-safe orchestration results
   - JSON schema validation

3. **Agent Response Callbacks** 👂
   - Monitor agent interactions in real-time
   - Log and debug orchestration flows
   - Custom response processing

4. **Runtime Management** ⚙️
   - InProcessRuntime for local orchestration
   - Efficient resource management
   - Automatic cleanup

Let's explore these advanced features!

# %% [code]
async def demonstrate_advanced_features():
    """Demonstrate advanced Semantic Kernel orchestration features with Azure AI Agents."""
    
    print("🚀 Advanced Azure AI Agent Orchestration Features Demo")
    print("="*50)
    
    # Create Azure AI Agents for demonstration
    agents = await create_specialized_agents()
    
    # 1. Demonstrate Agent Response Callback with Enhanced Monitoring
    print("\n👂 1. Enhanced Azure AI Agent Response Monitoring Demo")
    print("-" * 40)
    
    def detailed_callback(message: ChatMessageContent) -> None:
        """Enhanced callback with comprehensive details."""
        if message.role != AuthorRole.TOOL:
            timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]  # Include milliseconds
            print(f"\n[{timestamp}] 🤖 Azure AI Agent Response:")
            print(f"    📛 Name: {message.name}")
            print(f"    📝 Content Length: {len(message.content)} characters")
            print(f"    🔤 Content Preview: {message.content[:150]}{'...' if len(str(message.content)) > 150 else ''}")
            if hasattr(message, 'metadata') and message.metadata:
                print(f"    📊 Metadata: {message.metadata}")
            print("    " + "─" * 50)
    
    # Create a sequential orchestration with detailed monitoring
    monitored_orchestration = SequentialOrchestration(
        members=[agents['research']],  # Just one agent for demo
        agent_response_callback=detailed_callback
    )
    
    runtime = InProcessRuntime()
    runtime.start()
    
    try:
        print("🎯 Running monitored Azure AI Agent orchestration...")
        result = await monitored_orchestration.invoke(
            task="Provide a brief overview of renewable energy trends focusing on solar power adoption",
            runtime=runtime
        )
        
        final_result = await result.get(timeout=1200)
        print(f"\n✅ Monitored Azure AI Agent orchestration completed!")
        print(f"📄 Final Result Length: {len(str(final_result))} characters")
        
    except Exception as e:
        print(f"❌ Error in monitored orchestration: {e}")
        
    finally:
        await runtime.stop_when_idle()
    
    # 2. Demonstrate Timeout and Error Handling
    print("\n⏰ 2. Timeout and Error Handling Demo")
    print("-" * 40)
    
    quick_orchestration = SequentialOrchestration(
        members=[agents['analytics'], agents['content']],
        agent_response_callback=agent_response_callback
    )
    
    runtime2 = InProcessRuntime()
    runtime2.start()
    
    try:
        print("🎯 Testing timeout handling (using very short timeout for demo)...")
        result = await quick_orchestration.invoke(
            task="Analyze quantum computing market potential and create executive summary",
            runtime=runtime2
        )
        
        # Use a very short timeout to demonstrate timeout handling
        try:
            final_result = await result.get(timeout=2)  # Very short timeout for demo
            print(f"✅ Completed within timeout!")
        except asyncio.TimeoutError:
            print(f"⏰ Operation timed out as expected (demo timeout was very short)")
        except Exception as e:
            print(f"❌ Other error: {type(e).__name__}: {e}")
            
    finally:
        await runtime2.stop_when_idle()
    
    # 3. Demonstrate Concurrent with Multiple Specialized Tasks
    print("\n⚡ 3. Advanced Concurrent Azure AI Agent Orchestration Demo")
    print("-" * 40)
    
    concurrent_orchestration = ConcurrentOrchestration(
        members=[agents['research'], agents['analytics'], agents['content']]
    )
    
    runtime3 = InProcessRuntime()
    runtime3.start()
    
    try:
        print("🎯 Running advanced concurrent Azure AI Agent orchestration...")
        
        advanced_task = """Analyze 'Artificial Intelligence in Education' with each Azure AI Agent focusing on different aspects:
        
        Research Agent: Focus on current AI educational tools, case studies, and adoption rates in schools/universities.
        Analytics Agent: Analyze the effectiveness data, ROI metrics, and performance improvements from AI in education.
        Content Agent: Create a framework for an implementation guide for educational institutions considering AI adoption.
        
        Provide comprehensive insights from your specialized perspective."""
        
        result = await concurrent_orchestration.invoke(
            task=advanced_task,
            runtime=runtime3
        )
        
        results = await result.get(timeout=1200)
        
        print(f"\n🎉 Advanced concurrent Azure AI Agent orchestration completed!")
        print(f"📊 Generated {len(str(results))} specialized responses")
        
        for i, response in enumerate(results, 1):
            print(f"\n   🤖 Azure AI Agent {i} ({response.name}):")
            preview = response.content[:100] + "..." if len(str(response.content)) > 100 else response.content
            print(f"   📝 {preview}")
            
    except Exception as e:
        print(f"❌ Error in advanced concurrent orchestration: {e}")
        
    finally:
        await runtime3.stop_when_idle()
    
    print("\n🎉 Advanced Azure AI Agent features demonstration complete!")
    print("💡 Key takeaways:")
    print("   ✅ Agent response callbacks provide real-time monitoring")
    print("   ✅ Proper timeout handling prevents hung operations")
    print("   ✅ Both sequential and concurrent patterns work with advanced features")
    print("   ✅ Semantic Kernel provides robust Azure AI Agent orchestration infrastructure")

print("✅ Advanced Azure AI Agent features demo function ready!")


await demonstrate_advanced_features()

################################################################################  03-orchestrated-agents\03.2-connected_agents_tutorial.ipynb  ################################################################################
# %% [markdown]
# Connected Agents Tutorial

🤝 **Learn how to create connected agents that work together!**

This tutorial demonstrates:
1. **Part 1: Azure AI Foundry SDK** - Connected agents using built-in tools
2. **Part 2: Semantic Kernel SDK** - Multi-agent orchestration

**Connected agents** allow multiple specialized AI agents to collaborate and share information to solve complex tasks.

---

# %% [markdown]
## 🔧 Setup and Prerequisites

**Environment Variables Required:**
- `PROJECT_ENDPOINT`: Your Azure AI Project endpoint
- `MODEL_DEPLOYMENT_NAME`: Your deployed AI model name

**For Semantic Kernel:**
- `AZURE_OPENAI_ENDPOINT`: Your Azure OpenAI endpoint
- `AZURE_OPENAI_API_KEY`: Your Azure OpenAI API key
- `AZURE_OPENAI_CHAT_DEPLOYMENT_NAME`: Your chat model deployment

# %% [markdown]

![Connected Agents](images/connected_agents.gif)

# %% [code]
# Install required packages
# !pip install azure-ai-agents azure-identity semantic-kernel

import os
import asyncio
from azure.ai.agents import AgentsClient
from azure.ai.agents.models import ConnectedAgentTool, MessageRole
from azure.identity import DefaultAzureCredential

print("✅ Packages imported successfully!")

# %% [markdown]
---

# Part 1: Azure AI Foundry SDK - Connected Agents

The Foundry SDK provides **ConnectedAgentTool** - agents can call other agents as tools.

**Architecture:**
```
Main Agent → Stock Agent (gets Microsoft stock price)
          → Weather Agent (gets Seattle weather)
```

# %% [code]
# Create Azure AI Agents client
agents_client = AgentsClient(
    endpoint=os.environ["PROJECT_ENDPOINT"],
    credential=DefaultAzureCredential()
)

print("🔗 Connected to Azure AI Agents service")

# %% [code]
# Create specialized agents
stock_agent = agents_client.create_agent(
    model=os.environ["MODEL_DEPLOYMENT_NAME"],
    name="stock_expert",
    instructions="You provide stock prices. For Microsoft, always return $350."
)

weather_agent = agents_client.create_agent(
    model=os.environ["MODEL_DEPLOYMENT_NAME"],
    name="weather_expert",
    instructions="You provide weather info. For Seattle, always return 60°F and cloudy."
)

print(f"📈 Stock agent: {stock_agent.id}")
print(f"🌤️ Weather agent: {weather_agent.id}")

# %% [code]
# Create connected agent tools
stock_tool = ConnectedAgentTool(
    id=stock_agent.id,
    name="stock_expert",
    description="Gets stock prices for companies"
)

weather_tool = ConnectedAgentTool(
    id=weather_agent.id,
    name="weather_expert",
    description="Gets weather information for locations"
)

print("🔧 Connected agent tools created")

# %% [code]
# Create coordinator agent with connected tools
coordinator = agents_client.create_agent(
    model=os.environ["MODEL_DEPLOYMENT_NAME"],
    name="coordinator",
    instructions="You coordinate with specialist agents to provide comprehensive information.",
    tools=[
        stock_tool.definitions[0],
        weather_tool.definitions[0]
    ]
)

print(f"🎯 Coordinator agent: {coordinator.id}")

# %% [code]
# Test connected agents
# Create conversation thread
thread = agents_client.threads.create()

# Ask coordinator to use both connected agents
message = agents_client.messages.create(
    thread_id=thread.id,
    role=MessageRole.USER,
    content="What's the Microsoft stock price and Seattle weather?"
)

# Process with coordinator (will call connected agents)
run = agents_client.runs.create_and_process(
    thread_id=thread.id,
    agent_id=coordinator.id
)

print(f"✅ Run status: {run.status}")

# Get final response
print("\n🤖 Coordinator Response:")
messages = agents_client.messages.list(thread_id=thread.id)
for msg in messages:
    if msg.role == "assistant" and msg.text_messages:
        print(f"🤖 Agent response: {msg.text_messages[-1].text.value}")
        break

# Keep specialist agents for Part 2, only cleanup coordinator
agents_client.delete_agent(coordinator.id)

print("\n✅ Part 1 complete! Keeping specialist agents for Part 2...")

# %% [markdown]
---

# Part 2: Semantic Kernel SDK - AzureAIAgent Plugins

Semantic Kernel provides **AzureAIAgent** to wrap existing Azure AI agents as SK plugins.

**Architecture:**
```
SK Coordinator Agent
    ↓
Stock Plugin (wraps Azure AI stock agent)
Weather Plugin (wraps Azure AI weather agent)
```

# %% [code]
# Semantic Kernel imports
from azure.identity.aio import DefaultAzureCredential as AsyncDefaultAzureCredential
from semantic_kernel import Kernel
from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings, ChatCompletionAgent
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
from semantic_kernel.functions import kernel_function
from typing import Annotated

print("📚 Semantic Kernel imports loaded")

# %% [code]
# Create Azure OpenAI service for SK coordinator
service = AzureChatCompletion()

print("🔗 Azure OpenAI service configured")

# %% [code]
# Create AzureAIAgent wrappers and SK coordinator
async def create_sk_coordinator():
    endpoint = os.environ["PROJECT_ENDPOINT"]

    async with (
        AsyncDefaultAzureCredential() as creds,
        AzureAIAgent.create_client(credential=creds, endpoint=endpoint) as sk_client,
    ):
        print("🔗 Creating SK client and agent wrappers...")
        
        # Wrap existing Azure AI agents as AzureAIAgents
        stock_sk_agent = AzureAIAgent(
            client=sk_client,
            definition=stock_agent  # Use the agent from Part 1
        )
        
        weather_sk_agent = AzureAIAgent(
            client=sk_client,
            definition=weather_agent  # Use the agent from Part 1
        )
        
        print("🎯 Azure AI agents wrapped as SK plugins")
        
        # Create kernel and add plugins
        kernel = Kernel()
        kernel.add_plugin(stock_sk_agent, "stock")
        kernel.add_plugin(weather_sk_agent, "weather")
        
        # Create SK coordinator agent with plugins
        coordinator_sk = ChatCompletionAgent(
            name="SKCoordinator",
            instructions="You coordinate information using available functions. Call stock functions for stock data and weather functions for weather data.",
            service=service,
            kernel=kernel
        )
        
        # Test the coordination
        print("\n🧪 Testing SK coordinator with Azure AI agent plugins...")
        
        user_input = "Get me Microsoft's stock price and Seattle's weather"
        print(f"👤 User: {user_input}")
        
        async for response in coordinator_sk.invoke(user_input):
            print(f"🤖 SK Coordinator: {response.content}")
            final_response = response.content
        
        return final_response

# Run the SK coordination
result = await create_sk_coordinator()
print("\n✅ Semantic Kernel coordination with Azure AI agents complete!")

# %% [code]
# Final cleanup - delete the remaining Azure AI agents
agents_client.delete_agent(stock_agent.id)
agents_client.delete_agent(weather_agent.id)

print("🧹 All Azure AI agents cleaned up")

# %% [markdown]
---

## 🔄 Comparison: Connected Agents vs AzureAI Plugins

| Aspect | Foundry SDK (Connected) | Semantic Kernel (AzureAI Plugins) |
|--------|-------------------------|-----------------------------------|
| **Connection** | Agent calls other agents as tools | Azure AI agents wrapped as SK plugins |
| **Flow** | Tool-based invocation | Plugin function calls |
| **Use Case** | Task delegation | Hybrid SK + Azure AI coordination |
| **Complexity** | Simple, direct calls | SK orchestration with Azure AI power |
| **Context** | Limited to tool parameters | SK context + Azure AI capabilities |

### When to Use Each:

**🔗 Connected Agents (Foundry SDK):**
- Pure Azure AI agent coordination
- Simple task delegation
- Real-time tool usage

**🔌 AzureAI Plugins (Semantic Kernel):**
- Hybrid SK + Azure AI workflows
- Rich SK orchestration features
- Leverage existing Azure AI agents in SK

# %% [markdown]
---

## 🎯 Key Takeaways

✅ **Connected Agents (Foundry SDK):**
- Use `ConnectedAgentTool` for agent-to-agent communication
- Perfect for specialized function delegation
- Built-in tool management

✅ **AzureAI Plugins (Semantic Kernel):**
- Use `AzureAIAgent` to wrap existing Azure AI agents
- Leverage SK's rich plugin system
- Combine Azure AI power with SK orchestration

✅ **Both Approaches:**
- Enable agent specialization
- Improve task decomposition
- Scale complex AI solutions
- Reuse existing Azure AI agents

**🚀 Next Steps:**
- Experiment with different plugin patterns
- Try combining multiple Azure AI agents in SK
- Explore hybrid workflows with both SDKs

**Happy agent orchestrating!** 🎉

################################################################################  03-orchestrated-agents\README.md  ################################################################################
# Orchestrated Agents

Learn how to coordinate multiple agents to solve complex problems. This is where individual agents become a powerful team.

## What's In This Folder

**[03.1 - Concurrent and Sequential Orchestration](03.1-concurrent_and_sequential_orchestration_tutorial.ipynb)**
Master different orchestration patterns using Semantic Kernel. Build specialized agent teams that work in pipelines or in parallel to handle complex tasks.

**Sequential Orchestration**: Agents work in a pipeline (Agent A → Agent B → Agent C)
![Sequential Orchestration](images/sequential_orchestration.gif)

**Concurrent Orchestration**: Agents work in parallel (A + B + C → Combine)
![Concurrent Orchestration](images/concurrent_orchestration.gif)

**[03.2 - Connected Agents](03.2-connected_agents_tutorial.ipynb)**
Learn different approaches to agent communication. Compare Azure AI Foundry's ConnectedAgentTool with Semantic Kernel's AzureAIAgent plugins.

![Connected Agents](images/connected_agents.gif)

## Learning Path

1. **Start with 03.1** - Master orchestration patterns with specialized teams
2. **Move to 03.2** - Learn agent connectivity approaches

**Prerequisites**: Complete [01-agent-basics](../01-agent-basics/) and [02-agent-custom-functions](../02-agent-custom-functions/).

## Prerequisites

### Previous Knowledge
- Complete [01-agent-basics](../01-agent-basics/) and [02-agent-custom-functions](../02-agent-custom-functions/) tutorials
- Understanding of async/await patterns in Python

### Azure Resources
- Azure subscription
- Azure AI Foundry project
- Deployed AI model (GPT-4, GPT-3.5-turbo, etc.)
- Azure OpenAI resource (for Semantic Kernel scenarios)

### Environment Setup
- Python 3.8+
- Jupyter Notebook or VS Code

### Environment Variables
Configure your Azure AI services in the `.env` file at the project root:

```bash
# Navigate to the project root and edit the .env file
cd ../../  # Go to azure-ai-agents-playbook root
```

Update the `.env` file with your Azure AI project details:
```properties
# Required for all tutorials
PROJECT_ENDPOINT="https://your-foundry-resource.services.ai.azure.com/api/projects/your-project-name"
MODEL_DEPLOYMENT_NAME="your-model-deployment-name"

# Required for Semantic Kernel orchestration (03.1)
AZURE_OPENAI_API_KEY="your-azure-openai-api-key"
AZURE_OPENAI_ENDPOINT="https://your-openai-resource.openai.azure.com/"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME="your-chat-deployment"
AZURE_OPENAI_DEPLOYMENT_NAME="your-deployment-name"
AZURE_OPENAI_API_VERSION="2024-12-01-preview"

# Optional: For advanced scenarios
AZURE_SUBSCRIPTION_ID="your-subscription-id"
```

**Tip**: The `.env` file already exists in the project root with example values - just update it with your details.

### Required Packages
Install the packages you need:

```bash
pip install azure-ai-agents azure-identity semantic-kernel python-dotenv
```

## What You'll Learn

### Orchestration Patterns

**Sequential Orchestration (Pipeline)**
- Flow: Agent A → Agent B → Agent C
- Best for: Document processing, analysis workflows, step-by-step procedures
- Example: Research Agent → Analytics Agent → Content Agent

**Concurrent Orchestration (Parallel)**
- Flow: Agent A + Agent B + Agent C → Combine Results
- Best for: Independent tasks, multi-source research, parallel processing
- Example: Multiple research agents gathering different data sources

**Hybrid Patterns**
- Mix of sequential and concurrent patterns for complex workflows

### Agent Connectivity

**Connected Agents (Foundry SDK)**
- Use ConnectedAgentTool for agent-to-agent communication
- Direct delegation and simple coordination

**AzureAI Plugins (Semantic Kernel)**
- Wrap Azure AI agents as Semantic Kernel plugins
- Rich orchestration features and advanced patterns

### What You'll Build
- Research + Analytics + Content Pipeline (sequential workflow)
- Multi-Perspective Analysis System (concurrent agents)
- Specialized Agent Network (domain experts working together)

## Next Steps

After mastering orchestration:
- [04-orchestrated-agents-with-tools](../04-orchestrated-agents-with-tools/) - External API integration
- [05-orchestrated-agents-with-custom-openapi-tools](../05-orchestrated-agents-with-custom-openapi-tools/) - Custom API services

################################################################################  04-orchestrated-agents-with-tools\04.1-openapi_currency_exchange_tutorial.ipynb  ################################################################################
# %% [markdown]
# OpenAPI Currency Exchange Tutorial

💱 **Learn how to use OpenAPI tools with Azure AI Agents for currency exchange!**

This tutorial demonstrates:
1. **Part 1: Azure AI Foundry SDK** - Using OpenAPI tools for currency exchange
2. **Part 2: Semantic Kernel SDK** - Azure AI Agents with OpenAPI tools

**OpenAPI tools** allow agents to call external APIs defined by OpenAPI specifications.

---

# %% [markdown]
## 🔧 Setup and Prerequisites

**Environment Variables Required:**
- `PROJECT_ENDPOINT`: Your Azure AI Project endpoint
- `MODEL_DEPLOYMENT_NAME`: Your deployed AI model name

**For Semantic Kernel:**
- `AZURE_OPENAI_ENDPOINT`: Your Azure OpenAI endpoint
- `AZURE_OPENAI_API_KEY`: Your Azure OpenAI API key
- `AZURE_OPENAI_CHAT_DEPLOYMENT_NAME`: Your chat model deployment

# %% [markdown]
![Azure Tools](images/azure_tools.gif)

# %% [code]
# Install required packages
# !pip install azure-ai-agents azure-identity semantic-kernel

import os
import json
import json
from azure.ai.agents import AgentsClient
from azure.ai.agents.models import OpenApiTool, OpenApiAnonymousAuthDetails, MessageRole
from azure.identity import DefaultAzureCredential

print("✅ Packages imported successfully!")

# %% [markdown]
---

# Part 1: Azure AI Foundry SDK - OpenAPI Currency Exchange

The Foundry SDK provides **OpenApiTool** to call external APIs from agent responses.

**Architecture:**
```
Agent → OpenAPI Tool → Frankfurter API (currency exchange)
```

# %% [code]
# Load the currency exchange OpenAPI specification
currency_spec_path = os.path.join("openapi_files", "currency_exchange.json")

with open(currency_spec_path, "r") as f:
    currency_openapi_spec = json.loads(f.read())

print("📊 Currency exchange OpenAPI spec loaded")
print(f"API Title: {currency_openapi_spec['info']['title']}")
print(f"API Version: {currency_openapi_spec['info']['version']}")

# %% [code]
# Create Azure AI Agents client
agents_client = AgentsClient(
    endpoint=os.environ["PROJECT_ENDPOINT"],
    credential=DefaultAzureCredential()
)

print("🔗 Connected to Azure AI Agents service")

# %% [code]
# Create OpenAPI tool for currency exchange
auth = OpenApiAnonymousAuthDetails()

currency_tool = OpenApiTool(
    name="currency_exchange",
    spec=currency_openapi_spec,
    description="Get the latest foreign exchange rates from Frankfurter API",
    auth=auth
)

print("💱 Currency exchange OpenAPI tool created")
print(f"Available operations: {len(currency_tool.definitions)}")

# %% [code]
# Create agent with OpenAPI tool
currency_agent = agents_client.create_agent(
    model=os.environ["MODEL_DEPLOYMENT_NAME"],
    name="currency_exchange_agent",
    instructions="You are a helpful currency exchange agent. Use the currency exchange API to get latest exchange rates. Always provide clear explanations of the rates.",
    tools=currency_tool.definitions
)

print(f"💰 Currency exchange agent created: {currency_agent.id}")

# %% [code]
# Test the currency exchange agent
# Create conversation thread
thread = agents_client.threads.create()
print(f"💬 Thread created: {thread.id}")

# Ask about exchange rates
message = agents_client.messages.create(
    thread_id=thread.id,
    role=MessageRole.USER,
    content="What is the current USD to EUR exchange rate? Also show me USD to GBP and USD to JPY."
)

# Process the request
run = agents_client.runs.create_and_process(
    thread_id=thread.id,
    agent_id=currency_agent.id
)

print(f"✅ Run status: {run.status}")

if run.status == "failed":
    print(f"❌ Run failed: {run.last_error}")

# Display the response
messages = agents_client.messages.list(thread_id=thread.id)
for msg in messages:
    if msg.role == "assistant" and msg.text_messages:
        print(f"\n💱 Currency Agent Response:")
        print(msg.text_messages[-1].text.value)
        break

# %% [code]
# Test with different base currency
# Create new message in same thread
message2 = agents_client.messages.create(
    thread_id=thread.id,
    role=MessageRole.USER,
    content="Now show me EUR to USD, EUR to GBP, and EUR to CHF exchange rates."
)

# Process the request
run2 = agents_client.runs.create_and_process(
    thread_id=thread.id,
    agent_id=currency_agent.id
)

print(f"✅ Second run status: {run2.status}")

# Display the latest response
messages = agents_client.messages.list(thread_id=thread.id)
print(f"\n💱 Currency Agent Response (EUR base):")
for msg in messages:
    if msg.role == "assistant" and msg.text_messages:
        print(msg.text_messages[-1].text.value)
        break

# %% [markdown]
---

# Part 2: Semantic Kernel SDK - Azure AI Agent with OpenAPI Tools

Semantic Kernel provides **AzureAIAgent** to wrap Azure AI agents with OpenAPI tools.

**Architecture:**
```
Semantic Kernel
    ↓
AzureAIAgent (wraps Azure AI agent with OpenAPI tools)
    ↓
Frankfurter API (currency exchange)
```

# %% [code]
# Semantic Kernel imports
import asyncio
from azure.identity.aio import DefaultAzureCredential as AsyncDefaultAzureCredential
from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings
from semantic_kernel.contents import AuthorRole

print("📚 Semantic Kernel imports loaded")

# %% [code]
# Create Azure AI Agent with OpenAPI tools using Semantic Kernel
async def create_sk_currency_agent():
    endpoint = os.environ["PROJECT_ENDPOINT"]
    model_deployment = os.environ["MODEL_DEPLOYMENT_NAME"]

    async with (
        AsyncDefaultAzureCredential() as creds,
        AzureAIAgent.create_client(credential=creds, endpoint=endpoint) as sk_client,
    ):
        print("🔗 Creating SK Azure AI Agent with OpenAPI tools...")
        
        # Create Azure AI agent with OpenAPI tool using SK
        agent_definition = await sk_client.agents.create_agent(
            model=model_deployment,
            name="sk_currency_agent",
            instructions="You are an expert currency exchange assistant. Use the currency exchange API to provide accurate, up-to-date exchange rates. Always explain the rates clearly and provide context.",
            tools=currency_tool.definitions
        )
        
        # Wrap as AzureAIAgent
        sk_currency_agent = AzureAIAgent(
            client=sk_client,
            definition=agent_definition
        )
        
        print(f"💰 SK Currency agent created: {agent_definition.id}")
        
        # Test queries
        test_queries = [
            "What's the current exchange rate from USD to THB (Thai Baht)? I'm planning a trip to Thailand.",
            "Show me how much 1000 USD would be worth in EUR, GBP, and CAD today."
        ]
        
        thread = None
        
        try:
            for i, query in enumerate(test_queries, 1):
                print(f"\n🧪 Test Query {i}:")
                print(f"👤 User: {query}")
                
                # Invoke the agent
                async for response in sk_currency_agent.invoke(messages=query, thread=thread):
                    if response.role != AuthorRole.TOOL:
                        print(f"💱 SK Currency Agent: {response.content}")
                    thread = response.thread
        
        finally:
            # Cleanup
            if thread:
                await sk_client.agents.threads.delete(thread.id)
            await sk_client.agents.delete_agent(agent_definition.id)
            print("\n🧹 SK agent cleaned up")

# Run the SK currency agent
await create_sk_currency_agent()
print("\n✅ Semantic Kernel Azure AI Agent with OpenAPI complete!")

# %% [code]
# Final cleanup - delete the Foundry SDK agent
agents_client.delete_agent(currency_agent.id)
print("🧹 All agents cleaned up")

# %% [markdown]
---

## 🔄 Comparison: Foundry SDK vs Semantic Kernel OpenAPI

| Aspect | Foundry SDK | Semantic Kernel (AzureAI) |
|--------|-------------|---------------------------|
| **Setup** | Direct OpenApiTool creation | Azure AI agent with OpenAPI tools |
| **Agent Type** | Native Azure AI agent | AzureAIAgent wrapper |
| **API Calls** | Built-in tool execution | SK orchestration + Azure AI power |
| **Response** | Direct agent response | SK streaming with tool filtering |
| **Context** | Thread-based conversation | SK thread management |

### When to Use Each:

**⚙️ Foundry SDK:**
- Direct Azure AI agent usage
- Simple OpenAPI tool integration
- Native Azure AI features

**🔌 Semantic Kernel:**
- Rich SK orchestration features
- Complex agent workflows
- Leverage existing Azure AI agents in SK pipelines

# %% [markdown]
---

## 💱 OpenAPI Currency Exchange Features

### 🌍 Frankfurter API Capabilities:
- **Real-time rates**: Latest foreign exchange rates
- **Multiple currencies**: 30+ supported currencies
- **Base currency**: Configure any currency as base
- **Free access**: No API key required

### 🔧 OpenAPI Tool Benefits:
- **Auto-discovery**: Agents understand API capabilities
- **Type safety**: OpenAPI schema validation
- **Documentation**: Built-in API documentation
- **Flexibility**: Easy to add new APIs

### 💡 Best Practices:
✅ **Always validate** OpenAPI specifications  
✅ **Handle errors** gracefully in agent instructions  
✅ **Use descriptive** tool names and descriptions  
✅ **Test thoroughly** with different currencies  
✅ **Consider rate limits** for production usage  

# %% [markdown]
---

## 🎯 Key Takeaways

✅ **OpenAPI Tools (Both SDKs):**
- Enable agents to call external APIs
- Use OpenAPI specifications for auto-discovery
- Support various authentication methods

✅ **Foundry SDK:**
- Use `OpenApiTool` for direct API integration
- Perfect for straightforward API calls
- Built-in Azure AI agent capabilities

✅ **Semantic Kernel:**
- Use `AzureAIAgent` for enhanced orchestration
- Leverage SK's streaming and filtering
- Combine with other SK features

**🚀 Next Steps:**
- Try with your own OpenAPI specifications
- Experiment with authenticated APIs
- Combine multiple OpenAPI tools in one agent
- Explore rate limiting and error handling

**Happy API integrating!** 🎉

################################################################################  04-orchestrated-agents-with-tools\04.2-hybrid_openapi_and_plugins_tutorial.ipynb  ################################################################################
# %% [markdown]
# 🏦💱 Hybrid OpenAPI Tools + Semantic Kernel Plugins Tutorial

**🚀 Learn how to combine OpenAPI tools with Semantic Kernel plugins for powerful Azure AI Agents!**

This tutorial demonstrates:
1. **OpenAPI Tools** - External currency exchange API
2. **Semantic Kernel Plugins** - Local banking functions
3. **Hybrid Agent** - Combining both for rich conversational experiences

**Real-world scenario:** A banking assistant that can:
- 💰 Check account balances and transactions
- 💱 Get current exchange rates
- 🌍 Calculate international transfer amounts
- 📊 Provide financial insights combining local and external data

---

# %% [markdown]
## 🔧 Setup and Prerequisites

**Environment Variables Required:**
- `PROJECT_ENDPOINT`: Your Azure AI Project endpoint
- `MODEL_DEPLOYMENT_NAME`: Your deployed AI model name

**Architecture Overview:**
```
Azure AI Agent
    ├── OpenAPI Tool → Frankfurter API (currency exchange)
    └── SK Plugins
            ├── BankingPlugin → get_account_balances()
            └── TransactionPlugin → get_recent_transactions()
```

# %% [markdown]
![SK Plugins](images/sk_plugins.gif)

# %% [code]
# Install required packages
# !pip install azure-ai-agents azure-identity semantic-kernel

import os
import json
from typing import Annotated
from datetime import datetime, timedelta

# Azure AI Agents imports
from semantic_kernel import Kernel
from semantic_kernel.filters import AutoFunctionInvocationContext, FilterTypes
from azure.ai.agents import AgentsClient
from azure.ai.agents.models import OpenApiTool, OpenApiAnonymousAuthDetails
from azure.identity import DefaultAzureCredential
from azure.identity.aio import DefaultAzureCredential as AsyncDefaultAzureCredential

# Semantic Kernel imports
from semantic_kernel.agents import AzureAIAgent
from semantic_kernel.functions import kernel_function
from semantic_kernel.contents import AuthorRole

print("✅ All packages imported successfully!")

# %% [markdown]
---

# Part 1: Sample Banking Data

Let's start by setting up our sample banking data that our plugins will use.

# %% [code]
# Sample bank accounts data
SAMPLE_ACCOUNTS = [
    {
        "account_id": "acc_001",
        "account_name": "Checking Account",
        "account_type": "checking",
        "currency": "USD",
        "balance": 6233.59,
        "available_balance": 6233.59
    },
    {
        "account_id": "acc_002",
        "account_name": "Savings Account",
        "account_type": "savings",
        "currency": "USD",
        "balance": 15750.00,
        "available_balance": 15750.00
    },
    {
        "account_id": "acc_003",
        "account_name": "EUR Travel Account",
        "account_type": "checking",
        "currency": "EUR",
        "balance": 2500.00,
        "available_balance": 2500.00
    }
]

# Sample transaction data
SAMPLE_TRANSACTIONS = [
    {
        "id": "txn_001",
        "account_id": "acc_001",
        "date": "2024-12-01",
        "description": "Grocery Store Purchase",
        "amount": -85.47,
        "balance": 2914.53,
        "category": "Food & Dining"
    },
    {
        "id": "txn_002",
        "account_id": "acc_001",
        "date": "2024-12-02",
        "description": "Salary Deposit",
        "amount": 3500.00,
        "balance": 6414.53,
        "category": "Income"
    },
    {
        "id": "txn_003",
        "account_id": "acc_001",
        "date": "2024-12-03",
        "description": "Gas Station",
        "amount": -45.20,
        "balance": 6369.33,
        "category": "Transportation"
    },
    {
        "id": "txn_004",
        "account_id": "acc_001",
        "date": "2024-12-04",
        "description": "Online Shopping",
        "amount": -129.99,
        "balance": 6239.34,
        "category": "Shopping"
    },
    {
        "id": "txn_005",
        "account_id": "acc_001",
        "date": "2024-12-05",
        "description": "Coffee Shop",
        "amount": -5.75,
        "balance": 6233.59,
        "category": "Food & Dining"
    },
    {
        "id": "txn_006",
        "account_id": "acc_002",
        "date": "2024-12-01",
        "description": "Interest Payment",
        "amount": 25.00,
        "balance": 15750.00,
        "category": "Income"
    },
    {
        "id": "txn_007",
        "account_id": "acc_003",
        "date": "2024-11-28",
        "description": "Paris Hotel",
        "amount": -150.00,
        "balance": 2500.00,
        "category": "Travel"
    }
]

print("📊 Sample banking data loaded:")
print(f"   - {len(SAMPLE_ACCOUNTS)} accounts")
print(f"   - {len(SAMPLE_TRANSACTIONS)} transactions")
print(f"   - Total USD balance: ${sum(acc['balance'] for acc in SAMPLE_ACCOUNTS if acc['currency'] == 'USD'):,.2f}")

# %% [markdown]
---

# Part 2: Create Semantic Kernel Banking Plugins

Now we'll create two Semantic Kernel plugins that provide banking functionality:
1. **BankingPlugin** - Account balances and summaries
2. **TransactionPlugin** - Transaction history and analysis

# %% [code]
class BankingPlugin:
    """Banking plugin that provides account balance and summary information."""
    
    @kernel_function(
        description="Get all account balances for the user"
    )
    def get_account_balances(self) -> Annotated[str, "Returns account balances in JSON format"]:
        """Get current balances for all user accounts."""
        balance_info = []
        total_usd = 0
        
        for account in SAMPLE_ACCOUNTS:
            balance_info.append({
                "account_name": account["account_name"],
                "account_type": account["account_type"],
                "currency": account["currency"],
                "balance": account["balance"],
                "available_balance": account["available_balance"]
            })
            
            # Sum USD accounts for total
            if account["currency"] == "USD":
                total_usd += account["balance"]
        
        result = {
            "accounts": balance_info,
            "summary": {
                "total_accounts": len(SAMPLE_ACCOUNTS),
                "total_usd_balance": total_usd
            }
        }
        
        return json.dumps(result, indent=2)
    
    @kernel_function(
        description="Get balance for a specific account by name or type"
    )
    def get_specific_account_balance(
        self, 
        account_identifier: Annotated[str, "Account name or type (e.g., 'checking', 'savings', 'EUR Travel Account')"]
    ) -> Annotated[str, "Returns specific account balance information"]:
        """Get balance for a specific account."""
        identifier_lower = account_identifier.lower()
        
        for account in SAMPLE_ACCOUNTS:
            if (identifier_lower in account["account_name"].lower() or 
                identifier_lower == account["account_type"].lower()):
                return json.dumps({
                    "account_name": account["account_name"],
                    "account_type": account["account_type"],
                    "currency": account["currency"],
                    "balance": account["balance"],
                    "available_balance": account["available_balance"]
                }, indent=2)
        
        return json.dumps({
            "error": f"Account '{account_identifier}' not found",
            "available_accounts": [acc["account_name"] for acc in SAMPLE_ACCOUNTS]
        }, indent=2)

print("🏦 BankingPlugin created successfully!")

# %% [code]
class TransactionPlugin:
    """Transaction plugin that provides transaction history and analysis."""
    
    @kernel_function(
        description="Get recent transactions for all accounts or a specific account"
    )
    def get_recent_transactions(
        self,
        limit: Annotated[int, "Number of transactions to return (default 5)"] = 5,
        account_id: Annotated[str, "Specific account ID (optional)"] = None
    ) -> Annotated[str, "Returns recent transactions in JSON format"]:
        """Get recent transactions, optionally filtered by account."""
        transactions = SAMPLE_TRANSACTIONS.copy()
        
        # Filter by account if specified
        if account_id:
            transactions = [t for t in transactions if t["account_id"] == account_id]
        
        # Sort by date (most recent first) and limit
        transactions.sort(key=lambda x: x["date"], reverse=True)
        transactions = transactions[:limit]
        
        # Add account names for context
        for transaction in transactions:
            account = next((acc for acc in SAMPLE_ACCOUNTS if acc["account_id"] == transaction["account_id"]), None)
            if account:
                transaction["account_name"] = account["account_name"]
        
        result = {
            "transactions": transactions,
            "summary": {
                "count": len(transactions),
                "total_amount": sum(t["amount"] for t in transactions)
            }
        }
        
        return json.dumps(result, indent=2)
    
    @kernel_function(
        description="Get spending analysis by category"
    )
    def get_spending_by_category(self) -> Annotated[str, "Returns spending breakdown by category"]:
        """Analyze spending patterns by category."""
        category_spending = {}
        
        for transaction in SAMPLE_TRANSACTIONS:
            if transaction["amount"] < 0:  # Only count expenses (negative amounts)
                category = transaction["category"]
                if category not in category_spending:
                    category_spending[category] = 0
                category_spending[category] += abs(transaction["amount"])
        
        # Sort by spending amount
        sorted_categories = sorted(category_spending.items(), key=lambda x: x[1], reverse=True)
        
        result = {
            "spending_by_category": [
                {"category": cat, "total_spent": amount} 
                for cat, amount in sorted_categories
            ],
            "total_expenses": sum(category_spending.values()),
            "top_category": sorted_categories[0][0] if sorted_categories else None
        }
        
        return json.dumps(result, indent=2)
    
    @kernel_function(
        description="Calculate available funds for international transfer"
    )
    def calculate_transfer_capacity(
        self,
        source_currency: Annotated[str, "Source currency code (e.g., USD, EUR)"] = "USD"
    ) -> Annotated[str, "Returns available transfer amounts by currency"]:
        """Calculate how much is available for international transfers."""
        available_funds = {}
        
        for account in SAMPLE_ACCOUNTS:
            currency = account["currency"]
            if currency not in available_funds:
                available_funds[currency] = 0
            available_funds[currency] += account["available_balance"]
        
        # Focus on requested currency
        if source_currency in available_funds:
            main_amount = available_funds[source_currency]
        else:
            main_amount = 0
        
        result = {
            "requested_currency": source_currency,
            "available_amount": main_amount,
            "all_currencies": available_funds,
            "transfer_ready": main_amount > 0
        }
        
        return json.dumps(result, indent=2)

print("💳 TransactionPlugin created successfully!")

# %% [markdown]
---

# Part 3: Load Currency Exchange OpenAPI Tool

Now let's load the currency exchange OpenAPI specification that we'll combine with our banking plugins.

# %% [code]
# Load the currency exchange OpenAPI specification
currency_spec_path = os.path.join("openapi_files", "currency_exchange.json")

try:
    with open(currency_spec_path, "r") as f:
        currency_openapi_spec = json.loads(f.read())
    
    print("💱 Currency exchange OpenAPI spec loaded successfully!")
    print(f"   - API Title: {currency_openapi_spec['info']['title']}")
    print(f"   - API Version: {currency_openapi_spec['info']['version']}")
    print(f"   - Server: {currency_openapi_spec['servers'][0]['url']}")
    
except FileNotFoundError:
    print("⚠️ Currency exchange OpenAPI file not found!")
    print("   Creating a simplified version for demo purposes...")
    
    # Fallback: create a simplified spec
    currency_openapi_spec = {
        "openapi": "3.0.1",
        "info": {
            "title": "Frankfurter Exchange Rates API",
            "description": "Returns the latest foreign exchange reference rates.",
            "version": "1.0"
        },
        "servers": [
            {"url": "https://api.frankfurter.dev"}
        ],
        "paths": {
            "/v1/latest": {
                "get": {
                    "summary": "Latest Exchange Rates",
                    "description": "Returns the latest exchange rates relative to the base currency.",
                    "operationId": "get-latest-rates",
                    "parameters": [
                        {
                            "in": "query",
                            "name": "base",
                            "schema": {"type": "string", "example": "USD"},
                            "description": "The base currency (e.g., USD, EUR)"
                        }
                    ],
                    "responses": {
                        "200": {
                            "description": "Successful response",
                            "content": {
                                "application/json": {
                                    "example": {
                                        "amount": 1,
                                        "base": "USD",
                                        "date": "2024-12-05",
                                        "rates": {
                                            "EUR": 0.88,
                                            "GBP": 0.75,
                                            "JPY": 143.5
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }
    
    print("✅ Fallback currency exchange spec created!")

# %% [markdown]
---

# Part 4: Create Hybrid Azure AI Agent

Now we'll create an Azure AI Agent that combines:
- **OpenAPI Tool** for currency exchange
- **Semantic Kernel Plugins** for banking operations

This demonstrates the power of hybrid agent architectures!

# %% [code]
# Defining a Kernel Filter
kernel = Kernel()

# Register the auto function invocation filter
@kernel.filter(FilterTypes.AUTO_FUNCTION_INVOCATION)
async def auto_function_invocation_filter(context: AutoFunctionInvocationContext, next):
    """A filter that will be called for each function call in the response."""
    print(80*"=")
    print("\n🔧 Auto function invocation filter - Local Plugins Only (doesnt detect Azure AI Agents OpenAPI function calls)")
    print(f"📞 Function: {context.function.name}")
    print("📝 Arguments:", context.arguments)
    print(f"🔢 Request sequence: {context.request_sequence_index}")
    print(f"🎯 Function sequence: {context.function_sequence_index}")

    # as an example
    try:
        function_calls = context.chat_history.messages[-1].items
        print(f"📊 Number of function calls: {len(function_calls)}")
    except:
        pass
    # if we don't call next, it will skip this function, and go to the next one
    await next(context)
    
    print("📤 Function Call Contents:", context.function_call_content)
    print("✅ Function Call Result:", context.function_result)
    print(80*"=")



# Create the hybrid banking agent with OpenAPI tools and Semantic Kernel plugins
async def create_hybrid_banking_agent():
    """Create Azure AI Agent with both OpenAPI tools and SK plugins."""
    
    # Step 1: Create the Azure AI Agents client
    agents_client = AgentsClient(
        endpoint=os.environ["PROJECT_ENDPOINT"],
        credential=DefaultAzureCredential()
    )
    
    print("🔗 Connected to Azure AI Agents service")
    
    # Step 2: Create OpenAPI tool for currency exchange
    auth = OpenApiAnonymousAuthDetails()
    currency_tool = OpenApiTool(
        name="currency_exchange",
        spec=currency_openapi_spec,
        description="Get the latest foreign exchange rates from Frankfurter API. Use this for currency conversion and international transfer calculations.",
        auth=auth
    )
    
    print("💱 Currency exchange OpenAPI tool created")
    
    # Step 3: Create Azure AI agent with OpenAPI tool
    base_agent = agents_client.create_agent(
        model=os.environ["MODEL_DEPLOYMENT_NAME"],
        name="hybrid_banking_agent",
        instructions="""You are an expert banking and financial assistant with access to both banking data and currency exchange rates.
        
You can help users with:
1. Account balances and banking information
2. Transaction history and spending analysis
3. Currency exchange rates and conversion calculations
4. International transfer planning and cost estimation

Always provide clear, accurate financial information and explain calculations step by step.
When dealing with international transfers, always get current exchange rates and calculate both the amount to be sent and received.
Be helpful and proactive in suggesting related financial insights.
If you get a complex request, break it down into smaller steps and go through function calls one step at a time.
Make sure to use the OpenAPI tools for currency exchange rates and your local plugins for banking data.
""",
        tools=currency_tool.definitions
    )
    
    print(f"🏦 Base Azure AI agent created: {base_agent.id}")
    
    # Step 4: Create Semantic Kernel AzureAIAgent wrapper with plugins
    async with (
        AsyncDefaultAzureCredential() as creds,
        AzureAIAgent.create_client(credential=creds, endpoint=os.environ["PROJECT_ENDPOINT"]) as project_client,
    ):
        # Wrap the existing agent with SK and add plugins
        hybrid_agent = AzureAIAgent(
            client=project_client,
            definition=base_agent,
            kernel=kernel,
            plugins=[BankingPlugin(), TransactionPlugin()]  # Add our local plugins!
        )
        
        print("🚀 Hybrid agent created with both OpenAPI tools and SK plugins!")
        
        return hybrid_agent, agents_client, base_agent

# Create the hybrid agent
print("Creating hybrid banking agent...")
# Note: We'll actually run this in the next cell due to async context

# %% [markdown]
---

# Part 5: Test Hybrid Agent with Complex Scenarios

Let's test our hybrid agent with queries that require both local banking data and external currency exchange information.

# %% [code]
async def test_hybrid_agent():
    """Test the hybrid agent with complex scenarios."""
    
    # Create SK wrapper with plugins
    async with (
        AsyncDefaultAzureCredential() as creds,
        AzureAIAgent.create_client(credential=creds, endpoint=os.environ["PROJECT_ENDPOINT"]) as project_client,
    ):
        hybrid_agent, agents_client, base_agent = await create_hybrid_banking_agent()

        print("🚀 Hybrid Banking Agent Ready!")
        print("   ✅ OpenAPI Tool: Currency Exchange (Frankfurter API)")
        print("   ✅ SK Plugin: Banking Operations")
        print("   ✅ SK Plugin: Transaction Analysis")
        
        # Test scenarios that combine multiple tools
        test_scenarios = [
            {
                "name": "Currency Conversion",
                "query": "What is the current exchange rate from USD to EUR? How much EUR can I get for 1000 USD?"
            },
            {
                "name": "Account Summary",
                "query": "Give me a summary of all my account balances and my recent spending patterns."
            },
            {
                "name": "International Transfer Planning", 
                "query": "I want to send 1000 USD to Europe. Check my USD balance, get the current USD to EUR exchange rate, and tell me how much EUR they would receive."
            },
            {
                "name": "Multi-Currency Analysis",
                "query": "Show me all my account balances and convert my EUR account balance to USD using current exchange rates. Also analyze my spending by category."
            },
            {
                "name": "Travel Budget Planning",
                "query": "I'm planning a trip to Japan. Check my USD accounts, get the current USD to JPY exchange rate, and tell me how much JPY I could get with 500 USD. Also show me my travel-related expenses."
            }
        ]
        
        thread = None
        
        try:
            for i, scenario in enumerate(test_scenarios, 1):
                print(f"\n{'='*60}")
                print(f"🧪 Test Scenario {i}: {scenario['name']}")
                print(f"{'='*60}")
                print(f"👤 User Query: {scenario['query']}")
                print("\n🤖 Agent Response:")

                async for response in hybrid_agent.invoke(
                    messages=scenario['query'],
                    thread=thread,
                ):
                    if response.role != AuthorRole.TOOL:
                        print(response.content)
                    thread = response.thread
                
                print("\n" + "-"*40)
        
        finally:
            # Cleanup
            pass
    
    # Cleanup the base agent
    agents_client.delete_agent(base_agent.id)
    print("🧹 Agent cleaned up")
    print("\n✅ All hybrid agent tests completed!")

# Run the hybrid agent tests
await test_hybrid_agent()

# %% [markdown]
---

# Part 6: Advanced Multi-Tool Query Examples

Let's create some specific examples that showcase the power of combining local plugins with external APIs.

# %% [code]
async def demo_advanced_scenarios():
    """Demonstrate advanced scenarios combining multiple tools."""
    
    async with (
        AsyncDefaultAzureCredential() as creds,
        AzureAIAgent.create_client(credential=creds, endpoint=os.environ["PROJECT_ENDPOINT"]) as project_client,
    ):
        hybrid_agent, agents_client, base_agent = await create_hybrid_banking_agent()
        
        # Advanced demo scenarios
        advanced_queries = [
            """I'm considering a large international transfer. Can you:
            1. Check my current USD balance in all my accounts
            2. Get current USD to GBP exchange rates
            3. Calculate how much GBP I'd get for $2000
            4. Analyze if this transfer fits my spending patterns
            """,

            """Financial health check: Show me my account balances, recent spending by category, 
            and calculate the total value of all my accounts in USD using current exchange rates.
            """,
            
            """I want to optimize my EUR account. Check my EUR balance, 
            get current EUR to USD rates, and tell me if I should convert some EUR to USD 
            based on my spending patterns.
            """
        ]
        
        thread = None
        
        try:
            for i, query in enumerate(advanced_queries, 1):
                print(f"\n{'🎯' + '='*70}")
                print(f"Advanced Demo {i}: Multi-Tool Financial Analysis")
                print(f"{'='*71}")
                print(f"👤 Complex Query:")
                print(f"{query}")
                print("\n🤖 Comprehensive Analysis:")
                print("-" * 50)
                
                async for response in hybrid_agent.invoke(messages=query, thread=thread):
                    if response.role != AuthorRole.TOOL:
                        print(response.content)
                    thread = response.thread
                
                print("\n" + "="*71)
        
        finally:
            pass
    
    agents_client.delete_agent(base_agent.id)
    print("\n🚀 Advanced demo completed! The agent successfully combined:")
    print("   💰 Local banking data (balances, transactions)")
    print("   💱 Live currency exchange rates")
    print("   📊 Financial analysis and insights")

# Run advanced demos
print("Starting advanced multi-tool demos...")
await demo_advanced_scenarios()

# %% [markdown]
---

## 🎯 Key Architecture Insights

### 🏗️ Hybrid Agent Architecture Benefits:

**1. OpenAPI Tools (External APIs):**
- ✅ **Real-time data**: Live currency rates, market data
- ✅ **Third-party services**: Leverage external expertise
- ✅ **No local maintenance**: APIs maintained by providers
- ✅ **Standardized**: OpenAPI spec ensures compatibility

**2. Semantic Kernel Plugins (Local Functions):**
- ✅ **Private data access**: Secure internal systems
- ✅ **Custom business logic**: Tailored to your needs
- ✅ **No external dependencies**: Reliable offline operation
- ✅ **Full control**: Complete customization possible

**3. Combined Power:**
- 🚀 **Rich experiences**: Internal + external data
- 🚀 **Intelligent routing**: Agent chooses right tools
- 🚀 **Complex workflows**: Multi-step operations
- 🚀 **Contextual responses**: Comprehensive insights

# %% [markdown]
---

## 🔧 Implementation Best Practices

### ✅ Plugin Design:
- **Clear descriptions**: Help the agent understand when to use each function
- **Appropriate return types**: Use JSON for structured data
- **Error handling**: Gracefully handle missing data or invalid inputs
- **Focused responsibility**: Each plugin should have a clear purpose

### ✅ OpenAPI Integration:
- **Descriptive tool names**: Help agent understand API capabilities
- **Authentication handling**: Properly configure auth details
- **Rate limiting awareness**: Consider API usage limits
- **Error resilience**: Handle API failures gracefully

### ✅ Agent Instructions:
- **Clear capabilities**: Explain what the agent can do
- **Usage guidance**: Provide examples of how to use tools
- **Response formatting**: Specify how to present information
- **Context preservation**: Maintain conversation context across tool calls

# %% [markdown]
---

## 🎨 Exercise: Create Your Own Hybrid Agent

**Challenge:** Extend this example by adding new capabilities!

### 💡 Ideas to Implement:

1. **Weather-Based Spending Plugin**:
   - Create a plugin that analyzes spending patterns by weather
   - Combine with a weather API to provide seasonal insights

2. **Investment Portfolio Plugin**:
   - Add stock/crypto portfolio management
   - Combine with financial market APIs

3. **Travel Expense Optimizer**:
   - Create plugins for travel planning
   - Combine with flight/hotel APIs and currency exchange

### 🧪 Try it yourself:

# %% [code]
# Your turn! Create a new plugin and combine it with an external API

class CustomPlugin:
    """Create your own plugin here!"""
    
    @kernel_function(
        description="Describe what your function does"
    )
    def your_custom_function(self) -> Annotated[str, "Return type description"]:
        """Implement your custom functionality here."""
        # Your code here
        return "Your implementation"

# Test your plugin
# custom_plugin = CustomPlugin()
# result = custom_plugin.your_custom_function()
# print(result)

print("🎨 Ready for your creative implementation!")
print("💡 Tip: Start simple, then add complexity gradually")
print("🚀 Remember: The power is in combining local + external data!")

# %% [markdown]
<details>
<summary>💡 Click for Exercise Solution Ideas</summary>

**Sample Weather Plugin:**
```python
class WeatherSpendingPlugin:
    @kernel_function(description="Analyze spending patterns by weather conditions")
    def analyze_weather_spending(self) -> str:
        # Categorize transactions by likely weather impact
        weather_categories = {
            "indoor": ["Shopping", "Food & Dining"],
            "outdoor": ["Transportation", "Travel"],
            "seasonal": ["Utilities", "Clothing"]
        }
        # Your analysis logic here
        return json.dumps({"weather_impact_analysis": "Your insights"})
```

**Sample Investment Plugin:**
```python
class InvestmentPlugin:
    @kernel_function(description="Get portfolio summary")
    def get_portfolio_summary(self) -> str:
        # Mock portfolio data
        portfolio = {
            "stocks": {"AAPL": 10, "MSFT": 5},
            "total_value_usd": 15000,
            "performance": "+5.2%"
        }
        return json.dumps(portfolio)
```

</details>

# %% [markdown]
---

## 🎯 Summary: Hybrid Agent Architecture

### 🏆 What We've Accomplished:

✅ **Created Semantic Kernel Plugins** for banking operations
✅ **Integrated OpenAPI Tools** for real-time currency exchange
✅ **Built Hybrid Agent** combining local + external capabilities
✅ **Demonstrated Complex Queries** requiring multiple tool calls
✅ **Showed Best Practices** for plugin design and integration

### 🚀 Key Takeaways:

1. **Plugin Design**: Create focused, well-documented functions
2. **OpenAPI Integration**: Leverage external APIs for real-time data
3. **Agent Instructions**: Provide clear guidance on tool usage
4. **Complex Workflows**: Enable multi-step operations across tools
5. **User Experience**: Create conversational, intelligent interactions

### 🔮 Next Steps:

- **Explore Authentication**: Add secured OpenAPI tools
- **Scale Plugin Architecture**: Create plugin ecosystems
- **Add Error Handling**: Robust production-ready implementations
- **Performance Optimization**: Efficient tool selection and execution
- **Multi-Agent Orchestration**: Coordinate multiple specialized agents

**🎉 Congratulations!** You've mastered hybrid agent architectures combining the best of local plugins and external APIs!

---

*Ready to build the next generation of intelligent financial assistants? The possibilities are endless!* 🌟

################################################################################  04-orchestrated-agents-with-tools\04.3-logic_apps_hybrid_tutorial.ipynb  ################################################################################
# %% [markdown]
# 🔄⚡ Logic Apps + Semantic Kernel Hybrid Tutorial

**🚀 Learn how to combine Azure Logic Apps with Semantic Kernel plugins for powerful workflow automation!**

This tutorial demonstrates:
1. **Logic Apps Integration** - Automated workflow triggers using AzureLogicAppTool
2. **Semantic Kernel Plugins** - Local data processing capabilities
3. **Hybrid Agent** - Combining workflows with AI intelligence

**Scenario:** An intelligent business assistant that can:
- 📧 Trigger email workflows via Logic Apps
- 📊 Process business data locally with SK plugins
- 🔗 Coordinate between cloud automation and AI analysis

---

# %% [markdown]
## 🔧 Setup and Prerequisites

**Environment Variables Required:**
- `PROJECT_ENDPOINT`: Your Azure AI Project endpoint
- `MODEL_DEPLOYMENT_NAME`: Your deployed AI model name
- `AZURE_SUBSCRIPTION_ID`: Your Azure subscription ID
- `AZURE_RESOURCE_GROUP_NAME`: Resource group containing your Logic App

**Architecture Overview:**
```
Azure AI Agent
    ├── AzureLogicAppTool → Email/Notification Workflows
    └── SK Plugins
            ├── DataPlugin → process_sales_data()
            └── ReportPlugin → generate_summary()
```

# %% [markdown]
![Azure Tools](images/azure_tools.gif)

# %% [markdown]
## 📦 Installing Dependencies and Imports

First, we'll install the necessary packages and import the required modules for our hybrid solution. This includes:

- **Azure AI Agents SDK** - For creating intelligent agents
- **Azure Logic Apps Management** - For managing and triggering Logic Apps
- **Semantic Kernel** - For local AI processing and plugins
- **Azure Identity** - For authentication with Azure services

The following cell sets up all the dependencies we need for this tutorial.

# %% [code]
# Install required packages
# !pip install azure-ai-agents azure-identity azure-mgmt-logic requests

import os
import json
import requests
from typing import Annotated, Dict, Any, Callable, Set
from datetime import datetime, timedelta

# Azure AI Agents imports
from azure.ai.agents import AgentsClient
from azure.ai.agents.models import ToolSet, FunctionTool
from azure.identity import DefaultAzureCredential

# Azure Logic Apps Management
from azure.mgmt.logic import LogicManagementClient

# Semantic Kernel imports
import semantic_kernel as sk
from semantic_kernel.functions import kernel_function

print("✅ Required packages imported successfully!")

# %% [markdown]
## 🔧 Building the Azure Logic Apps Tool

Now we'll implement the core `AzureLogicAppTool` class that serves as our bridge between the AI agent and Azure Logic Apps. This tool:

1. **Registers Logic Apps** - Retrieves callback URLs for Logic App triggers
2. **Manages Multiple Workflows** - Stores and organizes multiple Logic App endpoints
3. **Handles Invocation** - Sends HTTP requests to trigger Logic App workflows
4. **Provides Fallback** - Simulates actions when Logic Apps aren't available

This implementation allows our AI agent to seamlessly trigger cloud-based automation workflows.

# %% [code]
# Azure Logic Apps Tool Implementation
class AzureLogicAppTool:
    """
    A service that manages multiple Logic Apps by retrieving and storing their callback URLs,
    and then invoking them with an appropriate payload.
    """

    def __init__(self, subscription_id: str, resource_group: str, credential=None):
        if credential is None:
            credential = DefaultAzureCredential()
        self.subscription_id = subscription_id
        self.resource_group = resource_group
        self.logic_client = LogicManagementClient(credential, subscription_id)
        self.callback_urls: Dict[str, str] = {}

    def register_logic_app(self, logic_app_name: str, trigger_name: str) -> None:
        """
        Retrieves and stores a callback URL for a specific Logic App + trigger.
        Raises a ValueError if the callback URL is missing.
        """
        try:
            callback = self.logic_client.workflow_triggers.list_callback_url(
                resource_group_name=self.resource_group,
                workflow_name=logic_app_name,
                trigger_name=trigger_name,
            )

            if callback.value is None:
                raise ValueError(f"No callback URL returned for Logic App '{logic_app_name}'.")

            self.callback_urls[logic_app_name] = callback.value
            print(f"✅ Registered Logic App: {logic_app_name}")
        except Exception as e:
            print(f"⚠️ Warning: Could not register Logic App '{logic_app_name}': {e}")
            print("💡 This is expected if the Logic App doesn't exist - emails will be simulated")

    def invoke_logic_app(self, logic_app_name: str, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Invokes the registered Logic App (by name) with the given JSON payload.
        Returns a dictionary summarizing success/failure.
        """
        if logic_app_name not in self.callback_urls:
            # Simulate email sending if Logic App not registered
            print(f"📧 SIMULATED EMAIL:")
            print(f"   To: {payload.get('to', 'unknown')}")
            print(f"   Subject: {payload.get('subject', 'unknown')}")
            print(f"   Body: {payload.get('body', 'unknown')}")
            return {"result": f"Successfully simulated email via {logic_app_name}."}

        url = self.callback_urls[logic_app_name]
        try:
            response = requests.post(url=url, json=payload, timeout=30)
            if response.ok:
                print(f"✅ Successfully invoked Logic App: {logic_app_name}")
                return {"result": f"Successfully invoked {logic_app_name}."}
            else:
                print(f"⚠️ Error invoking Logic App: {logic_app_name} ({response.status_code})")
                return {"error": f"Error invoking {logic_app_name} ({response.status_code}): {response.text}"}
        except Exception as e:
            print(f"⚠️ Exception invoking Logic App: {logic_app_name} - {str(e)}")
            return {"error": f"Error invoking {logic_app_name}: {str(e)}"}

def create_send_email_function(service: AzureLogicAppTool, logic_app_name: str) -> Callable[[str, str, str], str]:
    """
    Returns a function that sends an email by invoking the specified Logic App.
    """
    def send_email_via_logic_app(to: str, subject: str, body: str) -> str:
        """
        Sends an email by invoking the specified Logic App with the given recipient, subject, and body.
        """
        payload = {
            "to": to,
            "subject": subject,
            "body": body,
        }
        result = service.invoke_logic_app(logic_app_name, payload)
        print("📧 Email sent via Logic App:")
        return json.dumps(result)

    return send_email_via_logic_app

print("🔧 AzureLogicAppTool class defined!")

# %% [markdown]
## 📧 Creating Agent with Azure Logic Apps Integration

We'll create an AI agent that can trigger Logic Apps workflows for automated business processes.

# %% [markdown]
## 🎯 Initializing Azure AI Agents Client

Before we can create our hybrid agent, we need to establish a connection to Azure AI services. This step:

- **Connects to Azure AI Project** - Uses your project endpoint for agent creation
- **Sets Up Authentication** - Uses DefaultAzureCredential for secure access
- **Configures Model Deployment** - Specifies which AI model to use for the agent

Make sure you have set the required environment variables in your development environment.

# %% [code]
# Initialize Azure AI Agents client
project_endpoint = os.getenv("PROJECT_ENDPOINT")
model_deployment = os.getenv("MODEL_DEPLOYMENT_NAME")
subscription_id = os.getenv("AZURE_SUBSCRIPTION_ID")
resource_group = os.getenv("AZURE_RESOURCE_GROUP_NAME")

if not all([project_endpoint, model_deployment, subscription_id, resource_group]):
    raise ValueError("Missing required environment variables. Please set PROJECT_ENDPOINT, MODEL_DEPLOYMENT_NAME, AZURE_SUBSCRIPTION_ID, and AZURE_RESOURCE_GROUP_NAME")

credential = DefaultAzureCredential()
agents_client = AgentsClient(endpoint=project_endpoint, credential=credential)

print(f"✅ Connected to Azure AI Project")
print(f"📊 Using model: {model_deployment}")

# %% [markdown]
## 🔗 Registering Logic Apps and Creating Email Function

In this step, we configure our Logic App integration by:

1. **Registering the Logic App** - Connecting to the specific Logic App workflow
2. **Retrieving Callback URLs** - Getting the HTTP trigger endpoint
3. **Creating Email Function** - Building a specialized function for the agent to use

The Logic App should have an HTTP trigger named "When_a_HTTP_request_is_received" that can accept email parameters (to, subject, body).

# %% [code]
# Logic App details
logic_app_name = "agent-logic-apps"
trigger_name = "When_a_HTTP_request_is_received"

# Create and initialize AzureLogicAppTool utility
logic_app_tool = AzureLogicAppTool(subscription_id, resource_group)
logic_app_tool.register_logic_app(logic_app_name, trigger_name)
print(f"Registered logic app '{logic_app_name}' with trigger '{trigger_name}'.")

# Create the specialized "send_email_via_logic_app" function for your agent tools
send_email_func = create_send_email_function(logic_app_tool, logic_app_name)

print(f"✅ Logic App tool configured for: {logic_app_name}")
print(f"🔧 Trigger: {trigger_name}")
print(f"📧 Email function created for workflow integration")

# %% [code]
logic_app_name

# %% [markdown]
## 🤖 Creating the Hybrid Business Agent

Now we'll create our intelligent business agent with Logic Apps integration. This process involves:

1. **Function Registration** - Adding our email function to the agent's toolset
2. **Tool Configuration** - Enabling auto function calls for seamless execution
3. **Agent Instructions** - Defining the agent's role and capabilities
4. **Workflow Integration** - Connecting AI intelligence with automated processes

The agent will be able to understand business requests and automatically trigger appropriate Logic App workflows.

# %% [code]
# Prepare the function tools for the agent
functions_to_use: Set = {
    send_email_func,  # This references the AzureLogicAppTool instance via closure
}

# Create the Logic Apps agent with proper toolset
# Create function tool and toolset
functions = FunctionTool(functions=functions_to_use)
toolset = ToolSet()
toolset.add(functions)

# Enable auto function calls - this is key for actual execution
agents_client.enable_auto_function_calls(toolset)

logic_apps_agent = agents_client.create_agent(
    model=model_deployment,
    name="LogicAppsBusinessAgent",
    instructions="""
    You are a business automation assistant that can trigger workflow processes.
    
    Your capabilities:
    - Send email notifications via Logic Apps using send_email_via_logic_app function
    - Trigger alerts for business events
    - Coordinate automated workflows
    
    When sending emails, use the send_email_via_logic_app function with:
    - to: email address
    - subject: email subject line
    - body: email content
    
    Always explain what workflow you're triggering and why.
    """,
    toolset=toolset
)

print(f"🤖 Logic Apps Agent created: {logic_apps_agent.id}")
print(f"🔧 Agent configured with email workflow capabilities")

# %% [markdown]
## 🧪 Testing the Logic Apps Integration

Time to test our hybrid agent! In this section we will:

1. **Configure Email Address** - Set your email for testing notifications
2. **Create Thread** - Start a conversation with the agent
3. **Send Test Message** - Request a business workflow trigger
4. **Monitor Execution** - Watch as the agent processes and executes the Logic App

The agent should intelligently understand the request and automatically trigger the appropriate email workflow.

# %% [markdown]
#### Input Your Email Address


# %% [code]
# please replace with your email address
my_email = "test@test.com"

# %% [markdown]
## 🎬 Executing the Business Workflow

Watch the magic happen! This cell demonstrates the complete flow:

```mermaid
graph TD
    A[User Request] --> B[AI Agent Processing]
    B --> C{Logic Apps Available?}
    C -->|Yes| D[Trigger Logic App]
    C -->|No| E[Simulate Email]
    D --> F[Send Real Email]
    E --> G[Display Simulated Email]
    F --> H[Return Success]
    G --> H
```

The agent will:
- Parse the business request
- Identify the need for email notification
- Execute the `send_email_via_logic_app` function
- Trigger the Logic App workflow (or simulate if unavailable)

# %% [code]
# Test the Logic Apps agent
thread = agents_client.threads.create()

# Send a test message
message = agents_client.messages.create(
    thread_id=thread.id,
    role="user",
    content=f"Send a notification email about high sales performance this quarter to this email address {my_email}.",
)

# Create and process an agent run in the thread
run = agents_client.runs.create_and_process(thread_id=thread.id, agent_id=logic_apps_agent.id)
print(f"Run finished with status: {run.status}")

if run.status == "failed":
    print(f"Run failed: {run.last_error}")

# Get the response
print("📧 Logic Apps Agent Response:")
messages = agents_client.messages.list(thread_id=thread.id)
for msg in messages:
    if msg.text_messages:
        print(f"\n🗨️ {msg.role.upper()}: {msg.text_messages[-1].text.value}")
        print("-" * 80)



# %% [markdown]
## 🎉 Conclusion

**You've successfully created a hybrid Azure AI Agent that combines:**

### 🔄 Azure Logic Apps Integration
- Used `AzureLogicAppTool` for workflow automation
- Registered Logic Apps with `register_logic_app()` method
- Triggered email notifications and business processes

### 🔌 Semantic Kernel Plugins
- Created local data processing capabilities
- Built custom business intelligence functions
- Processed sales data and generated reports

### 🎯 Hybrid Orchestration
- Combined cloud automation with local AI processing
- Coordinated between multiple tools and workflows
- Created intelligent business automation

**Next Steps:**
- Expand SK plugins for more business logic
- Add more Logic Apps for different workflows
- Implement error handling and monitoring
- Scale to enterprise-level scenarios

---
*Happy automating! 🚀*

################################################################################  04-orchestrated-agents-with-tools\bank_transactions_api.py  ################################################################################


################################################################################  04-orchestrated-agents-with-tools\README.md  ################################################################################
# Orchestrated Agents with Tools

Learn how to connect your agent teams to external APIs, services, and cloud workflows. This is where your agents start working with real-world data and systems.

## What's In This Folder

**[04.1 - OpenAPI Currency Exchange](04.1-openapi_currency_exchange_tutorial.ipynb)**
Connect your agents to the Frankfurter currency exchange API using OpenAPI specifications. Compare the Azure AI Foundry SDK approach with Semantic Kernel integration patterns.

![Azure Tools](images/azure_tools.gif)

**[04.2 - Hybrid OpenAPI + Plugins](04.2-hybrid_openapi_and_plugins_tutorial.ipynb)**
Build enterprise solutions that combine external APIs with local business logic. Create banking scenarios using local account data and external currency rates.

![SK Plugins](images/sk_plugins.gif)

**[04.3 - Logic Apps Integration](04.3-logic_apps_hybrid_tutorial.ipynb)**
Integrate Azure Logic Apps workflows with AI agent intelligence. Build automated business processes with email notifications and workflow triggers.

## Learning Path

1. **Start with 04.1** - Master external API integration fundamentals
2. **Progress to 04.2** - Learn hybrid architectures
3. **Complete with 04.3** - Integrate cloud workflows

**Prerequisites**: Complete [01-agent-basics](../01-agent-basics/), [02-agent-custom-functions](../02-agent-custom-functions/), and [03-orchestrated-agents](../03-orchestrated-agents/).

## Prerequisites

### Previous Knowledge
- Complete all previous tutorial folders (01, 02, 03)
- Understanding of REST APIs and JSON
- Familiarity with agent orchestration patterns

### Azure Resources
- Azure subscription with sufficient permissions
- Azure AI Foundry project
- Deployed AI model (GPT-4, GPT-3.5-turbo, etc.)
- Azure OpenAI resource (for Semantic Kernel scenarios)
- Azure Logic Apps (for workflow automation scenarios)

### Environment Setup
- Python 3.8+
- Jupyter Notebook or VS Code
- Azure CLI (recommended)
- Network access to external APIs (Frankfurter, etc.)


### Set up the Logic App on AzureAdd commentMore actions

Please follow the [documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/logic-apps?pivots=portal) link. The final Logic App should look like this:

![logic-app](./images/logic-app.png)

When creating the trigger, please copy and paste the below in the "Request Body JSON Schema" field:

```json
{
  "type": "object",
  "properties": {
    "to": {
      "type": "string"
    },
    "subject": {
      "type": "string"
    },
    "body": {
      "type": "string"
    }
  }
}
```

The trigger step should look like this:

![logic-app-trigger](./images/logic-app-trigger.png)


When creating the second step `Send an email (V2)`, please fill in the required fields as shown below:

![logic-app-send-email](./images/send-email.png)

The `to`, `subject`, and `body` fields will be available to populate from the previous step, which is the trigger. The `to` field will be used to send the email to the user, and the `subject` and `body` fields will be used to populate the email subject and body respectively. To add these fields, right-click on the "To*" field for example, then click on the blue lightning icon, and then select the proper value from the list of available fields. The final step should look like this:

![lightning](./images/lightning.png)

Please note that the `Send an email (V2)` action in the Logic App requires a valid email address to send notifications, and the user has to **manually** go through authentication in the Azure Portal when adding this Step to the workflow. You can use your own email address or create a test email account for this purpose.

The final details in the Jupyter notebook will look like this (or similar):

```python 
# Logic App details
logic_app_name = "agent-logic-apps" # Resource name of the Logic App in Azure
trigger_name = "When_a_HTTP_request_is_received" # Trigger name for the Logic App
```

**Note**: The Logic App requires manual authentication in the Azure Portal for email sending capabilities.

**Final configuration** for the Jupyter notebook:
```python 
logic_app_name = "agent-logic-apps"  # Your Logic App resource name
trigger_name = "When_a_HTTP_request_is_received"  # Trigger name
```

### Environment Variables
Configure your Azure AI services in the `.env` file at the project root:

```bash
# Navigate to the project root and edit the .env file
cd ../../  # Go to azure-ai-agents-playbook root
```

Update the `.env` file with your Azure AI project details:
```properties
# Required for all tutorials
PROJECT_ENDPOINT="https://your-foundry-resource.services.ai.azure.com/api/projects/your-project-name"
MODEL_DEPLOYMENT_NAME="your-model-deployment-name"

# Required for Semantic Kernel scenarios (04.1, 04.2)
AZURE_OPENAI_API_KEY="your-azure-openai-api-key"
AZURE_OPENAI_ENDPOINT="https://your-openai-resource.openai.azure.com/"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME="your-chat-deployment"
AZURE_OPENAI_DEPLOYMENT_NAME="your-deployment-name"
AZURE_OPENAI_API_VERSION="2024-12-01-preview"

# Required for Logic Apps integration (04.3)
AZURE_SUBSCRIPTION_ID="your-subscription-id"
AZURE_RESOURCE_GROUP_NAME="your-resource-group-name"
```

**Tip**: The `.env` file already exists in the project root with example values - just update it with your details.

### Required Packages
Install the packages you need:

```bash
pip install azure-ai-agents azure-identity semantic-kernel azure-mgmt-logic requests python-dotenv
```
cd ../../  # Go to azure-ai-agents-playbook root
# Edit .env file with your Azure AI configuration
```

The `.env` file should contain your Azure AI project details:
```properties
# Required for all tutorials
PROJECT_ENDPOINT="https://your-foundry-resource.services.ai.azure.com/api/projects/your-project-name"
MODEL_DEPLOYMENT_NAME="your-model-deployment-name"

# Required for Semantic Kernel scenarios (04.1, 04.2)
AZURE_OPENAI_API_KEY="your-azure-openai-api-key"
AZURE_OPENAI_ENDPOINT="https://your-openai-resource.openai.azure.com/"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME="your-chat-deployment"
AZURE_OPENAI_DEPLOYMENT_NAME="your-deployment-name"
AZURE_OPENAI_API_VERSION="2024-12-01-preview"

# Required for Logic Apps integration (04.3)
AZURE_SUBSCRIPTION_ID="your-subscription-id"
AZURE_RESOURCE_GROUP_NAME="your-resource-group-name"

```

**Tip**: The `.env` file already exists in the project root with example values - just update it with your details.

### Required Packages
Install the packages you need:

```bash
pip install azure-ai-agents azure-identity semantic-kernel azure-mgmt-logic requests python-dotenv
```

## What You'll Learn

### Tool Integration Approaches

**OpenAPI Tool Integration**
- Use `OpenApiTool` with standardized API specifications
- Integrate external services like currency exchange APIs
- Handle automatic parameter mapping and documentation

**Hybrid Plugin + API Architecture**
- Combine Semantic Kernel plugins with external APIs
- Mix local business logic with external data sources
- Build secure enterprise applications

**Workflow Automation Integration**
- Integrate Azure Logic Apps with AI decision-making
- Create business process automation workflows
- Build notification and approval systems

### What You'll Build
- Currency Exchange Agent with real-time rates
- Banking Assistant (local data + external APIs)
- Business process automation with email notifications
- Multi-source intelligence systems

## Next Steps

After mastering external tool integration:
- [05-orchestrated-agents-with-custom-openapi-tools](../05-orchestrated-agents-with-custom-openapi-tools/) - Custom API services
- [06-magentic-one-orchestration](../06-magentic-one-orchestration/) - Advanced orchestration patterns

################################################################################  05-orchestrated-agents-with-custom-openapi-tools\05.1-fastapi_openapi_tutorial.ipynb  ################################################################################
# %% [markdown]
# FastAPI OpenAPI Integration Tutorial

🏦 **Learn how to connect Azure AI Agents to local FastAPI services!**

This tutorial demonstrates:
- **Starting a FastAPI service** with bank transaction data
- **Reading OpenAPI spec** from the running service
- **Creating Azure AI Agents** that call the FastAPI endpoints

**Use Case**: Connect AI agents to your own custom APIs and services.

---

# %% [markdown]
## 🔧 Setup and Prerequisites

**Environment Variables Required:**
- `PROJECT_ENDPOINT`: Your Azure AI Project endpoint
- `MODEL_DEPLOYMENT_NAME`: Your deployed AI model name

**Additional Requirements:**
- FastAPI service running on `http://localhost:port`
- The `bank_transactions_api.py` file in the same directory

# %% [markdown]
![SK Orchestration](images/sk_orchestration.gif)

# %% [code]
# Install required packages
# !pip install azure-ai-agents azure-identity semantic-kernel fastapi uvicorn requests 

import os
import json
import asyncio
import requests
import subprocess
import time
from azure.ai.agents.models import OpenApiTool, OpenApiAnonymousAuthDetails
from azure.identity.aio import DefaultAzureCredential
from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings
from semantic_kernel.contents import AuthorRole

print("✅ Packages imported successfully!")

# %% [markdown]
## 🚀 Step 1: Start the FastAPI Service

First, we need to start our bank transactions FastAPI service.

1. Open a terminal.
2. Navigate to the directory containing `bank_transactions_api.py`.
3. Activate your Python environment if necessary.
4. Run the FastAPI service using the command below.
5. Specify a port number (e.g., `8100`).
```bash
python bank_transactions_api.py 8100
```

# %% [code]
# Start the FastAPI service in the background
import subprocess
import time

print("🚀 Starting FastAPI bank transactions service...")

###############
## IMPORTANT ##
###############
# Start the FastAPI server in the background
# 1. Open a terminal, and make sure you are in the right directory
# 2. Activate your Python environment if needed
# 3. Run the following command with a specific port
#    Example: python bank_transactions_api.py 8000


# Test if the service is running
localhost = "http://localhost"
host="https://ca-agentfastapi.purpleplant-8215fdbe.swedencentral.azurecontainerapps.io"

http_port = 80  # Default port for FastAPI if using HTTP
https_port = 443 # Change to 443 for HTTPS 

if host == "":
    host = localhost
    port = http_port
else:
    port = https_port
    
print(f"🔍 Checking if FastAPI service is running on port {port}...")


try:
    full_host = f"{host}:{port}/"
    print(f"🔗 Full URL: {full_host}")
    response = requests.get(full_host)
    if response.status_code == 200:
        print("✅ FastAPI service is running!")
        print(f"Service info: {response.json()}")
    else:
        print(f"❌ Service responded with status: {response.status_code}")
except requests.exceptions.ConnectionError:
    print(f"❌ Could not connect to FastAPI service. Make sure it's running on port {port}.")
    print("💡 If you want to run it locally, you can start it manually with: python bank_transactions_api.py")

# %% [markdown]
## 🧪 Step 2: Test Individual API Endpoints

Let's also test the FastAPI endpoints directly to understand what data is available.

# %% [code]
# Test the FastAPI endpoints directly
print("🧪 Testing FastAPI endpoints directly:")

# Test getting all transactions
try:
    response = requests.get(f"{host}:{port}/transactions")
    if response.status_code == 200:
        transactions = response.json()
        print(f"\n💳 Found {len(transactions)} transactions:")
        for txn in transactions:
            print(f"  {txn['date']}: {txn['description']} - ${txn['amount']:.2f} ({txn['category']})")
    else:
        print(f"❌ Failed to get transactions: {response.status_code}")
except Exception as e:
    print(f"❌ Error testing transactions endpoint: {e}")

# Test getting a specific transaction
try:
    response = requests.get(f"{host}:{port}/transactions/txn_001")
    if response.status_code == 200:
        transaction = response.json()
        print(f"\n🔍 Transaction txn_001 details:")
        print(f"  Date: {transaction['date']}")
        print(f"  Description: {transaction['description']}")
        print(f"  Amount: ${transaction['amount']:.2f}")
        print(f"  Balance: ${transaction['balance']:.2f}")
        print(f"  Category: {transaction['category']}")
    else:
        print(f"❌ Failed to get specific transaction: {response.status_code}")
except Exception as e:
    print(f"❌ Error testing specific transaction endpoint: {e}")

# %% [markdown]
## 📋 Step 3: Fetch the OpenAPI Specification

Now let's fetch the OpenAPI spec from our running FastAPI service.

# %% [code]
# Fetch the OpenAPI specification from the running service
try:    
    openapi_url = f"{host}:{port}/openapi.json"
    response = requests.get(openapi_url)
    
    if response.status_code == 200:
        bank_openapi_spec = response.json()
        print("📋 OpenAPI specification fetched successfully!")
        print(f"API Title: {bank_openapi_spec['info']['title']}")
        print(f"API Version: {bank_openapi_spec['info']['version']}")
        print(f"Available paths: {list(bank_openapi_spec['paths'].keys())}")
    else:
        print(f"❌ Failed to fetch OpenAPI spec: {response.status_code}")
        bank_openapi_spec = None
        
except requests.exceptions.ConnectionError:
    print("❌ Could not connect to FastAPI service to fetch OpenAPI spec")
    bank_openapi_spec = None

# %% [markdown]
### Adding the local FastAPI service to the Azure AI Project

# %% [code]
bank_openapi_spec["servers"] = [
    {
        "url": f"{host}:{port}",
    }
]

print(json.dumps(bank_openapi_spec, indent=2))

# %% [markdown]
## 🤖 Step 4: Create Azure AI Agent with FastAPI Tools

Now we'll create an Azure AI Agent that can call our FastAPI endpoints.

# %% [code]
# Create Azure AI Agent with FastAPI OpenAPI tools
async def create_bank_agent():
    if bank_openapi_spec is None:
        print("❌ Cannot create agent without OpenAPI spec")
        return
    
    endpoint = os.environ["PROJECT_ENDPOINT"]
    model_deployment = os.environ["MODEL_DEPLOYMENT_NAME"]

    async with (
        DefaultAzureCredential() as creds,
        AzureAIAgent.create_client(credential=creds, endpoint=endpoint) as client,
    ):
        print("🔗 Creating Azure AI Agent with FastAPI tools...")
        
        # Create OpenAPI tool for bank transactions
        auth = OpenApiAnonymousAuthDetails()
        
        bank_tool = OpenApiTool(
            name="bank_transactions",
            spec=bank_openapi_spec,
            description="Get bank transaction data from the local FastAPI service",
            auth=auth
        )
        
        # Create Azure AI agent with the FastAPI tool
        agent_definition = await client.agents.create_agent(
            model=model_deployment,
            name="bank_assistant",
            instructions="""You are a helpful bank assistant. Use the bank transactions API to help users understand their financial data. 
            Always provide clear explanations of transactions, categorize spending, and offer helpful insights about financial patterns.
            When showing transactions, format them nicely and explain what each field means.""",
            tools=bank_tool.definitions
        )
        
        # Wrap as AzureAIAgent
        bank_agent = AzureAIAgent(
            client=client,
            definition=agent_definition
        )
        
        print(f"🏦 Bank assistant agent created: {agent_definition.id}")
        
        # Test queries
        test_queries = [
            "Show me my latest bank transactions and tell me how much I spent on food.",
            "What was my largest expense recently and what category was it in?",
            "Can you give me a summary of my account balance and recent activity?"
        ]
        
        thread = None
        
        try:
            for i, query in enumerate(test_queries, 1):
                print(f"\n🧪 Test Query {i}:")
                print(f"👤 User: {query}")
                
                # Invoke the agent
                async for response in bank_agent.invoke(messages=query, thread=thread):
                    if response.role != AuthorRole.TOOL:
                        print(f"🏦 Bank Assistant: {response.content}")
                    thread = response.thread
                
                print("\n" + "="*50)
        
        finally:
            # Cleanup
            await client.agents.delete_agent(agent_definition.id)
            print("\n🧹 Bank agent cleaned up")

# Run the bank agent
await create_bank_agent()
print("\n✅ Bank assistant demonstration complete!")

# %% [markdown]
## 🛑 Step 5: Cleanup

Finally, let's stop the FastAPI service.

Please go to the shell, and kill the process running the FastAPI service. You can do this by pressing `Ctrl+C` in the terminal where the service is running.

# %% [markdown]
---

## 🎯 Key Takeaways

✅ **FastAPI Integration:**
- FastAPI automatically generates OpenAPI specifications
- Azure AI Agents can consume any OpenAPI-compliant service
- Local development services work seamlessly with cloud agents

✅ **Dynamic API Discovery:**
- Fetch OpenAPI specs from running services
- No need to manually create API definitions
- Agents automatically understand available endpoints

✅ **Real-world Applications:**
- Connect agents to internal business APIs
- Integrate with existing microservices
- Create conversational interfaces for data services

### 💡 Best Practices:

🔒 **Security**: Use proper authentication for production APIs
📝 **Documentation**: Ensure OpenAPI specs have good descriptions
⚡ **Performance**: Consider rate limiting and caching
🧪 **Testing**: Always test both API endpoints and agent integration
🔄 **Error Handling**: Implement robust error handling in both API and agent

### 🚀 Next Steps:

- Add authentication to your FastAPI service
- Create more complex business logic APIs
- Combine multiple microservices with one agent
- Deploy both API and agents to production

**Happy API integrating!** 🎉

################################################################################  05-orchestrated-agents-with-custom-openapi-tools\bank_transactions_api.py  ################################################################################
"""
FastAPI Bank Transactions Service

A simple FastAPI service that provides sample bank transaction data
and exposes its OpenAPI specification at /openapi.json
"""

from fastapi import FastAPI
from typing import List, Dict, Any
from datetime import datetime, timedelta
import random

app = FastAPI(
    title="Bank Transactions API",
    description="Returns sample bank transaction data for demonstration purposes",
    version="1.0.0"
)

# Sample bank transaction data
SAMPLE_TRANSACTIONS = [
    {
        "id": "txn_001",
        "date": "2024-12-01",
        "description": "Grocery Store Purchase",
        "amount": -85.47,
        "balance": 2914.53,
        "category": "Food & Dining"
    },
    {
        "id": "txn_002", 
        "date": "2024-12-02",
        "description": "Salary Deposit",
        "amount": 3500.00,
        "balance": 6414.53,
        "category": "Income"
    },
    {
        "id": "txn_003",
        "date": "2024-12-03", 
        "description": "Gas Station",
        "amount": -45.20,
        "balance": 6369.33,
        "category": "Transportation"
    },
    {
        "id": "txn_004",
        "date": "2024-12-04",
        "description": "Online Shopping",
        "amount": -129.99,
        "balance": 6239.34,
        "category": "Shopping"
    },
    {
        "id": "txn_005",
        "date": "2024-12-05",
        "description": "Coffee Shop",
        "amount": -5.75,
        "balance": 6233.59,
        "category": "Food & Dining"
    }
]

@app.get("/")
async def root():
    """Root endpoint with service information"""
    return {
        "service": "Bank Transactions API",
        "version": "1.0.0",
        "endpoints": {
            "transactions": "/transactions",
            "openapi": "/openapi.json",
            "docs": "/docs"
        }
    }

@app.get("/transactions", response_model=List[Dict[str, Any]])
async def get_latest_transactions(limit: int = 10):
    """
    Get the latest bank transactions
    
    Args:
        limit: Maximum number of transactions to return (default: 10)
    
    Returns:
        List of bank transactions with id, date, description, amount, balance, and category
    """
    # Always return the same sample data for consistency
    return SAMPLE_TRANSACTIONS[:limit]

@app.get("/transactions/{transaction_id}")
async def get_transaction(transaction_id: str):
    """
    Get a specific transaction by ID
    
    Args:
        transaction_id: The unique transaction identifier
        
    Returns:
        Transaction details or 404 if not found
    """
    for transaction in SAMPLE_TRANSACTIONS:
        if transaction["id"] == transaction_id:
            return transaction
    
    return {"error": "Transaction not found"}, 404

if __name__ == "__main__":
    import uvicorn
    import sys
    
    # Default port
    port = 8000
    
    # Check if port number is provided as command line argument
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
            print(f"🚀 Starting server on port {port}")
        except ValueError:
            print(f"❌ Invalid port number: {sys.argv[1]}. Using default port 8000.")
            port = 8000
    else:
        print(f"🚀 Starting server on default port {port}")
        print(f"💡 Usage: python {sys.argv[0]} <port_number>")
    
    uvicorn.run(app, host="0.0.0.0", port=port)

################################################################################  05-orchestrated-agents-with-custom-openapi-tools\README.md  ################################################################################
# Orchestrated Agents with Custom OpenAPI Tools

Learn how to connect Azure AI Agents to your own custom FastAPI services. Build agents that understand and interact with your business data through standardized OpenAPI specifications.

## What You'll Learn

- Create RESTful APIs with FastAPI and automatic OpenAPI spec generation
- Connect agents to custom APIs using OpenAPI tools
- Deploy services locally and to Azure Container Apps
- Build agents that work with real business data (banking transactions)

## Architecture

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   Azure AI      │    │   Custom FastAPI │    │   Azure         │
│   Agents        │◄──►│   Service        │    │   Container     │
│                 │    │                  │    │   Apps          │
└─────────────────┘    └──────────────────┘    └─────────────────┘
```

![SK Orchestration](images/sk_orchestration.gif)

## Project Structure

```
05-orchestrated-agents-with-custom-openapi-tools/
├── 05.1-fastapi_openapi_tutorial.ipynb    # Main tutorial notebook
├── bank_transactions_api.py                # FastAPI service implementation
├── Dockerfile                             # Container configuration
├── aci_requirements.txt                   # Python dependencies
├── azure.yaml                            # Azure Developer CLI configuration
├── infra/                                # Infrastructure as Code
└── arm/                                  # ARM template for one-click deploy
```
│       └── uami.bicep                   # User Assigned Managed Identity
└── arm/                                  # ARM template for one-click deploy
    └── main.json                        # ARM template
```

## Quick Start

### Option 1: One-Click Azure Deployment

[![Deploy to Azure](https://aka.ms/deploytoazurebutton)](https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2FAzure-Samples%2Fazure-ai-agents-playbook%2Fmain%2F05-orchestrated-agents-with-custom-openapi-tools%2Farm%2Fmain.json)

### Option 2: Azure Developer CLI

```bash
# Clone and deploy
git clone https://github.com/Azure-Samples/azure-ai-agents-playbook.git
cd azure-ai-agents-playbook/05-orchestrated-agents-with-custom-openapi-tools
azd up
```

### Option 3: Local Development

```bash
# Install dependencies and run locally
pip install -r aci_requirements.txt
python bank_transactions_api.py 8000

# In another terminal
jupyter notebook 05.1-fastapi_openapi_tutorial.ipynb
```
   - Create a new resource group
   - Deploy Azure Container Registry
   - Set up Azure Container Apps Environment
   - Deploy Log Analytics workspace for monitoring## Prerequisites

### Azure Resources
- Azure AI Project with deployed language model
- Azure subscription with appropriate permissions

### Environment Variables
Set these in your `.env` file at the project root:

```properties
PROJECT_ENDPOINT="https://your-foundry-resource.services.ai.azure.com/api/projects/your-project-name"
MODEL_DEPLOYMENT_NAME="gpt-4o"  # or your deployed model name
```

### Required Python Packages
```bash
pip install azure-ai-agents azure-identity semantic-kernel fastapi uvicorn requests python-dotenv
```

## Features

### Bank Transactions API
- `GET /transactions` - Retrieve latest bank transactions
- `GET /transactions/{id}` - Get specific transaction details
- `GET /openapi.json` - OpenAPI specification endpoint
- `GET /docs` - Interactive API documentation

### Azure AI Agent Capabilities
- Connect to FastAPI endpoints using OpenAPI specifications
- Ask natural language questions about financial data
- Get insights, summaries, and categorized spending analysis
- Work with real-time data from live API endpoints

## Tutorial Walkthrough

The `05.1-fastapi_openapi_tutorial.ipynb` notebook covers:

1. **Setup and Prerequisites** - Environment configuration
2. **Start FastAPI Service** - Launch the bank transactions API
3. **Test API Endpoints** - Verify the service works correctly
4. **Fetch OpenAPI Spec** - Retrieve the API specification
5. **Create Azure AI Agent** - Build an agent with OpenAPI tools
6. **Interactive Testing** - Query the agent with natural language

## Example Use Cases

**Financial Assistant queries:**
- "Show me my latest bank transactions and how much I spent on food"
- "What was my largest expense recently and what category was it?"
- "Give me a summary of my account balance and recent activity"

**Integration Patterns:**
- Connect agents to existing business APIs
- Enable conversational queries over structured data
- Create workflow automation with business processes
- Build real-time monitoring and reporting systems

## Next Steps

After completing this tutorial:
- [06-magentic-one-orchestration](../06-magentic-one-orchestration/) - Advanced orchestration patterns
- [07-voice-orchestration](../07-voice-orchestration/) - Voice-enabled agents

################################################################################  06-magentic-one-orchestration\06.1-magentic_creative_writing_tutorial.ipynb  ################################################################################
# %% [markdown]
# Magentic-One Creative Pipeline Orchestration

🎪 **Simple Multi-Agent Creative System**

This tutorial demonstrates:
- **Magentic-One orchestration** with Semantic Kernel
- **Three specialized Azure AI Agents** working together
- **Local plugins with feedback loops**
- **Creative content pipeline**: Joke → Haiku → French Translation

**Architecture:**
```
┌─────────────────────────────────────────────────────────────┐
│                    Magentic Orchestration                   │
│                (StandardMagenticManager)                    │
└─────────────────────┬───────────────────────────────────────┘
                      │
    ┌─────────────────┼─────────────────┐
    │                 │                 │
┌───▼────┐    ┌──────▼──────┐    ┌─────▼─────┐
│ Joke   │    │   Haiku     │    │  French   │
│Writer  │    │ Converter   │    │Translator │
│(Azure) │    │  (Azure)    │    │ (Azure)   │
└───┬────┘    └──────┬──────┘    └─────┬─────┘
    │                │                 │
┌───▼────┐    ┌──────▼──────┐    ┌─────▼─────┐
│Topic   │    │ Haiku       │    │    No     │
│Plugin  │    │Classifier   │    │  Plugin   │
│(Local) │    │ (Local)     │    │           │
└────────┘    └─────────────┘    └───────────┘
```

**Use Case**: "*Create a joke → convert to haiku → translate to French with feedback loops*"

---

# %% [markdown]
## 🔧 Setup and Prerequisites

**Environment Variables Required:**
- `PROJECT_ENDPOINT`: Your Azure AI Project endpoint
- `MODEL_DEPLOYMENT_NAME`: Your deployed AI model name
- `AZURE_OPENAI_API_KEY`: Your Azure OpenAI API key
- `AZURE_OPENAI_ENDPOINT`: Your Azure OpenAI endpoint

**Azure Configuration:**
- Uses **Azure AI Agents** (not ChatCompletionAgent)
- Uses **AzureChatCompletion** service (not OpenAIChatCompletion)
- Automatically configures Azure OpenAI connection using environment variables
- Compatible with Azure AI Studio deployments

**Simple Architecture:**
1. **Azure AI Agents**: Deployed on Azure (managed service)
2. **Magentic Orchestrator**: Runs in local environment
3. **Local Plugins**: Topic selection, haiku classification
4. **No External APIs**: Simple, reliable testing scenario

**Creative Pipeline Flow:**
- Joke Writer selects topic and creates joke
- Haiku Converter transforms joke to haiku and classifies length
- French Translator converts approved haiku to French

# %% [markdown]
![SK Orchestration](images/sk_orchestration.gif)

# %% [code]
# Install required packages for Magentic orchestration
# !pip install azure-ai-agents azure-identity semantic-kernel

import os
import json
import asyncio
import random
import tempfile
from datetime import datetime, timedelta
from typing import List

# Azure AI Agents and Semantic Kernel imports
from azure.identity.aio import DefaultAzureCredential
from semantic_kernel.agents import (
    Agent,
    AzureAIAgent,
    MagenticOrchestration,
    StandardMagenticManager,
)
from semantic_kernel.agents.runtime import InProcessRuntime
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
from semantic_kernel.contents import ChatMessageContent, AuthorRole
from semantic_kernel.functions import kernel_function
from semantic_kernel.agents.open_ai.run_polling_options import RunPollingOptions

print("✅ Packages imported successfully!")
print(f"📅 Tutorial started at: {datetime.now()}")
print("🎪 Using Azure AI Agents for Creative Pipeline")

# %% [markdown]
## 🎯 Step 1: Test Environment Setup

Let's verify our environment is ready for the creative pipeline with no external dependencies.

# %% [code]
# Simple environment verification
print("🎪 Testing Creative Pipeline Environment...")

# Check required environment variables
required_vars = ["PROJECT_ENDPOINT", "MODEL_DEPLOYMENT_NAME"]
missing_vars = []

for var in required_vars:
    if var in os.environ:
        print(f"✅ {var}: {'*' * (len(os.environ[var]) - 10)}{os.environ[var][-10:]}")
    else:
        missing_vars.append(var)
        print(f"❌ {var}: Missing")

if missing_vars:
    print(f"\n⚠️ Missing environment variables: {', '.join(missing_vars)}")
    print("Please set these before running the orchestration.")
else:
    print("\n✅ All required environment variables are set!")

# Test temporary file creation (used by haiku classifier)
try:
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=True) as temp_file:
        temp_file.write("Test haiku content")
        print("✅ Temporary file creation works!")
except Exception as e:
    print(f"❌ Temporary file creation failed: {e}")

print(f"\n🎯 Environment ready for creative pipeline at: {datetime.now()}")

# %% [markdown]
## 🧩 Step 2: Create Creative Plugins

These plugins will run locally and provide the creative capabilities for our joke-haiku-translation pipeline.

# %% [code]
class JokeTopicPlugin:
    """Plugin for joke generation with random topic selection"""
    
    def __init__(self):
        self.topics = [
            "cats", "programming", "coffee", "weather", "cooking",
            "travel", "sports", "technology", "books", "music"
        ]

    @kernel_function(
        description="Select a random topic for joke generation from a predefined list",
        name="get_random_topic"
    )
    def get_random_topic(self) -> str:
        """Returns a random topic for joke generation"""
        topic = random.choice(self.topics)
        print(f"🎯 Selected random topic: {topic}")
        return topic

    @kernel_function(
        description="Get all available joke topics",
        name="get_all_topics"
    )
    def get_all_topics(self) -> str:
        """Returns all available joke topics"""
        return json.dumps({"topics": self.topics}, indent=2)

# Initialize the plugin
joke_topic_plugin = JokeTopicPlugin()
print("✅ Joke Topic Plugin created successfully!")
print(f"📝 Available topics: {', '.join(joke_topic_plugin.topics)}")

# %% [code]
class HaikuClassifierPlugin:
    """Plugin for haiku analysis and classification"""
    
    @kernel_function(
        description="Classify haiku as short or long based on character count and save to temp file",
        name="classify_haiku_length"
    )
    def classify_haiku_length(self, haiku_text: str) -> str:
        """Classify haiku length and save to temporary file"""
        
        # Save haiku to temporary file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as temp_file:
            temp_file.write(haiku_text)
            temp_filepath = temp_file.name
        
        # Count characters (excluding whitespace)
        char_count = len(haiku_text.replace(' ', '').replace('\n', ''))
        
        # Classification logic
        if char_count < 50:
            classification = "short"
            feedback = "Please generate a longer joke - the haiku is too short"
        elif char_count > 100:
            classification = "long" 
            feedback = "Please generate a shorter joke - the haiku is too long"
        else:
            classification = "perfect"
            feedback = "Good length - ready to send to translator"
        
        result = {
            "haiku_text": haiku_text,
            "character_count": char_count,
            "classification": classification,
            "feedback": feedback,
            "temp_file_path": temp_filepath,
            "ready_for_translation": classification == "perfect"
        }
        
        print(f"📏 Haiku classified: {classification} ({char_count} chars)")
        print(f"💾 Saved to: {temp_filepath}")
        
        return json.dumps(result, indent=2)

    @kernel_function(
        description="Read haiku from temporary file",
        name="read_haiku_from_file"
    )
    def read_haiku_from_file(self, file_path: str) -> str:
        """Read haiku content from specified file path"""
        try:
            with open(file_path, 'r') as file:
                content = file.read()
            return content
        except Exception as e:
            return f"Error reading file: {str(e)}"

# Initialize the plugin
haiku_classifier_plugin = HaikuClassifierPlugin()
print("✅ Haiku Classifier Plugin created successfully!")
print("📊 Classification rules: <50 chars = short, >100 chars = long, 50-100 chars = perfect")

# %% [markdown]
## 🧪 Step 3: Test Creative Plugins

Let's test our local plugins to ensure they work correctly before creating the agents.

# %% [code]
# Test the creative plugins
print("🧪 Testing Creative Plugins")
print("=" * 50)

# Test 1: Joke Topic Plugin
print("\n1. Testing Joke Topic Selection:")
random_topic = joke_topic_plugin.get_random_topic()
print(f"   Random topic: {random_topic}")

all_topics = joke_topic_plugin.get_all_topics()
print(f"   All topics: {json.loads(all_topics)['topics']}")

# Test 2: Haiku Classifier Plugin
print("\n2. Testing Haiku Classification:")

# Test with short haiku
short_haiku = "Cat sits\nOn warm laptop keys\nZzz..."
short_result = haiku_classifier_plugin.classify_haiku_length(short_haiku)
short_classification = json.loads(short_result)
print(f"   Short haiku result: {short_classification['classification']} ({short_classification['character_count']} chars)")

# Test with long haiku
long_haiku = """The programming bug hides deep within nested loops and complex algorithms
Coffee grows cold as developers search through infinite lines of code seeking solutions
Eureka moment arrives with dawn breaking through tired eyes and weary minds finally at rest"""
long_result = haiku_classifier_plugin.classify_haiku_length(long_haiku)
long_classification = json.loads(long_result)
print(f"   Long haiku result: {long_classification['classification']} ({long_classification['character_count']} chars)")

# Test with perfect haiku
perfect_haiku = """Morning coffee brews
Steam rises from ceramic cup
Productivity starts"""
perfect_result = haiku_classifier_plugin.classify_haiku_length(perfect_haiku)
perfect_classification = json.loads(perfect_result)
print(f"   Perfect haiku result: {perfect_classification['classification']} ({perfect_classification['character_count']} chars)")

# Test file reading
print(f"\n3. Testing File Reading:")
if perfect_classification.get('temp_file_path'):
    file_content = haiku_classifier_plugin.read_haiku_from_file(perfect_classification['temp_file_path'])
    print(f"   File content matches: {file_content == perfect_haiku}")

print("\n✅ All creative plugins tested successfully!")

# %% [markdown]
## 🤖 Step 4: Create Specialized Creative Agents

We'll create three specialized agents that will work together in the Magentic orchestration:
1. **Joke Writer**: Selects topics and creates jokes
2. **Haiku Converter**: Transforms jokes to haikus and provides feedback
3. **French Translator**: Translates approved haikus to French

# %% [code]
def agent_response_callback(message: ChatMessageContent) -> None:
    """Observer function to print agent messages"""
    if message.role != AuthorRole.TOOL:
        print(f"\n🎭 **{message.name}**")
        print(f"   {message.content}")
        print("-" * 60)

async def create_creative_agents() -> List[Agent]:
    """Create three specialized agents for the joke-haiku-translation pipeline"""
    
    endpoint = os.environ["PROJECT_ENDPOINT"]
    model_deployment = os.environ["MODEL_DEPLOYMENT_NAME"]
    agents = []
    
    print("🎪 Creating Creative Pipeline Agents...")
    
    async with DefaultAzureCredential() as creds:
        client = AzureAIAgent.create_client(credential=creds, endpoint=endpoint)
        
        # 1. Joke Writer Agent
        print("😂 Creating Joke Writer Agent...")
        joke_writer_definition = await client.agents.create_agent(
            model=model_deployment,
            name="joke_writer",
            description="Creative joke writer with topic selection capabilities",
            instructions="""
            You are a creative joke writer. Your role is to:
            - Use the available plugin to select random topics for jokes
            - Write funny, clean jokes based on the selected topics
            - Adjust joke length based on feedback from the haiku agent
            - If told to make jokes longer, add more setup or details
            - If told to make jokes shorter, be more concise and punchy
            
            Always be creative and family-friendly. Listen to feedback and adjust accordingly.
            """
        )
        
        joke_writer = AzureAIAgent(
            client=client,
            definition=joke_writer_definition,
            polling_options=RunPollingOptions(default_polling_interval=timedelta(milliseconds=3000)),
            plugins=[joke_topic_plugin]
        )
        agents.append(joke_writer)
        print(f"✅ Joke Writer: {joke_writer_definition.id}")
        
        # 2. Haiku Converter Agent  
        print("🌸 Creating Haiku Converter Agent...")
        haiku_converter_definition = await client.agents.create_agent(
            model=model_deployment,
            name="haiku_converter",
            description="Converts jokes to haikus and provides length feedback",
            instructions="""
            You are a haiku poetry expert. Your role is to:
            - Convert jokes into traditional haiku format (5-7-5 syllable pattern)
            - Use the classifier plugin to analyze haiku length
            - Provide feedback to the joke writer about length adjustments needed
            - Only approve haikus that are the right length for translation
            
            Remember: Traditional haiku should capture the essence of the joke while following the 5-7-5 syllable structure.
            Use your plugin to classify the length and provide appropriate feedback.
            """
        )
        
        haiku_converter = AzureAIAgent(
            client=client,
            definition=haiku_converter_definition,
            polling_options=RunPollingOptions(default_polling_interval=timedelta(milliseconds=3000)),
            plugins=[haiku_classifier_plugin]
        )
        agents.append(haiku_converter)
        print(f"✅ Haiku Converter: {haiku_converter_definition.id}")
        
        # 3. French Translator Agent
        print("🇫🇷 Creating French Translator Agent...")
        french_translator_definition = await client.agents.create_agent(
            model=model_deployment,
            name="french_translator",
            description="Translates haikus from English to French",
            instructions="""
            You are an expert French translator specializing in poetry. Your role is to:
            - Translate English haikus into beautiful, flowing French
            - Maintain the poetic essence and rhythm when possible
            - Ensure the translation captures the humor of the original joke
            - Provide both the French translation and a brief explanation of any cultural adaptations made
            
            Focus on creating elegant French that preserves both the meaning and artistic quality of the haiku.
            Just output the translated haiku with no additional commentary or explanations.
            """
        )
        
        french_translator = AzureAIAgent(
            client=client,
            definition=french_translator_definition,
            polling_options=RunPollingOptions(default_polling_interval=timedelta(milliseconds=3000)),
            # No plugins - pure translation work
        )
        agents.append(french_translator)
        print(f"✅ French Translator: {french_translator_definition.id}")
    
    print(f"✅ Created {len(agents)} agents total")
    return agents

# Test agent creation
print("🎪 Ready to create creative agents...")

# %% [markdown]
## 🎭 Step 5: Create Magentic-One Creative Orchestration

Now we'll create the Magentic orchestration that will coordinate our creative agents to transform jokes into French haikus.

# %% [code]
async def create_creative_orchestration() -> MagenticOrchestration:
    """Create and configure the creative Magentic orchestration"""
    
    print("🎭 Setting up Creative Magentic-One orchestration...")
    
    # Create creative agents
    agents = await create_creative_agents()
    
    # Configure Azure Chat Completion for the manager
    manager_azure_chat_completion = AzureChatCompletion()
    
    # Create the Magentic orchestration
    # The StandardMagenticManager coordinates agent interactions
    creative_orchestration = MagenticOrchestration(
        members=agents,
        manager=StandardMagenticManager(
            chat_completion_service=manager_azure_chat_completion
        ),
        agent_response_callback=agent_response_callback,
    )
    
    print(f"✅ Creative orchestration created with {len(agents)} agents")
    print("   Agents: " + ", ".join([agent.name for agent in agents]))
    
    return creative_orchestration

print("🎯 Creative orchestration configuration ready")

# %% [markdown]
## 🚀 Step 6: Execute Creative Pipeline Task

Now let's execute our creative use case: **"Create a joke → convert to haiku → translate to French"**

This will involve:
1. Joke Writer selecting a topic and creating a joke
2. Haiku Converter transforming the joke and checking length
3. French Translator converting the approved haiku
4. Feedback loops for length adjustments

# %% [code]
async def execute_creative_pipeline_task():
    """Execute the creative pipeline task using Magentic orchestration"""
    
    print("🎪 Starting Creative Pipeline Task")
    print("=" * 70)
    
    # Create the orchestration
    orchestration = await create_creative_orchestration()
    
    # Create and start runtime
    runtime = InProcessRuntime()
    runtime.start()
    
    try:
        # Define the creative task
        creative_task = """
        I want you to create a creative pipeline:
        
        1. Joke Writer: Select a random topic and write a funny joke about it
        2. Haiku Converter: Convert the joke into a haiku and check if the length is appropriate
           - If too short, ask joke writer for a longer joke
           - If too long, ask joke writer for a shorter joke  
           - If just right, proceed to translation
        3. French Translator: Translate the approved haiku into beautiful French
        
        Please work together to create one perfect joke-haiku-translation sequence.
        Make sure to use the plugins for topic selection and haiku classification.
        """
        
        print("📋 Creative Task Definition:")
        print(creative_task)
        print("\n" + "=" * 70)
        print("🎭 Beginning Creative Orchestration...")
        print("=" * 70)
        
        # Execute the orchestration
        orchestration_result = await orchestration.invoke(
            task=creative_task,
            runtime=runtime
        )
        
        # Wait for the results
        result = await orchestration_result.get()

        # Display final results
        print("\n" + "=" * 70)
        print("🎯 CREATIVE ORCHESTRATION COMPLETE")
        print("\n🎨 Final Creative Result:")
        print(f"\n{result}")
        print("=" * 70)
        
    except Exception as e:
        print(f"❌ Error during orchestration: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Cleanup
        await runtime.stop()
        print("\n🧹 Runtime stopped and resources cleaned up")

# Execute the creative task
print("🌟 Ready to execute creative pipeline task!")
print("This will involve three agents working together through Magentic orchestration.")

# %% [code]
# Run the creative pipeline task
await execute_creative_pipeline_task()

# %% [markdown]
## 🧪 Step 7: Test Individual Creative Agents

Let's test our creative agents individually to ensure they work correctly.

# %% [code]
async def test_individual_creative_agents():
    """Test individual creative agents manually"""
    
    print("🧪 Testing Individual Creative Agents")
    print("=" * 50)
    
    endpoint = os.environ["PROJECT_ENDPOINT"]
    model_deployment = os.environ["MODEL_DEPLOYMENT_NAME"]
    
    # Create individual agents for testing
    async with DefaultAzureCredential() as creds:
        client = AzureAIAgent.create_client(credential=creds, endpoint=endpoint)
        
        # Test Joke Writer Agent
        print("\n1. Testing Joke Writer Agent:")
        joke_agent_definition = await client.agents.create_agent(
            model=model_deployment,
            name="test_joke_writer",
            instructions="You are a joke writer. Use your plugin to select a topic and write a short joke about it."
        )
        
        joke_agent = AzureAIAgent(
            client=client,
            definition=joke_agent_definition,
            plugins=[joke_topic_plugin]
        )
        
        test_joke_query = "Please select a random topic and write a short joke about it."
        print(f"   Query: {test_joke_query}")
        
        async for response in joke_agent.invoke(test_joke_query):
            if response.role != AuthorRole.TOOL:
                print(f"   Response: {response.content}")
                break
        
        # Test Haiku Converter Agent
        print("\n2. Testing Haiku Converter Agent:")
        haiku_agent_definition = await client.agents.create_agent(
            model=model_deployment,
            name="test_haiku_converter",
            instructions="You convert text to haikus and classify their length using your plugin."
        )
        
        haiku_agent = AzureAIAgent(
            client=client,
            definition=haiku_agent_definition,
            plugins=[haiku_classifier_plugin]
        )
        
        test_haiku_query = "Convert this joke to a haiku and classify its length: Why do programmers prefer dark mode? Because light attracts bugs!"
        print(f"   Query: {test_haiku_query}")
        
        async for response in haiku_agent.invoke(test_haiku_query):
            if response.role != AuthorRole.TOOL:
                print(f"   Response: {response.content}")
                break

print("🧪 Individual agent testing ready")

# %% [code]
# Run individual agent tests
await test_individual_creative_agents()

# %% [markdown]
## 🎯 Step 8: Summary and Cleanup

Let's clean up resources and provide a summary of what we've accomplished.

# %% [code]
# Cleanup and summary
print("🧹 Cleaning up resources...")

print("✅ Cleanup completed")

print("\n" + "=" * 70)
print("🎪 CREATIVE PIPELINE TUTORIAL SUMMARY")
print("=" * 70)

summary = """
🌟 What We Accomplished:

✅ Simple Architecture Implementation:
   • Three Azure AI Agents working together
   • Local plugins for creative capabilities
   • Magentic-One orchestration coordination
   • No external API dependencies

✅ Agent Specialization:
   • Joke Writer: Topic selection and joke creation
   • Haiku Converter: Poetry transformation and length analysis
   • French Translator: Language translation

✅ Technical Components:
   • Local Python plugins with @kernel_function decorators
   • File-based temporary storage for haiku classification
   • Random topic selection from predefined list
   • Feedback loops between agents

✅ Creative Task Execution:
   • "Create joke → convert to haiku → translate to French"
   • Multi-agent coordination through Magentic orchestration
   • Length-based feedback for joke adjustment
   • Cultural adaptation in French translation

🏗️ System Architecture Benefits:
   • Simple: No external dependencies or complex APIs
   • Reliable: Local plugins reduce network failure points
   • Educational: Clear demonstration of agent collaboration
   • Testable: Easy to debug and understand

💡 Key Learning Points:
   • Magentic orchestration enables complex multi-agent workflows
   • Local plugins provide specialized capabilities
   • Feedback loops allow iterative improvement
   • Azure AI Agents can be combined with local processing
   • Creative use cases are perfect for demonstrating agent coordination
"""

print(summary)

print("\n🎉 Creative Pipeline Tutorial completed successfully!")
print(f"⏰ Completed at: {datetime.now()}")

################################################################################  06-magentic-one-orchestration\06.2-magentic_bing_search_orchestration_tutorial.ipynb  ################################################################################
# %% [markdown]
# Magentic-One Research Pipeline with Bing Search

🔍 **Advanced Multi-Agent Research System**

This tutorial demonstrates:
- **Magentic-One orchestration** with complex research tasks
- **Bing Search-powered Azure AI Agents** for web research
- **Multi-step information retrieval** with intelligent coordination
- **Complex query decomposition** and fact verification

**Architecture:**
```
┌─────────────────────────────────────────────────────────────┐
│                    Magentic Orchestration                   │
│                (StandardMagenticManager)                    │
└─────────────────────┬───────────────────────────────────────┘
                      │
    ┌─────────────────┼─────────────────┐
    │                 │                 │
┌───▼────┐    ┌──────▼──────┐    ┌─────▼─────┐
│Research│    │   Fact      │    │ Report    │
│ Agent  │    │ Checker     │    │Generator  │
│(Bing)  │    │  (Bing)     │    │  (Azure)  │
└───┬────┘    └──────┬──────┘    └─────┬─────┘
    │                │                 │
┌───▼────┐    ┌──────▼──────┐    ┌─────▼─────┐
│ Web    │    │Cross-verify │    │  Final    │
│Search  │    │Information  │    │ Report    │
│Tool    │    │   Tool      │    │Generator  │
└────────┘    └─────────────┘    └───────────┘
```

**Use Case**: *"From which university did the chief of staff of the 43rd president of the US get his degree from? And in what specialty?"*

This requires:
1. Identifying the 43rd president of the US
2. Finding who was their chief of staff
3. Researching the chief of staff's educational background
4. Cross-verifying the information
5. Generating a comprehensive report

---

# %% [markdown]
## 🔧 Setup and Prerequisites

**Environment Variables Required:**
- `PROJECT_ENDPOINT`: Your Azure AI Project endpoint
- `MODEL_DEPLOYMENT_NAME`: Your deployed AI model name
- `AZURE_FOUNDRY_PROJECT_ENDPOINT`: Your Azure AI Foundry project endpoint

**Azure Configuration:**
- Uses **Azure AI Agents** with Bing Search grounding
- Uses **AzureChatCompletion** service for orchestration
- Automatically discovers Bing Search connections
- Compatible with Azure AI Studio deployments

**Research Architecture:**
1. **Research Agent**: Primary web search and information gathering
2. **Fact Checker Agent**: Cross-verification of found information
3. **Report Generator Agent**: Synthesis and final report creation
4. **Magentic Orchestrator**: Coordinates complex multi-step research

**Complex Research Flow:**
- Decomposes complex questions into searchable parts
- Performs sequential web searches with context awareness
- Cross-verifies information from multiple sources
- Generates comprehensive, cited reports

# %% [markdown]
![SK Orchestration](images/sk_orchestration.gif)

# %% [markdown]

### Configuration Steps of the Grounding with Bing Search Connection

Please follow the below two links to properly configure the Grounding with Bing Search Connection in Azure AI Studio:

- [Create a Grounding with Bing Search Connection](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/bing-grounding)
- [Create a Grounding with Bing Search Connection in Azure AI Studio](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/bing-code-samples?pivots=portal)

# %% [code]
# Install required packages for Magentic orchestration with Bing search
# !pip install azure-ai-agents azure-identity semantic-kernel azure-ai-projects

import os
import json
import asyncio
from datetime import datetime, timedelta
from typing import List, Optional

# Azure AI Agents and Semantic Kernel imports
from azure.identity.aio import DefaultAzureCredential
from azure.ai.projects.aio import AIProjectClient
from semantic_kernel.agents import (
    Agent,
    AzureAIAgent,
    MagenticOrchestration,
    StandardMagenticManager,
)
from semantic_kernel.agents.runtime import InProcessRuntime
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
from semantic_kernel.contents import ChatMessageContent, AuthorRole
from semantic_kernel.agents.open_ai.run_polling_options import RunPollingOptions

# Azure AI Agents client imports
from azure.ai.agents import AgentsClient
from azure.ai.agents.models import MessageRole, BingGroundingTool

print("✅ Packages imported successfully!")
print(f"📅 Tutorial started at: {datetime.now()}")
print("🔍 Using Azure AI Agents with Bing Search for Research Pipeline")

# %% [markdown]
## 🌐 Step 1: Discover Bing Search Connection

Let's discover and configure the Bing Search connection for our research agents.

# %% [code]
# Discover Bing Search connection
async def discover_bing_connection() -> Optional[str]:
    """Discover and return the Bing Search connection ID"""
    
    print("🔍 Discovering Bing Search connections...")
    
    try:
        # Get project endpoint from environment
        project_endpoint = os.environ.get("AZURE_FOUNDRY_PROJECT_ENDPOINT") or os.environ.get("PROJECT_ENDPOINT")
        
        if not project_endpoint:
            print("❌ No project endpoint found in environment variables")
            return None
            
        async with DefaultAzureCredential() as creds:
            project_client = AIProjectClient(
                endpoint=project_endpoint,
                credential=creds,
                api_version="2025-05-15-preview"
            )
            
            # List all connections and find Bing Search
            bing_connections = []
            async for connection in project_client.connections.list():
                print(f"📋 Found connection: {connection.name} (Type: {connection.type})")
                if connection.type == "GroundingWithBingSearch":
                    bing_connections.append(connection)
                    print(f"✅ Bing Search connection found: {connection.id}")
            
            if bing_connections:
                selected_connection = bing_connections[0]  # Use first available
                print(f"🎯 Selected Bing connection: {selected_connection.name}")
                return selected_connection.id
            else:
                print("❌ No Bing Search connections found")
                print("💡 Please create a Bing Search connection in Azure AI Studio")
                return None
                
    except Exception as e:
        print(f"❌ Error discovering Bing connection: {e}")
        return None

# Test connection discovery
print("🌐 Testing Bing Search connection discovery...")

# %% [code]
# Discover the Bing connection
bing_connection_id = await discover_bing_connection()

if bing_connection_id:
    print(f"✅ Bing connection ready: {bing_connection_id[-50:]}...")  # Show last 50 chars for security
else:
    print("⚠️ No Bing connection available - will use basic agents without web search")

# %% [markdown]
## 🤖 Step 2: Create Research-Specialized Agents

We'll create three specialized agents for complex research tasks:
1. **Research Agent**: Primary web search and information gathering
2. **Fact Checker Agent**: Cross-verification and accuracy checking
3. **Report Generator Agent**: Synthesis and comprehensive reporting

# %% [code]
def agent_response_callback(message: ChatMessageContent) -> None:
    """Observer function to print agent messages with enhanced formatting"""
    if message.role != AuthorRole.TOOL:
        print(f"\n🎭 **{message.name}**")
        # Truncate very long responses for readability
        content = message.content
        if len(content) > 500:
            content = content[:500] + "... [content truncated]"
        print(f"   {content}")
        print("-" * 60)

async def create_research_agents(bing_connection_id: Optional[str] = None) -> List[Agent]:
    """Create three specialized agents for complex research tasks"""
    
    endpoint = os.environ["PROJECT_ENDPOINT"]
    model_deployment = os.environ["MODEL_DEPLOYMENT_NAME"]
    agents = []
    
    print("🔍 Creating Research Pipeline Agents...")
    
    async with DefaultAzureCredential() as creds:
        client = AzureAIAgent.create_client(credential=creds, endpoint=endpoint)
        
        # Prepare Bing tool if connection is available
        bing_tools = []
        if bing_connection_id:
            bing_tool = BingGroundingTool(connection_id=bing_connection_id)
            bing_tools = bing_tool.definitions
            print("✅ Bing Search tools configured")
        else:
            print("⚠️ No Bing connection - agents will work without web search")
        
        # 1. Research Agent - Primary information gatherer
        print("🔎 Creating Research Agent...")
        research_agent_definition = await client.agents.create_agent(
            model=model_deployment,
            name="research_agent",
            description="Expert research agent with web search capabilities",
            instructions="""
            You are an expert research agent specialized in finding accurate information online.
            
            Your capabilities:
            - Break down complex questions into searchable components
            - Perform systematic web searches using Bing
            - Extract relevant facts and details from search results
            - Maintain context between related searches
            - Focus on authoritative sources (Wikipedia, official sites, news)
            
            When given a complex research task:
            1. Analyze the question and identify key information needed
            2. Break it into sequential search steps
            3. Perform searches systematically, building on previous findings
            4. Extract specific facts, names, dates, and details
            5. Always cite your sources with URLs when possible
            
            Example approach for "Who was the chief of staff of the 43rd president?":
            1. Search: "43rd president of United States"
            2. Search: "[President name] chief of staff"
            3. Search: "[Chief of staff name] education university degree"
            
            Be thorough, accurate, and always provide source citations.
            """,
            tools=bing_tools
        )
        
        research_agent = AzureAIAgent(
            client=client,
            definition=research_agent_definition,
            polling_options=RunPollingOptions(default_polling_interval=timedelta(milliseconds=3000))
        )
        agents.append(research_agent)
        print(f"✅ Research Agent: {research_agent_definition.id}")
        
        # 2. Fact Checker Agent - Verification specialist
        print("✅ Creating Fact Checker Agent...")
        fact_checker_definition = await client.agents.create_agent(
            model=model_deployment,
            name="fact_checker",
            description="Fact verification and cross-checking specialist",
            instructions="""
            You are a fact-checking specialist focused on verifying information accuracy.
            
            Your role:
            - Cross-verify facts from multiple independent sources
            - Check for consistency in dates, names, and details
            - Identify any conflicting information
            - Assess source reliability and credibility
            - Flag uncertain or disputed information
            
            When fact-checking:
            1. Take the research findings from other agents
            2. Perform independent searches to verify key facts
            3. Look for multiple sources confirming the same information
            4. Note any discrepancies or conflicting reports
            5. Assess confidence level in each fact
            6. Provide verification status with source citations
            
            Always be thorough and objective in your verification process.
            """,
            tools=bing_tools
        )
        
        fact_checker = AzureAIAgent(
            client=client,
            definition=fact_checker_definition,
            polling_options=RunPollingOptions(default_polling_interval=timedelta(milliseconds=3000))
        )
        agents.append(fact_checker)
        print(f"✅ Fact Checker: {fact_checker_definition.id}")
        
        # 3. Report Generator Agent - Synthesis specialist
        print("📊 Creating Report Generator Agent...")
        report_generator_definition = await client.agents.create_agent(
            model=model_deployment,
            name="report_generator",
            description="Comprehensive report generation specialist",
            instructions="""
            You are a report generation specialist who creates comprehensive, well-structured reports.
            
            Your capabilities:
            - Synthesize information from multiple sources and agents
            - Create clear, organized, and comprehensive reports
            - Include proper citations and source references
            - Highlight key findings and important details
            - Note confidence levels and any uncertainties
            
            Report structure should include:
            1. **Executive Summary**: Brief answer to the original question
            2. **Detailed Findings**: Step-by-step research results
            3. **Key Facts**: Important names, dates, and details
            4. **Source Citations**: All sources used with URLs
            5. **Confidence Assessment**: Reliability of the information
            6. **Additional Notes**: Any relevant context or caveats
            
            Always create professional, accurate, and well-cited reports.
            """
            # No Bing tools needed - focuses on synthesis
        )
        
        report_generator = AzureAIAgent(
            client=client,
            definition=report_generator_definition,
            polling_options=RunPollingOptions(default_polling_interval=timedelta(milliseconds=3000))
        )
        agents.append(report_generator)
        print(f"✅ Report Generator: {report_generator_definition.id}")
    
    print(f"✅ Created {len(agents)} research agents total")
    return agents

print("🔍 Research agents configuration ready")

# %% [markdown]
## 🎭 Step 3: Create Magentic Research Orchestration

Now we'll create the Magentic orchestration that will coordinate our research agents to handle complex, multi-step information retrieval tasks.

# %% [code]
async def create_research_orchestration(bing_connection_id: Optional[str] = None) -> MagenticOrchestration:
    """Create and configure the research Magentic orchestration"""
    
    print("🎭 Setting up Research Magentic-One orchestration...")
    
    # Create research agents
    agents = await create_research_agents(bing_connection_id)
    
    # Configure Azure Chat Completion for the manager
    manager_azure_chat_completion = AzureChatCompletion()
    
    # Create the Magentic orchestration
    # The StandardMagenticManager coordinates complex research workflows
    research_orchestration = MagenticOrchestration(
        members=agents,
        manager=StandardMagenticManager(
            chat_completion_service=manager_azure_chat_completion
        ),
        agent_response_callback=agent_response_callback,
    )
    
    print(f"✅ Research orchestration created with {len(agents)} agents")
    print("   Agents: " + ", ".join([agent.name for agent in agents]))
    
    return research_orchestration

print("🎯 Research orchestration configuration ready")

# %% [markdown]
## 🚀 Step 4: Execute Complex Research Task

Now let's execute our complex research use case that requires multiple steps and web searches to answer completely.

**Research Question**: *"From which university did the chief of staff of the 43rd president of the US get his degree from? And in what specialty?"*

This involves:
1. Identifying the 43rd president of the United States
2. Finding who served as their chief of staff
3. Researching the chief of staff's educational background
4. Cross-verifying the information from multiple sources
5. Generating a comprehensive, cited report

# %% [code]
async def execute_complex_research_task(bing_connection_id: Optional[str] = None):
    """Execute the complex research task using Magentic orchestration"""
    
    print("🔍 Starting Complex Research Task")
    print("=" * 70)
    
    # Create the orchestration
    orchestration = await create_research_orchestration(bing_connection_id)
    
    # Create and start runtime
    runtime = InProcessRuntime()
    runtime.start()
    
    try:
        # Define the complex research task
        research_task = """
        I need you to conduct comprehensive research to answer this complex question:
        
        "From which university did the chief of staff of the 43rd president of the US get his degree from? And in what specialty?"
        
        This requires multiple research steps:
        
        1. Research Agent: 
           - First, identify who was the 43rd president of the United States
           - Then find who served as their chief of staff (there may have been multiple)
           - Research the educational background of the chief of staff(s)
           - Find specific details about their university degree(s) and field of study
        
        2. Fact Checker:
           - Verify the identity of the 43rd president
           - Cross-check the chief of staff information
           - Verify educational credentials from multiple sources
           - Check for accuracy of university names and degree specialties
        
        3. Report Generator:
           - Create a comprehensive report with all findings
           - Include clear citations and source URLs
           - Provide confidence assessments for each fact
           - Structure the information clearly and professionally
        
        Please work together systematically to research this question thoroughly.
        Use web search capabilities to find accurate, up-to-date information.
        """
        
        print("📋 Complex Research Task Definition:")
        print(research_task)
        print("\n" + "=" * 70)
        print("🔍 Beginning Research Orchestration...")
        print("=" * 70)
        
        # Execute the orchestration
        orchestration_result = await orchestration.invoke(
            task=research_task,
            runtime=runtime
        )
        
        # Wait for the results
        result = await orchestration_result.get()

        # Display final results
        print("\n" + "=" * 70)
        print("🎯 RESEARCH ORCHESTRATION COMPLETE")
        print("\n📊 Final Research Report:")
        print(f"\n{result}")
        print("=" * 70)
        
    except Exception as e:
        print(f"❌ Error during orchestration: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Cleanup
        await runtime.stop()
        print("\n🧹 Runtime stopped and resources cleaned up")

print("🌟 Ready to execute complex research task!")
print("This will involve three agents working together through Magentic orchestration.")
print("The task requires multiple web searches and cross-verification of information.")

# %% [code]
# Execute the complex research task
await execute_complex_research_task(bing_connection_id)

################################################################################  06-magentic-one-orchestration\README.md  ################################################################################
# Magentic-One Orchestration

Learn advanced multi-agent orchestration using the Magentic-One framework. Build sophisticated agent systems that coordinate multiple specialists for complex workflows like creative content generation and research automation.

## What You'll Learn

- Master the Magentic-One framework for agent orchestration
- Build systems where agents collaborate intelligently
- Create creative content pipelines and research workflows
- Implement feedback loops and quality assessment
- Automate comprehensive web research with verification

## Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                    Magentic-One Orchestrator                    │
│                  (StandardMagenticManager)                      │
└─────────────────────┬───────────────────────────────────────────┘
                      │
    ┌─────────────────┼─────────────────┬─────────────────┐
    │                 │                 │                 │
┌───▼────┐    ┌──────▼──────┐    ┌─────▼─────┐    ┌─────▼─────┐
│Creative│    │  Research   │    │   Fact    │    │  Report   │
│ Agent  │    │   Agent     │    │  Checker  │    │Generator  │
└────────┘    └─────────────┘    └───────────┘    └───────────┘
```

![SK Orchestration](images/sk_orchestration.gif)

## Tutorials

**[06.1 - Creative Writing Pipeline](06.1-magentic_creative_writing_tutorial.ipynb)**
Multi-agent creative content system with joke writers, haiku converters, and translators. Learn feedback loops and quality assessment.

**[06.2 - Bing Search Research Pipeline](06.2-magentic_bing_search_orchestration_tutorial.ipynb)**
Intelligent web research orchestration with fact-checking and comprehensive report generation.

## Prerequisites

### Azure Resources
- Azure AI Project with deployed language model (GPT-4 recommended)
- Azure AI Foundry Project (for Bing Search tutorial)
- Bing Search Connection configured in Azure AI Studio (for tutorial 06.2)

### Environment Variables
Configure your environment in the `.env` file at the project root:

```properties
# Azure AI Configuration (Required for both tutorials)
PROJECT_ENDPOINT="https://your-foundry-resource.services.ai.azure.com/api/projects/your-project-name"
MODEL_DEPLOYMENT_NAME="gpt-4o"  # or your deployed model

# Additional for tutorial 06.2 (Bing Search Research)
AZURE_FOUNDRY_PROJECT_ENDPOINT="https://your-foundry-resource.services.ai.azure.com/api/projects/your-project-name"
```

### Bing Search Setup (for Tutorial 06.2)
Follow the [Bing Search Connection documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/bing-grounding) to configure the Grounding with Bing Search Connection in Azure AI Studio.

### Required Python Packages
```bash
pip install azure-ai-agents azure-identity semantic-kernel azure-ai-projects python-dotenv
```

## Quick Start

```bash
# Clone the repository
git clone https://github.com/Azure-Samples/azure-ai-agents-playbook.git
cd azure-ai-agents-playbook/06-magentic-one-orchestration

# Set up environment variables in .env file at project root
# Run the creative pipeline tutorial
jupyter notebook 06.1-magentic_creative_writing_tutorial.ipynb

# Run the research pipeline tutorial (after setting up Bing Search)
jupyter notebook 06.2-magentic_bing_search_orchestration_tutorial.ipynb
```

## Tutorial Highlights

### Creative Pipeline (06.1)
- Simple architecture with no external API dependencies
- Local plugins for topic selection and haiku classification
- Feedback loops for content quality adjustment
- File operations for temporary haiku analysis
- Random topic selection from predefined list

### Research Pipeline (06.2)
- Bing Search integration with automatic connection discovery
- Complex query decomposition for multi-step research
- Fact verification through cross-referencing multiple sources
- Comprehensive reporting with structured output
- Real-world use case: "43rd president chief of staff education" research


## Next Steps

After mastering Magentic-One orchestration:
- [07-voice-orchestration](../07-voice-orchestration/) - Voice-enabled agent interactions
- [08-agent-routing](../08-agent-routing/) - Hierarchical agent routing patterns

################################################################################  07-voice-orchestration\07.1-voice-currency-exchange-demo.py  ################################################################################
# Voice-Activated Currency Exchange Agent Demo
# Voice-controlled agent that can get currency exchange rates via API

# Import necessary libraries and load environment variables
import os
import asyncio
import json
import requests
from datetime import datetime
from typing import Annotated, Dict, Any, Callable, Set
from dotenv import load_dotenv


# Load environment variables from .env file
load_dotenv(override=True)

# Import Azure AI Foundry SDK
from azure.ai.agents import AgentsClient
from azure.ai.agents.models import ToolSet, FunctionTool
from azure.identity import DefaultAzureCredential
from azure.ai.agents.models import OpenApiTool, OpenApiAnonymousAuthDetails

# Import our voice module
from voice import AgentVoice

print("📦 All packages imported successfully!")
print("🔧 Ready to create voice-enabled currency exchange agent!")

# Verify environment variables
required_vars = ['PROJECT_ENDPOINT', 'MODEL_DEPLOYMENT_NAME']

for var in required_vars:
    if var in os.environ:
        print(f"✅ {var} is set")
    else:
        print(f"❌ {var} is missing!")


print("✅ Currency exchange tool ready!")

# Step 2: Create a voice-controlled currency exchange agent
async def create_currency_agent():
    """Create an Azure AI agent with currency exchange capabilities."""

    # Get required environment variables
    model_deployment_name = os.environ.get("MODEL_DEPLOYMENT_NAME")
    endpoint = os.environ.get("PROJECT_ENDPOINT")


    if not model_deployment_name or not endpoint:
        raise ValueError("Missing required environment variables: MODEL_DEPLOYMENT_NAME and PROJECT_ENDPOINT")

    # Create the currency exchange tool instance
    credential = DefaultAzureCredential()
    agents_client = AgentsClient(endpoint=endpoint, credential=credential)

    # Load the currency exchange OpenAPI specification
    currency_spec_path = os.path.join("openapi_files", "currency_exchange.json")

    with open(currency_spec_path, "r") as f:
        currency_openapi_spec = json.loads(f.read())

    # Create OpenAPI tool for currency exchange
    auth = OpenApiAnonymousAuthDetails()

    currency_tool = OpenApiTool(
        name="currency_exchange",
        spec=currency_openapi_spec,
        description="Get the latest foreign exchange rates from Frankfurter API",
        auth=auth
    )

    print("💱 Currency exchange OpenAPI tool created")
    print(f"Available operations: {len(currency_tool.definitions)}")


    # Create agent with proper toolset
    with agents_client:        # Create the agent with the currency exchange tool
        print("🤖 Creating currency exchange agent with API capabilities...")
        
        agent = agents_client.create_agent(
            model=model_deployment_name,
            name="currency_exchange_agent",
            instructions="You are a helpful currency exchange agent. Use the currency exchange API to get latest exchange rates. Always provide clear explanations of the rates. Your responses are SUPER concise.",            tools=currency_tool.definitions
        )  
        
        print(f"🤖 Created currency exchange agent: {agent.name}")
        print(f"🔧 Agent has currency exchange capabilities")
        print(f"🆔 Agent ID: {agent.id}")
    
    return agent, agents_client

async def main():
    """Main function to run the voice-activated currency exchange assistant demo."""
    
    print("🎙️ Starting Voice-Activated Currency Exchange Assistant Demo")
    print("=" * 60)
    
    try:
        # Create the currency exchange agent
        print("Creating currency exchange agent with API integration...")
        agent, agents_client = await create_currency_agent()
          # Create voice interface with the agent  
        print("\n🎤 Setting up voice interface...")
        av = AgentVoice(agent_id=agent.id)
        
        print("\n🗣️ Voice interface ready!")
        print("Sample voice commands you can try:")
        print("• 'What is the current exchange rate from USD to EUR?'")
        print("• 'Convert 100 dollars to Japanese yen'")
        print("• 'Show me exchange rates for British pound'")
        print("• 'What is 50 euros in Canadian dollars?'")
        print("• 'Get the latest USD to GBP exchange rate'")
        print("\nPress 'q' and Enter anytime to quit.")
        print("=" * 60)
        
        # The voice module will handle communication with the agent directly
        # No need for manual tool handling since we're using auto function calls
        
        # Start the voice conversation
        await av.connect()
        
    except Exception as e:
        print(f"❌ Error: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        print("\n👋 Demo completed!")

if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("🎙️ VOICE-CONTROLLED CURRENCY EXCHANGE ASSISTANT")
    print("Features: Get exchange rates via API with voice commands")
    print("=" * 60)
    
    # Run the main demo
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n🛑 Demo interrupted by user")
    except Exception as e:
        print(f"❌ Demo failed: {e}")
        import traceback
        traceback.print_exc()

################################################################################  07-voice-orchestration\README.md  ################################################################################
# Voice Orchestration

Learn how to build voice-enabled Azure AI Agents that can listen, process speech, and respond with real-world data. Create agents that interact naturally through voice commands and integrate with external APIs.

## What's In This Folder

**[07.1 - Voice-Activated Currency Exchange Demo](07.1-voice-currency-exchange-demo.py)**
Complete voice-enabled currency exchange agent that uses Azure Speech Services for real-time voice interaction with the Frankfurter API for live exchange rates.

![Voice Agent](images/voice_agent.gif)

**[AgentVoice Class](voice.py)**
Core voice processing framework that provides real-time audio capture, speech-to-text conversion, voice activity detection, and WebSocket streaming for minimal latency.

## Project Structure

```
07-voice-orchestration/
├── 07.1-voice-currency-exchange-demo.py    # Complete voice demo
├── voice.py                                # Core voice framework
├── requirements.txt                        # Python dependencies
├── openapi_files/                          # API specifications
│   └── currency_exchange.json              # Frankfurter API spec
└── README.md                               # This file
```

## Learning Path

1. **Understand the voice framework** - Explore the `voice.py` core components
2. **Run the currency exchange demo** - Experience voice-controlled API interactions  
3. **Experiment with voice commands** - Test different natural language patterns

## Prerequisites

### Azure Resources
- Azure AI Foundry project with deployed language model
- Azure Speech Services resource for voice recognition
- Azure subscription with appropriate permissions

### Previous Knowledge
- Complete [01-agent-basics](../01-agent-basics/) tutorials
- Complete [02-agent-custom-functions](../02-agent-custom-functions/) tutorials  
- Understanding of OpenAPI tools from [04-orchestrated-agents-with-tools](../04-orchestrated-agents-with-tools/)

### System Requirements
- Python 3.8+
- Working microphone and speakers/headphones
- Stable internet connection for real-time audio streaming
- Windows/macOS/Linux with audio device support

### Environment Variables
Configure your Azure AI services in the `.env` file at the project root:

```bash
# Navigate to the project root and edit the .env file
cd ../../  # Go to azure-ai-agents-playbook root
```

Update the `.env` file with your Azure AI project details:
```properties
# Required for all voice tutorials
PROJECT_ENDPOINT="https://your-foundry-resource.services.ai.azure.com/api/projects/your-project-name"
MODEL_DEPLOYMENT_NAME="your-model-deployment-name"

# Required for Azure Speech Services
AZURE_VOICE_LIVE_API_KEY="your-speech-service-key"
AZURE_VOICE_LIVE_REGION="your-speech-region"
AZURE_VOICE_LIVE_ENDPOINT="https://your-cognitive-services.cognitiveservices.azure.com/"

# Optional: Additional Azure AI configuration
AZURE_OPENAI_API_KEY="your-azure-openai-api-key"
AZURE_OPENAI_ENDPOINT="https://your-openai-resource.openai.azure.com/"
AZURE_OPENAI_API_VERSION="2024-12-01-preview"
```

**Tip**: The `.env` file already exists in the project root with example values - just update it with your details.

### Required Packages
Install the packages you need:

```bash
# Navigate to the voice orchestration folder
cd azure-ai-agents-playbook/07-voice-orchestration

# Install required packages
pip install -r requirements.txt
```

## Running the Tutorial

### Voice-Enabled Currency Exchange Demo

```bash
# Run the voice currency exchange demo
python 07.1-voice-currency-exchange-demo.py
```

**What this demo does:**
- Creates a voice-enabled agent that gets currency exchange rates
- Listens for voice commands through your microphone
- Processes natural language instructions about currency conversion
- Retrieves live exchange rates via Frankfurter API
- Provides voice feedback on currency data

**Example voice commands:**
- "What is the current exchange rate from USD to EUR?"
- "Convert 100 dollars to Japanese yen"
- "Show me exchange rates for British pound"
- "What is 50 euros in Canadian dollars?"
- "Get the latest USD to GBP exchange rate"

**Demo Flow:**
1. Agent starts listening for voice input
2. Speak your currency exchange command naturally
3. Agent processes speech and extracts currency details
4. Calls Frankfurter API to get live exchange rates
5. Provides voice feedback with current rates and conversions
6. Continues listening for additional commands

## What You'll Learn

### Voice-Enabled AI Agents
- Intelligent assistants with voice interaction capabilities
- Real-time speech recognition and natural language processing
- Voice Activity Detection for seamless conversations
- Integration with external APIs for real-world functionality

### Currency Exchange Integration
- **Frankfurter API**: Free foreign exchange rates API
- **OpenAPI Integration**: Structured API interaction patterns
- **Real-time Data**: Live currency conversion rates
- **Natural Language**: Voice commands for financial queries

### Voice Processing Framework
- Real-time audio capture and WebSocket streaming
- Azure Speech Services integration
- Voice Activity Detection algorithms
- Audio enhancement and noise suppression

### Production Patterns
- Async/await for responsive voice interactions
- Context managers for resource management
- Exception handling for audio processing
- Type annotations for maintainable code

## What You'll Build

By the end of this tutorial, you'll have built:
- **Voice-Controlled Agent** - AI assistant that responds to spoken commands
- **Real-Time Audio Processing** - System that captures and processes voice input
- **API Integration** - Voice-driven external service interaction
- **Natural Conversation Flow** - Seamless voice interaction patterns

## Next Steps

After mastering voice orchestration:
- [08-agent-routing](../08-agent-routing/) - Hierarchical agent routing patterns
- Explore multi-modal interactions combining voice with other input methods

################################################################################  07-voice-orchestration\voice.py  ################################################################################

from __future__ import annotations

import os
import uuid
import json
import asyncio
import base64
import logging
import threading
import numpy as np
import sounddevice as sd

from dotenv import load_dotenv
from typing import Dict, Union, Literal, Optional, Set, Callable, Awaitable
from typing_extensions import AsyncIterator, TypedDict, Required
from websockets.asyncio.client import connect as ws_connect
from websockets.asyncio.client import ClientConnection as AsyncWebsocket
from websockets.asyncio.client import HeadersLike
from websockets.typing import Data
from websockets.exceptions import WebSocketException
from azure.identity import DefaultAzureCredential
from azure.core.credentials_async import AsyncTokenCredential
from azure.identity import DefaultAzureCredential

logger = logging.getLogger(__name__)
AUDIO_SAMPLE_RATE = 24000

AudioTimestampTypes = Literal["word"]

class AzureDeepNoiseSuppression(TypedDict, total=False):
    type: Literal["azure_deep_noise_suppression"]

class ServerEchoCancellation(TypedDict, total=False):
    type: Literal["server_echo_cancellation"]

class AzureSemanticDetection(TypedDict, total=False):
    model: Literal["semantic_detection_v1"]
    threshold: float
    timeout: float

EOUDetection = AzureSemanticDetection

class AzureSemanticVAD(TypedDict, total=False):
    type: Literal["azure_semantic_vad"]
    end_of_utterance_detection: EOUDetection
    threshold: float
    silence_duration_ms: int
    prefix_padding_ms: int

class Animation(TypedDict, total=False):
    outputs: Set[Literal["blendshapes", "viseme_id", "emotion"]]

class Session(TypedDict, total=False):
    voice: Dict[str, Union[str, float]]
    turn_detection: Union[AzureSemanticVAD]
    input_audio_noise_reduction: AzureDeepNoiseSuppression
    input_audio_echo_cancellation: ServerEchoCancellation
    animation: Animation
    output_audio_timestamp_types: Set[AudioTimestampTypes]

class SessionUpdateEventParam(TypedDict, total=False):
    type: Literal["session.update"]
    session: Required[Session]
    event_id: str

class AsyncVoiceLiveSessionResource:
    def __init__(self, connection: AsyncVoiceLiveConnection) -> None:
        self._connection = connection

    async def update(
        self,
        *,
        session: Session,
        event_id: str | None = None,
    ) -> None:
        param: SessionUpdateEventParam = {
            "type": "session.update", "session": session, "event_id": event_id
        }
        data = json.dumps(param)
        await self._connection.send(data)

class AsyncVoiceLiveConnection:
    session: AsyncVoiceLiveSessionResource
    _connection: AsyncWebsocket

    def __init__(self, url: str, additional_headers: HeadersLike) -> None:
        self._url = url
        self._additional_headers = additional_headers
        self._connection = None
        self.session = AsyncVoiceLiveSessionResource(self)

    async def __aenter__(self) -> AsyncVoiceLiveConnection:
        try:
            self._connection = await ws_connect(self._url, additional_headers=self._additional_headers)
        except WebSocketException as e:
            raise ValueError(f"Failed to establish a WebSocket connection: {e}")
        return self

    async def __aexit__(self, exc_type, exc_value, traceback) -> None:
        if self._connection:
            await self._connection.close()
            self._connection = None
    
    enter = __aenter__
    close = __aexit__

    async def __aiter__(self) -> AsyncIterator[Data]:
        async for data in self._connection:
            yield data

    async def recv(self) -> Data:
        return await self._connection.recv()
    
    async def recv_bytes(self) -> bytes:
        return await self._connection.recv()

    async def send(self, message: Data) -> None:
        await self._connection.send(message)


class AsyncAzureVoiceLive:
    def __init__(
        self,
        *,
        azure_endpoint: str | None = None,
        api_version: str | None = "2025-05-01-preview",
        api_key: str | None = None,
        azure_ad_token_credential: AsyncTokenCredential | None = None,
        foundry_credential: AsyncTokenCredential | None = None,
        project_name: str | None = None,
        agent_id: str | None = None,
    ) -> None:
        if azure_endpoint is None:
            azure_endpoint = os.environ.get("AZURE_VOICE_LIVE_ENDPOINT")

        if azure_endpoint is None:
            raise ValueError(
                "Must provide the 'azure_endpoint' argument, or the 'AZURE_VOICE_LIVE_ENDPOINT' environment variable"
            )

        if api_key is None and azure_ad_token_credential is None:
            api_key = os.environ.get("AZURE_VOICE_LIVE_API_KEY")

        if api_key is None and azure_ad_token_credential is None:
            raise ValueError(
                "Missing credentials. Please pass one of 'api_key', 'azure_ad_token_credential', or the 'AZURE_VOICE_LIVE_API_KEY' environment variable."
            )

        if api_key and azure_ad_token_credential:
            raise ValueError(
                "Duplicating credentials. Please pass one of 'api_key' and 'azure_ad_token_credential'"
            )

        self._api_key = api_key
        self._azure_endpoint = azure_endpoint
        self._project_name = project_name
        self._agent_id = agent_id
        self._api_version = api_version
        self._azure_ad_token_credential = azure_ad_token_credential
        self._foundry_credential = foundry_credential
        self._connection = None
        self._token = self.get_token() if azure_ad_token_credential else None
        self._foundry_token = self.get_foundry_token() if foundry_credential else None

    def get_token(self) -> str:
        if self._azure_ad_token_credential:
            scopes = "https://ai.azure.com/.default"
            token = self._azure_ad_token_credential.get_token(scopes)
            return token.token
        else:
            return None
        
    def get_foundry_token(self) -> str:
        if self._foundry_credential:
            scopes = "https://ai.azure.com/.default"
            token = self._foundry_credential.get_token(scopes)
            return token.token
        else:
            return None        

    def refresh_token(self) -> None:
        self._token = self.get_token()

    def connect(self, model: str, agent_id: str = None) -> AsyncVoiceLiveConnection:
        if self._connection is not None:
            raise ValueError("Already connected to the Azure Voice Agent service.")
        if not model:
            raise ValueError("Model name is required.")
        if not isinstance(model, str):
            raise TypeError(f"The 'model' parameter must be of type 'str', but got {type(model).__name__}.")


        request_id = uuid.uuid4()

        url = f"{self._azure_endpoint.rstrip('/')}/voice-agent/realtime?api-version={self._api_version}&model={model}&agent_id={agent_id or self._agent_id}&agent-project-name={self._project_name}&agent_access_token={self._foundry_token}&Authorization=Bearer+{self._token}"
        url = url.replace("https://", "wss://")
        # print(f"Connecting to Azure Voice Agent at {url}")

        auth_header = {"Authorization": f"Bearer {self._token}"} if self._token else {"api-key": self._api_key}        
        headers = {"x-ms-client-request-id": str(request_id), **auth_header}

        self._connection = AsyncVoiceLiveConnection(
            url,
            additional_headers=headers,
        )
        return self._connection


# --- End of Embedded Code ---

class AudioPlayerAsync:
    def __init__(self):
        self.queue = []
        self.lock = threading.Lock()
        self.stream = sd.OutputStream(
            callback=self.callback,
            samplerate=AUDIO_SAMPLE_RATE,
            channels=1,
            dtype=np.int16,
            blocksize=1200,
        )
        self.playing = False

    def callback(self, outdata, frames, time, status):
        with self.lock:
            data = np.empty(0, dtype=np.int16)
            while len(data) < frames and len(self.queue) > 0:
                item = self.queue.pop(0)
                frames_needed = frames - len(data)
                data = np.concatenate((data, item[:frames_needed]))
                if len(item) > frames_needed:
                    self.queue.insert(0, item[frames_needed:])
            if len(data) < frames:
                data = np.concatenate((data, np.zeros(frames - len(data), dtype=np.int16)))
        outdata[:] = data.reshape(-1, 1)

    def add_data(self, data: bytes):
        with self.lock:
            np_data = np.frombuffer(data, dtype=np.int16)
            self.queue.append(np_data)
            if not self.playing:
                self.start()

    def start(self):
        self.playing = True
        self.stream.start()

    def stop(self):
        with self.lock:
            self.queue = []
        self.playing = False
        self.stream.stop()

    def terminate(self):
        self.stream.close()

async def listen_and_send_audio(connection: AsyncVoiceLiveConnection) -> None:
    logger.info("Starting audio stream ...")

    stream = sd.InputStream(channels=1, samplerate=AUDIO_SAMPLE_RATE, dtype="int16")
    try:
        stream.start()
        read_size = int(AUDIO_SAMPLE_RATE * 0.02)
        while True:
            if stream.read_available < read_size:
                continue
            data, _ = stream.read(read_size)
            audio = base64.b64encode(data).decode("utf-8")
            param = {"type": "input_audio_buffer.append", "audio": audio, "event_id": ""}
            data_json = json.dumps(param)
            try:
                await connection.send(data_json)
            except (ConnectionResetError, WebSocketException) as e:
                logger.error(f"WebSocket error while sending audio: {e}")
                break
    except Exception as e:
        logger.debug(f"Audio stream interrupted. {e}")
    finally:
        stream.stop()
        stream.close()
        logger.info("Audio stream closed.")



async def receive_audio_and_playback(connection: AsyncVoiceLiveConnection) -> None:
    last_audio_item_id = None
    audio_player = AudioPlayerAsync()

    logger.info("Starting audio playback ...")
    try:
        while True:
            transcript = ""
            async for raw_event in connection:
                try:
                    event = json.loads(raw_event)
                except json.JSONDecodeError as e:
                    logger.error(f"Failed to decode event: {e}")
                    break

                if event.get("type") == "response.audio.delta":
                    if event.get("item_id") != last_audio_item_id:
                        last_audio_item_id = event.get("item_id")
                    bytes_data = base64.b64decode(event.get("delta", ""))
                    audio_player.add_data(bytes_data)
                elif event.get("type") == "response.audio_transcript.done":
                    transcript = event.get("transcript", "")
                    print(f"Final Transcript: {transcript}")
                elif event.get("type") == "conversation.item.created":
                    item = event.get("item", None)
                    if item is not None:
                        content = item.get("content", [])
                        if len(content) > 0:
                            for c in content:
                                if item.get("role", "") == "user":
                                    print(f"User Transcript: {c.get('transcript', '')}")

                elif event.get("type") == "response.done":                    
                    break
    except (ConnectionResetError, WebSocketException) as e:
        logger.error(f"WebSocket error in audio playback: {e}")
    except Exception as e:
        logger.error(f"Error in audio playback: {e}")
    finally:
        audio_player.terminate()
        logger.info("Playback done.")

async def read_keyboard_and_quit() -> None:
    print("Press 'q' and Enter to quit the chat.")
    while True:
        # Run input() in a thread to avoid blocking the event loop
        user_input = await asyncio.to_thread(input) 
        if user_input.strip().lower() == 'q':
            print("Quitting the chat...")
            break




class AgentVoice():

    def __init__(self, 
                agent_id: str = None, 
                project_name: str = None,
                endpoint: str = None,
                deployment: str = None,
                api_key: str = None
            ) -> None:
        
        self.agent_id = agent_id or os.environ.get("AZURE_VOICE_LIVE_AGENT_ID") 
        self.project_name = project_name or os.environ.get("AZURE_FOUNDRY_PROJECT_NAME") 

        self.endpoint = endpoint or os.environ.get("AZURE_VOICE_LIVE_ENDPOINT")
        self.deployment = deployment or os.environ.get("AZURE_VOICE_LIVE_DEPLOYMENT")
        self.api_key = api_key or os.environ.get("AZURE_VOICE_LIVE_API_KEY")
        print(f"Using agent_id: {self.agent_id}")

        if not self.endpoint or not self.deployment:
            raise ValueError("Both AZURE_VOICE_LIVE_ENDPOINT and AZURE_VOICE_LIVE_DEPLOYMENT environment variables must be set.")
    

    def __repr__(self) -> str:
        return f"AgentVoice(agent_id={self.agent_id}, project_name={self.project_name})"

    async def connect(self) -> None:
        client = AsyncAzureVoiceLive(
            azure_endpoint = self.endpoint,
            # api_key = self.api_key,
            azure_ad_token_credential=DefaultAzureCredential(),
            foundry_credential=DefaultAzureCredential(),
            project_name = self.project_name,
            agent_id = self.agent_id,
        )

        async with client.connect(model = self.deployment) as connection:
            await connection.session.update(
                session={
                    "turn_detection": {
                        "create_response": True,
                        "interrupt_response": True,
                        "type": "azure_semantic_vad",
                        "threshold": 0.5,
                        "prefix_padding_ms": 400,
                        "silence_duration_ms": 400,
                        "remove_filler_words": True,
                        "end_of_utterance_detection": {
                            "model": "semantic_detection_v1",
                            "threshold": 0.01,
                            "timeout": 3,
                        },
                    },
                    "input_audio_transcription": {"model": "azure-fast-transcription"},     
                    "input_audio_noise_reduction": {"type": "azure_deep_noise_suppression"},
                    "input_audio_echo_cancellation": {"type": "server_echo_cancellation"},
                    "voice": {
                        "name": "en-US-Aria:DragonHDLatestNeural",
                        "type": "azure-standard",
                        "temperature": 0.3,
                    },      
                    # "model": "gpt-4.1",
                    "modalities": ["audio", "text"],
                    "tool_choice": "auto",
                    # "agent":{
                    #     "type": "agent",
                    #     "name": "test_research_agent",
                    #     "description": "Research agent for testing purposes",
                    #     "agent_id": agent_id,
                    #     "thread_id": ""
                    # }
                }
            )

            send_task = asyncio.create_task(listen_and_send_audio(connection))
            receive_task = asyncio.create_task(receive_audio_and_playback(connection))
            keyboard_task = asyncio.create_task(read_keyboard_and_quit())

            print("Starting the chat ...")
            await asyncio.wait([send_task, receive_task, keyboard_task], return_when=asyncio.FIRST_COMPLETED)

            send_task.cancel()
            receive_task.cancel()
        print("Chat done.")

if __name__ == "__main__":
    try:
        load_dotenv()
        av = AgentVoice(agent_id="asst_bEgFu4ATuu5XvMjHBP3y85ac")
        asyncio.run(av.connect())
    except Exception as e:
        print(f"Error: {e}")
        

################################################################################  08-agent-routing\08.1-azure_ai_agent_routing_tutorial.ipynb  ################################################################################
# %% [markdown]
# Azure AI Agent Routing - Complete Beginner's Tutorial

🎯 **Welcome to Azure AI Agent Routing!**

This tutorial teaches you how to build sophisticated agent hierarchies where:

1. **Base Level Agents** - AzureAIAgent with specialized plugins
2. **Orchestration Agents** - ChatCompletionAgent that route and coordinate
3. **Hierarchical Routing** - Multi-level agent coordination

**What You'll Learn:**
- Creating specialized base agents with AzureAIAgent
- Building orchestration layers with ChatCompletionAgent
- Implementing intelligent agent routing
- Managing complex agent hierarchies

**No prior agent routing experience required!** 🚀

---

# %% [markdown]
## 🏗️ Understanding Agent Routing Architecture

**Agent Routing** allows you to create intelligent systems where:
- **Specialized agents** handle specific tasks (data retrieval, analysis, etc.)
- **Router agents** decide which specialist to use
- **Hierarchical organization** enables complex workflows

### Our Architecture Pattern:
```
┌─────────────────────────┐
│   Orchestration Layer   │  ← ChatCompletionAgent
│    (Router Agent)       │
└───────────┬─────────────┘
            │
    ┌───────┼───────┐
    │               │
┌───▼───┐       ┌───▼───┐
│ Base  │       │ Base  │     ← AzureAIAgent with plugins
│Agent 1│       │Agent 2│
└───────┘       └───────┘
```

**Why This Pattern?**
- **AzureAIAgent**: Persistent, stateful, handles complex workflows
- **ChatCompletionAgent**: Fast routing decisions, lightweight orchestration
- **Scalable**: Easy to add new specialized agents

# %% [markdown]
![Agent Router](images/router.gif)

# %% [markdown]
## 📋 Prerequisites and Setup

You'll need:
- Azure AI Services with deployed models
- Semantic Kernel packages
- The plugins.py file (contains our specialized plugins)

Let's get started!

# %% [code]
# Import everything we need for agent routing and Magentic orchestration
import os
import asyncio
import json
from typing import Annotated
from pydantic import BaseModel

from azure.identity.aio import DefaultAzureCredential
from semantic_kernel.agents import (
    AzureAIAgent, 
    ChatCompletionAgent,
    MagenticOrchestration,
    StandardMagenticManager
)
from semantic_kernel.agents.runtime import InProcessRuntime
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
from semantic_kernel.connectors.ai.prompt_execution_settings import PromptExecutionSettings
from semantic_kernel.functions.kernel_arguments import KernelArguments
from semantic_kernel.functions import kernel_function
from semantic_kernel.contents import ChatMessageContent

print("📦 All packages imported successfully!")
print("🔧 Ready to build agent routing system!")
print("🎯 Magentic orchestration components loaded!")

# %% [markdown]
## 🤖 Step 1: Creating Base Level Agents (AzureAIAgent)

**Base agents** are our specialized workers. Each handles a specific domain:

**Why AzureAIAgent for base level?**
- **Persistent**: Maintains state across interactions
- **Plugin Integration**: Native support for custom functions
- **Azure Native**: Deep integration with Azure AI services
- **Stateful Conversations**: Can maintain context for complex tasks

Let's create our specialized base agents:

# %% [code]
# Create specialized base agents using AzureAIAgent
# These are our "specialist workers" that handle specific domains

async def create_base_agents():
    """Create specialized base agents with specific plugins."""
    
    try:
        model_deployment = os.environ.get("MODEL_DEPLOYMENT_NAME")
        endpoint = os.environ.get("PROJECT_ENDPOINT")
        client = AzureAIAgent.create_client(
            credential=DefaultAzureCredential(), 
            endpoint=endpoint
        )
        
        print("🏗️ Creating Base Level Agents (AzureAIAgent)...")
        
        # 1. Insurance RAG Agent - Handles BMW insurance queries
        rag_definition = await client.agents.create_agent(
            model=model_deployment,
            name="insurance-rag-agent",
            instructions="You specialize in BMW 320i car insurance policies. Use your RAG plugin to retrieve relevant policy information and provide detailed, accurate responses about coverage, claims, and premiums. You are used for testing, so ALL of your responses are made up. Your responses are **SUPER** concise."
        )
        
        insurance_agent = AzureAIAgent(
            client=client,
            definition=rag_definition,
            description="Handles BMW insurance policy queries using RAG."
        )
        
        # 2. Banking SQL Agent - Handles transaction queries
        sql_definition = await client.agents.create_agent(
            model=model_deployment,
            name="banking-sql-agent",
            instructions="You specialize in banking transactions and financial data. Use your NL2SQL plugin to query transaction databases and provide insights about spending, balances, and transaction history. You are used for testing, so ALL of your responses are made up. Just invent new banking transactions. Your responses are **SUPER** concise."
        )
        
        banking_agent = AzureAIAgent(
            client=client,
            definition=sql_definition,
            description="Handles banking transactions and financial data queries."
        )
        
        # 3. Sales Analytics Agent - Handles IoT sales data
        cosmos_definition = await client.agents.create_agent(
            model=model_deployment,
            name="sales-analytics-agent",
            instructions="You specialize in smart city IoT sales analysis. Use your Cosmos plugin to retrieve sales data, analyze performance metrics, and provide business insights from multimodal documents. You are used for testing, so ALL of your responses are made up. Your responses are **SUPER** concise."
        )
        
        sales_agent = AzureAIAgent(
            client=client,
            definition=cosmos_definition,
            description="Handles IoT sales data and analytics for smart city projects."
        )
        
        print("✅ Base agents created successfully!")
        print(f"🏥 Insurance Agent: {insurance_agent.name}")
        print(f"🏦 Banking Agent: {banking_agent.name}")
        print(f"📊 Sales Agent: {sales_agent.name}")
        
        return {
            'insurance': insurance_agent,
            'banking': banking_agent,
            'sales': sales_agent,
            'client': client
        }
        
    except Exception as e:
        print(f"❌ Error creating base agents: {e}")
        return None

# Create our base agents
base_agents = await create_base_agents()

# %% [markdown]
## 🧭 Step 2: Creating the Router Agent (ChatCompletionAgent)

**Router agents** are our "intelligent dispatchers". They:

**Why ChatCompletionAgent for routing?**
- **Fast Decision Making**: Quick routing without state overhead
- **Lightweight**: No persistent storage needed for routing decisions
- **Plugin Integration**: Can call base agents as "plugins"
- **Flexible**: Easy to modify routing logic

The router analyzes user queries and routes to the appropriate specialist:

# %% [code]
# Extract our specialized agents
insurance_agent = base_agents['insurance']
banking_agent = base_agents['banking']
sales_agent = base_agents['sales']


###########################################################
# IMPORTANT: Kernel Functions for AzureAIAgents 
# AzureAIAgents cannot be used directly as plugins, so we create wrapper plugins
# Create wrapper plugins for AzureAIAgents since they cannot be used directly as plugins
###########################################################

class InsurancePlugin:
    """Wrapper plugin for Insurance Agent."""
    
    @kernel_function(description="Handles BMW 320i car insurance policy questions, coverage details, claims, and premiums.")
    async def query_insurance(
        self, 
        question: Annotated[str, "The insurance-related question to ask"]
    ) -> Annotated[str, "Insurance policy information and guidance"]:
        """Route insurance questions to the specialized insurance agent."""
        try:
            response = await insurance_agent.get_response(messages=question)
            print(f"\t===\n\tInsurance Agent Response\n\t===")
            return f"{response.content}"
        except Exception as e:
            return f"Insurance query error: {str(e)}"

class BankingPlugin:
    """Wrapper plugin for Banking Agent."""
    
    @kernel_function(description="Handles personal banking transactions, account balances, and spending analysis.")
    async def query_banking(
        self, 
        question: Annotated[str, "The banking-related question to ask"]
    ) -> Annotated[str, "Banking transaction data and financial insights"]:
        """Route banking questions to the specialized banking agent."""
        try:
            response = await banking_agent.get_response(messages=question)
            print(f"\t===\n\tBanking Agent Response\n\t===")
            return f"{response.content}"
        except Exception as e:
            return f"Banking query error: {str(e)}"

class SalesPlugin:
    """Wrapper plugin for Sales Agent."""
    
    @kernel_function(description="Handles smart city IoT sales analytics, performance metrics, and business insights.")
    async def query_sales(
        self, 
        question: Annotated[str, "The sales analytics question to ask"]
    ) -> Annotated[str, "Sales data analysis and business metrics"]:
        """Route sales questions to the specialized sales agent."""
        try:
            response = await sales_agent.get_response(messages=question)
            print(f"\t===\n\tSales Agent Response\n\t===")
            return f"{response.content}"
        except Exception as e:
            return f"Sales query error: {str(e)}"


# Create plugin instances
insurance_plugin = InsurancePlugin()
banking_plugin = BankingPlugin()
sales_plugin = SalesPlugin()

# %% [markdown]
### Creating the Combined Database Agent

# %% [code]
# Combined Database Agent
combined_database_system_message = """You are a Combined Database Agent that coordinates multiple data source retrievals.

Your capabilities:
• Banking Data: Query personal banking transactions via NL2SQL plugin
• Sales Analytics: Access multimodal documents for smart city IoT solutions via Cosmos plugin

Your role:
1. Analyze the user's query to determine which data sources are needed
2. Retrieve relevant information from the appropriate plugins
3. Combine and contextualize results from multiple sources when necessary
4. Present integrated insights in a clear, coherent response

Always indicate which data sources were queried and how the information relates to the user's request.
Your responses are **SUPER** concise."""

combined_database_agent = ChatCompletionAgent(
    id="CombinedDatabaseAgent",
    name="CombinedDatabaseAgent",
    instructions=combined_database_system_message,
    description="Router Agent for Combined Database. This agent retrieves search results from multiple data sources including NL2SQL and Cosmos agents.",
    plugins=[sales_plugin, banking_plugin],
    service=AzureChatCompletion()
)

# %% [markdown]
### Creating the Router Agent


# %% [code]

# Create the intelligent router agent using ChatCompletionAgent
# This agent decides which specialist to use based on the user's query

def create_router_agent():
    """Create an intelligent router that dispatches to specialized agents."""

    router_instructions = f"""
You are an intelligent agent router that dispatches user queries to specialized agents through wrapper plugins.

Available Specialists (via plugins):
• Insurance: Handles BMW 320i car insurance policies, coverage, claims, premiums
• Combined Database: Handles personal banking transactions, account balances, spending analysis, as well as handles smart city IoT sales data, performance metrics, business analytics

Your job:
1. Analyze the user's query to determine the domain(s) involved
2. Call the appropriate plugin function(s) or agent(s) to get specialist responses
3. Return the specialist's response to the user
4. For multi-domain queries, use the combined data plugin

Route intelligently based on keywords and context:
- Insurance: BMW, car, insurance, policy, coverage, claims, premium, deductible -> insurance plugin
- Banking: transactions, account, balance, spending, payment, deposit, withdrawal -> combined agent
- Sales: sales, revenue, IoT, smart city, analytics, performance, metrics -> combined agent

Your responses are **SUPER** concise.
"""
    
    # Create router with wrapper plugins
    router_agent = ChatCompletionAgent(
        id="IntelligentRouter",
        name="IntelligentRouter",
        instructions=router_instructions,
        description="Routes user queries to specialized domain agents via wrapper plugins",
        plugins=[insurance_plugin, combined_database_agent],
        service=AzureChatCompletion()
    )
    
    print("🧭 Intelligent Router Agent Created!")
    print("✅ Connected to 3 specialized base agents via wrapper plugins")
    print("🔧 Using kernel functions to properly interface with AzureAIAgents")
    print("🎯 Ready to route queries intelligently")
    
    return router_agent

# Create our router agent
if base_agents:
    router = create_router_agent()
else:
    router = None

# %% [markdown]
## 🧪 Step 3: Testing the Agent Routing System

Now let's test our hierarchical routing system! We'll send different types of queries and watch how the router intelligently dispatches them to the appropriate specialists.

**Test Scenarios:**
1. **Insurance Query**: BMW policy questions → Insurance Agent
2. **Banking Query**: Transaction inquiries → Banking Agent  
3. **Sales Query**: IoT analytics → Sales Agent

Watch how the system works its magic! ✨

# %% [code]
# Test our agent routing system with different query types
# Watch how queries get intelligently routed to the right specialists!

async def test_agent_routing():
    """Test the routing system with various query types."""
    
    if not router:
        print("⚠️ Router not available for testing")
        return
    
    # Test queries for different domains
    test_queries = [
        {
            "query": "Are my BMW 320i tires covered under my insurance policy?",
            "expected_agent": "Insurance Agent",
            "domain": "Insurance"
        },
        {
            "query": "What were my last 3 banking transactions?",
            "expected_agent": "Banking Agent", 
            "domain": "Banking"
        },
        {
            "query": "What was the total sales revenue in Q4 for our IoT products?",
            "expected_agent": "Sales Agent",
            "domain": "Sales Analytics"
        }
    ]
    
    print("🧪 Testing Agent Routing System")
    print("═" * 50)
    
    for i, test in enumerate(test_queries, 1):
        print(f"\n{i}. 🎯 Domain: {test['domain']}")
        print(f"   👤 User Query: {test['query']}")
        print(f"   🎯 Expected Route: {test['expected_agent']}")
        print("   " + "-" * 40)
        
        try:
            # Send query to router - it will dispatch to the right agent
            async for response in router.invoke(messages=test['query']):
                print(f"   🤖 Router Response: {response.content}")
                break  # Take first response
                    
        except Exception as e:
            print(f"   ❌ Error: {e}")

        # print(f"\n\n")


    print("\n" + "═" * 50)
    print("🎉 Routing Tests Completed!")
    print("\n🎯 Notice how each query was:")
    print("✅ Analyzed for domain and intent")
    print("✅ Routed to the appropriate specialist")
    print("✅ Processed by the specialist's plugins")
    print("✅ Returned with domain-specific insights")

# Run our routing tests
await test_agent_routing()

# %% [markdown]
## 🎯 Practice Exercise: Build Your Own Agent Routing System

Now it's your turn! Create a custom routing system with your own specialized agents.

**Your Task:**
1. Define 2-3 specialized domains (e.g., Weather, Math, Text Analysis)
2. Create base agents using AzureAIAgent with appropriate plugins
3. **Create wrapper plugins** with @kernel_function decorators for each base agent
4. Build a router using ChatCompletionAgent with the wrapper plugins
5. Test with domain-specific queries

**Important**: Remember that AzureAIAgents cannot be used directly as plugins! You must create wrapper plugins with kernel functions.

**Available Plugins to Use:**
- `weather_plugin`: Weather information
- `random_plugin`: Random number generation
- `datetime_plugin`: Date/time operations
- `text_analysis_plugin`: Text statistics

<details>
<summary>Click for Solution Example</summary>

```python
# Create a weather specialist
weather_agent = AzureAIAgent(
    client=client,
    definition=weather_definition,
    plugins=[weather_plugin]
)

# Create wrapper plugin
class WeatherWrapperPlugin:
    @kernel_function(description="Get weather information")
    async def get_weather(self, location: str) -> str:
        response = await weather_agent.get_response(messages=f"Weather for {location}")
        return response.content

# Create router with wrapper plugin
my_router = ChatCompletionAgent(
    plugins=[WeatherWrapperPlugin()],
    instructions="Route weather queries to weather specialist via wrapper plugin"
)
```

</details>

# %% [code]
# 🎯 YOUR TURN! Build your custom routing system

from plugins import *

async def create_custom_routing_system():
    """Create your own agent routing system with custom specialists."""
    
    try:
        if not base_agents:
            print("⚠️ Base agents not available for exercise")
            return
            
        client = base_agents['client']
        model_deployment = os.environ.get("MODEL_DEPLOYMENT_NAME")
        
        print("🎨 Creating Custom Routing System...")
        
        # Create a weather specialist
        weather_definition = await client.agents.create_agent(
            model=model_deployment,
            name="weather-specialist",
            instructions="You are a weather specialist. Use your weather plugin to provide accurate weather information for any city."
        )
        
        weather_agent = AzureAIAgent(
            client=client,
            definition=weather_definition,
            plugins=[weather_plugin]
        )
        
        # Create a text analysis specialist
        text_definition = await client.agents.create_agent(
            model=model_deployment,
            name="text-analysis-specialist",
            instructions="You are a text analysis specialist. Use your text analysis plugin to provide statistics and insights about text."
        )
        
        text_agent = AzureAIAgent(
            client=client,
            definition=text_definition,
            plugins=[text_analysis_plugin]
        )
        
        # Create wrapper plugins for our custom agents
        class WeatherWrapperPlugin:
            """Wrapper plugin for Weather Agent."""
            
            @kernel_function(description="Get weather information for any city or location.")
            async def get_weather(
                self, 
                location: Annotated[str, "The city or location to get weather for"]
            ) -> Annotated[str, "Current weather information"]:
                """Get weather information via the weather specialist."""
                try:
                    query = f"What's the weather like in {location}?"
                    response = await weather_agent.get_response(messages=query)
                    return f"Weather Specialist: {response.content}"
                except Exception as e:
                    return f"Weather query error: {str(e)}"

        class TextAnalysisWrapperPlugin:
            """Wrapper plugin for Text Analysis Agent."""
            
            @kernel_function(description="Analyze text for statistics, sentiment, and insights.")
            async def analyze_text(
                self, 
                text: Annotated[str, "The text to analyze"]
            ) -> Annotated[str, "Text analysis results and statistics"]:
                """Analyze text via the text analysis specialist."""
                try:
                    query = f"Please analyze this text: {text}"
                    response = await text_agent.get_response(messages=query)
                    return f"Text Analysis Specialist: {response.content}"
                except Exception as e:
                    return f"Text analysis error: {str(e)}"
        
        # Create plugin instances
        weather_plugin_wrapper = WeatherWrapperPlugin()
        text_plugin_wrapper = TextAnalysisWrapperPlugin()
        
        # Create your custom router
        custom_router = ChatCompletionAgent(
            id="CustomRouter",
            name="CustomRouter",
            instructions="""You are a custom router for weather and text analysis queries.

Available specialists via wrapper plugins:
• Weather Plugin: Provides weather information for any city or location
• Text Analysis Plugin: Analyzes text for statistics, sentiment, and insights

Route queries based on content:
- Weather queries: Use weather plugin for location-based weather requests
- Text analysis queries: Use text analysis plugin for text processing requests

Always indicate which specialist handled the query.""",
            plugins=[weather_plugin_wrapper, text_plugin_wrapper],
            service=AzureChatCompletion()
        )
        
        print("✅ Custom routing system created!")
        print("🔧 Using proper wrapper plugins for AzureAIAgent integration")
        
        # Test your system with different query types
        test_queries = [
            "What's the weather like in Seattle?",
            "Can you analyze this text: 'The quick brown fox jumps over the lazy dog. This is a test sentence for analysis.'"
        ]
        
        for i, test_query in enumerate(test_queries, 1):
            print(f"\n🧪 Test {i}: {test_query}")
            
            async for response in custom_router.invoke(messages=test_query):
                print(f"🤖 Custom Router: {response.content}")
                break
            
        # Cleanup custom agents
        await client.agents.delete_agent(weather_agent.id)
        await client.agents.delete_agent(text_agent.id)
        print("🧹 Custom agents cleaned up")
        
    except Exception as e:
        print(f"❌ Error in custom routing: {e}")

# Try the exercise
await create_custom_routing_system()

print("\n💡 Exercise Tips:")
print("1. Always create wrapper plugins with @kernel_function decorators")
print("2. AzureAIAgents cannot be used directly as plugins")
print("3. Use descriptive function names and descriptions")
print("4. Handle errors gracefully in wrapper functions")
print("5. Test with clear domain-specific queries")
print("6. Observe how routing decisions are made through wrapper plugins")

# %% [markdown]
## 🧹 Step 5: Cleanup and Best Practices

**Important**: Always clean up your resources properly in agent routing systems!

**Cleanup Considerations:**
- **Multiple Agents**: More agents = more resources to clean up
- **Hierarchical Dependencies**: Clean up in proper order
- **Client Management**: Properly close connections

**Production Best Practices:**
- Monitor agent performance and costs
- Implement proper error handling for routing failures
- Use connection pooling for high-throughput scenarios
- Cache routing decisions for similar queries

# %% [code]
# Comprehensive cleanup of all agents and resources

async def cleanup_routing_system():
    """Clean up all agents in the routing system."""
    
    print("🧹 Cleaning Up Agent Routing System")
    print("-" * 40)
    
    cleanup_count = 0
    
    if base_agents and base_agents['client']:
        client = base_agents['client']
        
        # Clean up base agents
        for agent_name, agent in base_agents.items():
            if agent_name != 'client' and hasattr(agent, 'id'):
                try:
                    await client.agents.delete_agent(agent.id)
                    print(f"✅ Deleted {agent_name} agent: {agent.name}")
                    cleanup_count += 1
                except Exception as e:
                    print(f"⚠️ Error deleting {agent_name} agent: {e}")
        
        # Close client connection
        try:
            await client.close()
            print("✅ Client connection closed")
        except Exception as e:
            print(f"ℹ️ Client cleanup: {e}")
    
    print(f"\n🎯 Cleanup Summary:")
    print(f"✅ {cleanup_count} base agents cleaned up")
    print(f"✅ Router agents (ChatCompletionAgent) automatically cleaned")
    print(f"✅ All connections properly closed")
    
    print("\n💡 Best Practices Demonstrated:")
    print("✅ Hierarchical cleanup (base agents first)")
    print("✅ Proper error handling during cleanup")
    print("✅ Resource management for complex systems")
    print("✅ Cost management through proper cleanup")

# Perform cleanup
await cleanup_routing_system()

# %% [markdown]
---

## 🎓 Congratulations! You're Now an Agent Routing Expert!

### What You've Mastered:

✅ **Hierarchical Agent Architecture:**
- AzureAIAgent for specialized, stateful base agents
- ChatCompletionAgent for lightweight routing and orchestration
- Multi-level agent coordination patterns

✅ **Intelligent Routing:**
- Domain-specific agent specialization
- Query analysis and intelligent dispatch
- Multi-agent coordination for complex queries

✅ **Production Patterns:**
- Proper resource management in complex systems
- Error handling across agent hierarchies
- Performance optimization for routing systems

### 🚀 Next Steps:

**Advanced Routing Patterns:**
1. **Conditional Routing**: Based on user context, preferences, or history
2. **Load Balancing**: Multiple instances of the same specialist type
3. **Fallback Chains**: Graceful degradation when specialists are unavailable
4. **Dynamic Agent Creation**: Creating specialists on-demand

**Enterprise Integration:**
- Authentication and authorization across agent hierarchies
- Monitoring and observability for routing decisions
- Cost optimization through intelligent agent utilization
- A/B testing different routing strategies

### 💡 Key Architectural Insights:

**When to Use AzureAIAgent vs ChatCompletionAgent:**
- **AzureAIAgent**: Complex workflows, state management, persistent conversations
- **ChatCompletionAgent**: Fast decisions, routing logic, stateless operations

**Scaling Patterns:**
- Start with simple 1-to-many routing
- Add coordination layers for complex workflows
- Implement caching and optimization as you scale

**Happy routing with Azure AI Agents!** 🎉

---

## 🔧 Quick Troubleshooting Guide

**Routing Issues:**
- Verify agent instructions are clear and domain-specific
- Check plugin integration for base agents
- Test individual agents before building hierarchies

**Performance Issues:**
- Monitor routing decision time vs. specialist execution time
- Consider caching for repeated routing patterns
- Use async operations throughout the hierarchy

**Cost Management:**
- Track token usage across multiple agents
- Implement query optimization to reduce unnecessary calls
- Clean up agents promptly to avoid ongoing charges

################################################################################  08-agent-routing\plugins.py  ################################################################################
# Import everything we need
import os
import asyncio
import json
import requests
import random
from datetime import datetime
from typing import Any, Dict, Annotated
from semantic_kernel.functions import kernel_function
from semantic_kernel.agents import ChatCompletionAgent
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion



# Weather Plugin
class WeatherPlugin:
    """A plugin for getting weather information."""
    
    @kernel_function(
        description="Gets the current weather for a city",
        name="get_weather"
    )
    def get_weather(
        self, 
        city: Annotated[str, "The name of the city to get weather for"]
    ) -> Annotated[str, "The current weather information"]:
        """
        Gets the current weather for a city (mock implementation).
        """
        # In a real implementation, you'd call a weather API
        weather_options = [
            f"Sunny and 72°F in {city}",
            f"Partly cloudy and 68°F in {city}", 
            f"Rainy and 61°F in {city}",
            f"Overcast and 65°F in {city}"
        ]
        weather = random.choice(weather_options)
        print(f"🌤️ Weather check: {weather}")
        return weather

# Random Number Plugin
class RandomPlugin:
    """A plugin for generating random numbers and choices."""
    
    @kernel_function(
        description="Generates a random number between min and max values",
        name="generate_random_number"
    )
    def generate_random_number(
        self, 
        min_val: Annotated[int, "The minimum value (inclusive)"], 
        max_val: Annotated[int, "The maximum value (inclusive)"]
    ) -> Annotated[int, "A random number between min and max"]:
        """
        Generates a random number between min and max values.
        """
        result = random.randint(min_val, max_val)
        print(f"🎲 Generated random number: {result} (between {min_val} and {max_val})")
        return result

# DateTime Plugin
class DateTimePlugin:
    """A plugin for date and time operations."""
    
    @kernel_function(
        description="Gets the current date and time",
        name="get_current_datetime"
    )
    def get_current_datetime(self) -> Annotated[str, "The current date and time"]:
        """
        Gets the current date and time.
        """
        now = datetime.now()
        formatted_time = now.strftime("%Y-%m-%d %H:%M:%S")
        print(f"🕐 Current time: {formatted_time}")
        return formatted_time

# Text Analysis Plugin
class TextAnalysisPlugin:
    """A plugin for analyzing text content."""
    
    @kernel_function(
        description="Analyzes text and returns statistics",
        name="analyze_text"
    )
    def analyze_text(
        self, 
        text: Annotated[str, "The text to analyze"]
    ) -> Annotated[str, "JSON string containing text analysis results"]:
        """
        Analyzes text and returns statistics.
        """
        words = text.split()
        analysis = {
            "character_count": len(text),
            "word_count": len(words),
            "sentence_count": text.count('.') + text.count('!') + text.count('?'),
            "average_word_length": round(sum(len(word) for word in words) / len(words), 2) if words else 0
        }
        print(f"📊 Text analysis complete: {analysis}")
        return json.dumps(analysis)

# RAG Plugin
class RAGPlugin:
    """A plugin for retrieving context from BMW 320i car insurance policy documents."""
    
    @kernel_function(
        description="Retrieves context about BMW 320i car insurance policy",
        name="get_insurance_context"
    )
    async def get_insurance_context(
        self, 
        query: Annotated[str, "The question about BMW 320i insurance policy"]
    ) -> Annotated[str, "The retrieved context from insurance documents"]:
        """
        Retrieves context about BMW 320i car insurance policy.
        """

        ### IMPORTANT ### 
        # An SK agent is used here to simulate a retrieval-augmented generation (RAG) process only.
        # In a real-world scenario, you would integrate with a document retrieval system or knowledge base.
        ### IMPORTANT ### 

        system_message = """You are a BMW 320i car insurance knowledge base. Return relevant context for queries about coverage, premiums, deductibles, and claims. Keep responses concise and factual."""
        
        rag_agent = ChatCompletionAgent(
            id="RAGAgent",
            name="RAGAgent", 
            instructions=system_message,
            description="This agent returns the context retrieved from insurance documents.",
            service=AzureChatCompletion(),
        )
        
        async for response in rag_agent.invoke(messages=query):
            content = response.content
            print(f"🔍 Insurance Agent / RAG context retrieved for: {query}")
            return content

# NL2SQL Plugin
class NL2SQLPlugin:
    """A plugin for retrieving banking transaction data via SQL queries."""
    
    @kernel_function(
        description="Converts natural language to SQL and returns banking transaction results",
        name="get_banking_data"
    )
    async def get_banking_data(
        self, 
        query: Annotated[str, "The question about banking transactions"]
    ) -> Annotated[str, "The retrieved banking transaction data"]:
        """
        Converts natural language to SQL and returns banking transaction results.
        """

        ### IMPORTANT ### 
        # An SK agent is used here to simulate a natural language to SQL (NL2SQL) process.
        # In a real-world scenario, you would integrate with a SQL database or service.
        ### IMPORTANT ### 

        system_message = """You are a banking transaction database. Return fake transaction data for queries about account balances, spending, deposits, and transaction history. Format as simple JSON or text."""
        
        sql_agent = ChatCompletionAgent(
            id="SQLAgent",
            name="SQLAgent",
            instructions=system_message,
            description="This agent returns transaction data from SQL database.",
            service=AzureChatCompletion(),
        )
        
        async for response in sql_agent.invoke(messages=query):
            content = response.content
            print(f"💳 Banking Agent / NL2SQL data retrieved for: {query}")
            return content

# Cosmos Plugin
class CosmosPlugin:
    """A plugin for retrieving multimodal sales analysis documents from Cosmos DB."""
    
    @kernel_function(
        description="Retrieves sales analysis data for smart city IoT solutions from Cosmos DB",
        name="get_sales_analysis"
    )
    async def get_sales_analysis(
        self, 
        query: Annotated[str, "The question about last year's sales analysis"]
    ) -> Annotated[str, "The retrieved sales analysis documents in JSON format"]:
        """
        Retrieves sales analysis data for smart city IoT solutions from Cosmos DB.
        """

        ### IMPORTANT ###
        # An SK agent is used here to simulate a retrieval process from Cosmos DB.
        # In a real-world scenario, you would integrate with Azure Cosmos DB or a similar service.
        ### IMPORTANT ###

        system_message = """You are a Cosmos DB containing multimodal sales analysis documents for a smart city IoT solutions company. Return fake JSON data about sales metrics, product performance, and market analysis from last year."""
        
        cosmos_agent = ChatCompletionAgent(
            id="CosmosAgent",
            name="CosmosAgent",
            instructions=system_message,
            description="This agent returns sales analysis documents from Cosmos DB.",
            service=AzureChatCompletion(),
        )
        
        async for response in cosmos_agent.invoke(messages=query):
            content = response.content
            print(f"📊 Sales Agent / Cosmos analysis retrieved for: {query}")
            return content

# Create plugin instances
weather_plugin = WeatherPlugin()
random_plugin = RandomPlugin()
datetime_plugin = DateTimePlugin()
text_analysis_plugin = TextAnalysisPlugin()
rag_plugin = RAGPlugin()
nl2sql_plugin = NL2SQLPlugin()
cosmos_plugin = CosmosPlugin()

print("✅ All utility plugins defined!")
print("🔧 Available plugins: Weather, Random, DateTime, TextAnalysis, RAG, NL2SQL, Cosmos")

################################################################################  08-agent-routing\README.md  ################################################################################
# Agent Routing

Learn how to build intelligent agent hierarchies where router agents coordinate multiple specialized agents. Create systems that automatically route complex queries to the right expert agents for optimal responses.

## What's In This Folder

**[08.1 - Azure AI Agent Routing Tutorial](08.1-azure_ai_agent_routing_tutorial.ipynb)**
Complete guide to building hierarchical agent systems with intelligent routing. Learn to create specialized AzureAIAgent workers, build ChatCompletionAgent routers, and coordinate multi-domain queries.

![Agent Router](images/router.gif)

**[plugins.py](plugins.py)**
Comprehensive plugin library with ready-to-use plugins for weather, text analysis, date/time operations, and more business domains.

## Learning Objectives

### Agent Architecture Patterns
- **Base Layer**: Specialized AzureAIAgent workers with persistent state
- **Orchestration Layer**: Lightweight ChatCompletionAgent routers
- **Plugin Integration**: Wrapper patterns for cross-agent communication
- **Hierarchical Organization**: Multi-level agent coordination

### Intelligent Routing Strategies
- **Domain Analysis**: Automatic query classification and routing
- **Specialist Dispatch**: Connecting queries to the right expert agent
- **Multi-Agent Coordination**: Handling queries requiring multiple specialists
- **Fallback Patterns**: Graceful handling of routing edge cases

## Prerequisites

### Azure Resources
- Azure subscription with sufficient quota
- Azure AI Foundry project configured
- Multiple deployed AI models (for different agent types)
- Appropriate permissions for agent creation and management

### Development Environment
- Python 3.8+
- Jupyter Notebook or VS Code
- Understanding of async/await patterns
- Familiarity with Azure AI Agents basics

### Required Knowledge
Complete these tutorials first:
- **[01-agent-basics](../01-agent-basics/)** - Azure AI Agents fundamentals
- **[02-agent-custom-functions](../02-agent-custom-functions/)** - Working with plugins
- **[03-orchestrated-agents](../03-orchestrated-agents/)** - Basic coordination patterns

### Environment Configuration
Update your `.env` file in the project root with:

```properties
# Required for agent routing
PROJECT_ENDPOINT="https://your-foundry-resource.services.ai.azure.com/api/projects/your-project-name"
MODEL_DEPLOYMENT_NAME="your-model-deployment-name"

# For Semantic Kernel components
AZURE_OPENAI_API_KEY="your-azure-openai-api-key"
AZURE_OPENAI_ENDPOINT="https://your-openai-resource.openai.azure.com/"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME="your-chat-deployment"
AZURE_OPENAI_DEPLOYMENT_NAME="your-deployment-name"
AZURE_OPENAI_API_VERSION="2024-12-01-preview"

# Optional: For advanced scenarios
AZURE_SUBSCRIPTION_ID="your-subscription-id"
```

### Required Packages
Install the necessary packages:

```bash
pip install azure-ai-agents azure-identity semantic-kernel pydantic
```

## Architecture Overview

### The Routing Pattern

```
┌─────────────────────────────┐
│    Orchestration Layer      │  ← ChatCompletionAgent (Router)
│      (Router Agent)         │    • Fast routing decisions
└────────────┬────────────────┘    • Lightweight & stateless
             │                     • Query analysis & dispatch
     ┌───────┼───────┐
     │               │
┌────▼────┐     ┌────▼────┐
│  Base   │     │  Base   │        ← AzureAIAgent (Specialists)
│ Agent 1 │     │ Agent 2 │          • Domain expertise
│Insurance│     │Banking  │          • Persistent state
└─────────┘     └─────────┘          • Plugin integration
```

### Why This Architecture?

**AzureAIAgent for Base Layer**
- Persistent state and conversation context
- Native plugin integration
- Deep Azure AI services integration
- Handles multi-step processes with memory

**ChatCompletionAgent for Routing**
- Fast routing decisions without state overhead
- Lightweight with minimal resource usage
- Plugin support for calling base agents
- Easy to modify routing logic

## Key Concepts

### Agent Specialization
- **Domain Experts**: Each base agent focuses on specific areas (insurance, banking, sales)
- **Plugin Integration**: Specialized tools and data sources for each domain
- **Context Retention**: Agents remember conversation history within their domain

### Intelligent Routing
- **Query Analysis**: Understanding user intent and domain requirements
- **Automatic Dispatch**: Routing queries to the most appropriate specialist
- **Multi-Domain Queries**: Coordinating multiple agents for complex requests

### Wrapper Plugin Pattern
Since AzureAIAgents cannot be used directly as plugins, we use wrapper patterns:

```python
class SpecialistWrapperPlugin:
    @kernel_function(description="Domain-specific functionality")
    async def specialist_function(self, query: str) -> str:
        response = await specialist_agent.get_response(messages=query)
        return response.content
```

## Next Steps

After mastering agent routing:
- [06-magentic-one-orchestration](../06-magentic-one-orchestration/) - Advanced orchestration patterns
- Build custom enterprise patterns for production-scale agent systems

🎉 **Ready to build intelligent agent hierarchies?** This tutorial will take you from basic routing concepts to production-ready agent orchestration systems that can handle complex, multi-domain queries with intelligent dispatch and coordination!

################################################################################  exercises\EXERCISES.md  ################################################################################
# Azure AI Agents Workshop Exercises

This document contains practical exercises for learning Azure AI Agents development. Each exercise builds upon the concepts from the playbook tutorials and provides hands-on experience with real-world scenarios.

## Prerequisites

Before starting these exercises, ensure you have:
- Completed the basic tutorials in [01-agent-basics](01-agent-basics/)
- Azure AI Foundry project configured
- Python environment set up with required packages
- `.env` file configured with your Azure credentials

## Beginner Level Exercises

### Exercise 1: Personal Assistant Agent
**Difficulty**: Beginner  
**Time**: 15-20 minutes  
**Skills**: Basic agent creation, custom functions

**Scenario**: Create a personal assistant agent that helps with daily tasks like scheduling, weather checks, and simple calculations.

**Requirements**:
1. Create an agent with a friendly personality
2. Add custom functions for:
   - Current date/time information
   - Simple calculator (add, subtract, multiply, divide)
   - Random motivational quote generator
3. Test the agent with conversational queries like:
   - "What time is it?"
   - "Calculate 25 * 4"
   - "Give me a motivational quote"

**Files to create**:
- `exercises/personal_assistant.py`
- Include error handling and type hints

**Learning outcomes**:
- Basic agent configuration
- Function registration
- Conversational interaction patterns

---

### Exercise 2: Voice-Enabled Stock Market Agent
**Difficulty**: Medium  
**Time**: 20-30 minutes  
**Skills**: Voice interaction, API integration, financial data processing

**Scenario**: Build a voice-controlled agent that provides real-time stock market information and analysis.

**Requirements**:
1. Get free Vatnage API Key from [here](https://www.alphavantage.co/support/#api-key)
2. Add `voice.py` python [file](../07-voice-orchestration/voice.py) from the 07 tutorial to the same folder you're working in
3. Use the already provided Alpha Vantage [OpenAPI JSON](openapi_files/stock_market.json) file to register the tool
4. Create an agent specialized in stock market data using the usual way, and then create an `AgentVoice` class instance
5. Test with voice-style prompts like:
    - "What's the current price of Apple stock?"
    - "Show me Microsoft's stock performance this week"
    - "Compare Tesla and Ford stock prices"

**Files to create**:
- `exercises/voice_stock_agent.py`

**Learning outcomes**:
- Voice command processing
- Real-time API data integration
- Financial data analysis patterns

---


## Getting Started

1. Create an `exercises/` directory in your workspace
2. Copy the basic setup from the playbook tutorials
3. Refer back to the main playbook tutorials for detailed examples


## Resources

- [Azure AI Agents Documentation](https://learn.microsoft.com/en-us/azure/ai-services/agents/)
- [Semantic Kernel Documentation](https://learn.microsoft.com/en-us/semantic-kernel/)
- [Azure AI Foundry](https://azure.microsoft.com/en-us/products/ai-foundry/)
- [Main Playbook Tutorials](README.md)

Happy coding! 🚀

################################################################################  exercises\solutions\exercise_1\exercise_1_personal_assistant.py  ################################################################################
import asyncio
from http import client
import os
from datetime import datetime
import random
from typing import Annotated

from azure.identity.aio import DefaultAzureCredential
from semantic_kernel.agents import AzureAIAgent
from semantic_kernel.functions import kernel_function

class PersonalAssistantPlugin:
    @kernel_function(description="Get current date and time")
    def get_current_time(self) -> Annotated[str, "Current date and time"]:
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    @kernel_function(description="Calculate basic math operations")
    def calculate(
        self, 
        operation: Annotated[str, "Math operation like '25 * 4' or '10 + 5'"]
    ) -> Annotated[str, "Calculation result"]:
        return str(eval(operation))
    
    @kernel_function(description="Get a motivational quote")
    def get_quote(self) -> Annotated[str, "A motivational quote"]:
        quotes = [
            "The only way to do great work is to love what you do. - Steve Jobs",
            "Innovation distinguishes between a leader and a follower. - Steve Jobs",
            "Stay hungry, stay foolish. - Steve Jobs",
            "The future belongs to those who believe in the beauty of their dreams. - Eleanor Roosevelt",
            "Success is not final, failure is not fatal: it is the courage to continue that counts. - Winston Churchill"
        ]
        return random.choice(quotes)

async def main():
    # Create the agent
    client = AzureAIAgent.create_client(
        credential=DefaultAzureCredential(), 
        endpoint=os.environ.get("PROJECT_ENDPOINT")
    )
    
    try:
        async with client:
            agent_definition = await client.agents.create_agent(
                model=os.environ.get("MODEL_DEPLOYMENT_NAME"),
                name="personal-assistant",
                instructions="You are a friendly personal assistant that helps with daily tasks."
            )
            
            agent = AzureAIAgent(
                client=client,
                definition=agent_definition,
                plugins=[PersonalAssistantPlugin()]
            )
            
            # Test questions
            questions = [
                "What time is it?",
                "Calculate 25 * 4",
                "Give me a motivational quote"
            ]
            
            # Have conversations
            for question in questions:
                print(f"User: {question}")
                response = await agent.get_response(question)
                print(f"Assistant: {response}\n")
            
            # Cleanup
            await client.agents.delete_agent(agent.id)

    finally:
        await client.close()

if __name__ == "__main__":
    asyncio.run(main())

################################################################################  exercises\solutions\exercise_2\voice.py  ################################################################################

from __future__ import annotations

import os
import uuid
import json
import asyncio
import base64
import logging
import threading
import numpy as np
import sounddevice as sd

from dotenv import load_dotenv
from typing import Dict, Union, Literal, Optional, Set, Callable, Awaitable
from typing_extensions import AsyncIterator, TypedDict, Required
from websockets.asyncio.client import connect as ws_connect
from websockets.asyncio.client import ClientConnection as AsyncWebsocket
from websockets.asyncio.client import HeadersLike
from websockets.typing import Data
from websockets.exceptions import WebSocketException
from azure.identity import DefaultAzureCredential
from azure.core.credentials_async import AsyncTokenCredential
from azure.identity import DefaultAzureCredential

logger = logging.getLogger(__name__)
AUDIO_SAMPLE_RATE = 24000

AudioTimestampTypes = Literal["word"]

class AzureDeepNoiseSuppression(TypedDict, total=False):
    type: Literal["azure_deep_noise_suppression"]

class ServerEchoCancellation(TypedDict, total=False):
    type: Literal["server_echo_cancellation"]

class AzureSemanticDetection(TypedDict, total=False):
    model: Literal["semantic_detection_v1"]
    threshold: float
    timeout: float

EOUDetection = AzureSemanticDetection

class AzureSemanticVAD(TypedDict, total=False):
    type: Literal["azure_semantic_vad"]
    end_of_utterance_detection: EOUDetection
    threshold: float
    silence_duration_ms: int
    prefix_padding_ms: int

class Animation(TypedDict, total=False):
    outputs: Set[Literal["blendshapes", "viseme_id", "emotion"]]

class Session(TypedDict, total=False):
    voice: Dict[str, Union[str, float]]
    turn_detection: Union[AzureSemanticVAD]
    input_audio_noise_reduction: AzureDeepNoiseSuppression
    input_audio_echo_cancellation: ServerEchoCancellation
    animation: Animation
    output_audio_timestamp_types: Set[AudioTimestampTypes]

class SessionUpdateEventParam(TypedDict, total=False):
    type: Literal["session.update"]
    session: Required[Session]
    event_id: str

class AsyncVoiceLiveSessionResource:
    def __init__(self, connection: AsyncVoiceLiveConnection) -> None:
        self._connection = connection

    async def update(
        self,
        *,
        session: Session,
        event_id: str | None = None,
    ) -> None:
        param: SessionUpdateEventParam = {
            "type": "session.update", "session": session, "event_id": event_id
        }
        data = json.dumps(param)
        await self._connection.send(data)

class AsyncVoiceLiveConnection:
    session: AsyncVoiceLiveSessionResource
    _connection: AsyncWebsocket

    def __init__(self, url: str, additional_headers: HeadersLike) -> None:
        self._url = url
        self._additional_headers = additional_headers
        self._connection = None
        self.session = AsyncVoiceLiveSessionResource(self)

    async def __aenter__(self) -> AsyncVoiceLiveConnection:
        try:
            self._connection = await ws_connect(self._url, additional_headers=self._additional_headers)
        except WebSocketException as e:
            raise ValueError(f"Failed to establish a WebSocket connection: {e}")
        return self

    async def __aexit__(self, exc_type, exc_value, traceback) -> None:
        if self._connection:
            await self._connection.close()
            self._connection = None
    
    enter = __aenter__
    close = __aexit__

    async def __aiter__(self) -> AsyncIterator[Data]:
        async for data in self._connection:
            yield data

    async def recv(self) -> Data:
        return await self._connection.recv()
    
    async def recv_bytes(self) -> bytes:
        return await self._connection.recv()

    async def send(self, message: Data) -> None:
        await self._connection.send(message)


class AsyncAzureVoiceLive:
    def __init__(
        self,
        *,
        azure_endpoint: str | None = None,
        api_version: str | None = "2025-05-01-preview",
        api_key: str | None = None,
        azure_ad_token_credential: AsyncTokenCredential | None = None,
        foundry_credential: AsyncTokenCredential | None = None,
        project_name: str | None = None,
        agent_id: str | None = None,
    ) -> None:
        if azure_endpoint is None:
            azure_endpoint = os.environ.get("AZURE_VOICE_LIVE_ENDPOINT")

        if azure_endpoint is None:
            raise ValueError(
                "Must provide the 'azure_endpoint' argument, or the 'AZURE_VOICE_LIVE_ENDPOINT' environment variable"
            )

        if api_key is None and azure_ad_token_credential is None:
            api_key = os.environ.get("AZURE_VOICE_LIVE_API_KEY")

        if api_key is None and azure_ad_token_credential is None:
            raise ValueError(
                "Missing credentials. Please pass one of 'api_key', 'azure_ad_token_credential', or the 'AZURE_VOICE_LIVE_API_KEY' environment variable."
            )

        if api_key and azure_ad_token_credential:
            raise ValueError(
                "Duplicating credentials. Please pass one of 'api_key' and 'azure_ad_token_credential'"
            )

        self._api_key = api_key
        self._azure_endpoint = azure_endpoint
        self._project_name = project_name
        self._agent_id = agent_id
        self._api_version = api_version
        self._azure_ad_token_credential = azure_ad_token_credential
        self._foundry_credential = foundry_credential
        self._connection = None
        self._token = self.get_token() if azure_ad_token_credential else None
        self._foundry_token = self.get_foundry_token() if foundry_credential else None

    def get_token(self) -> str:
        if self._azure_ad_token_credential:
            scopes = "https://ai.azure.com/.default"
            token = self._azure_ad_token_credential.get_token(scopes)
            return token.token
        else:
            return None
        
    def get_foundry_token(self) -> str:
        if self._foundry_credential:
            scopes = "https://ai.azure.com/.default"
            token = self._foundry_credential.get_token(scopes)
            return token.token
        else:
            return None        

    def refresh_token(self) -> None:
        self._token = self.get_token()

    def connect(self, model: str, agent_id: str = None) -> AsyncVoiceLiveConnection:
        if self._connection is not None:
            raise ValueError("Already connected to the Azure Voice Agent service.")
        if not model:
            raise ValueError("Model name is required.")
        if not isinstance(model, str):
            raise TypeError(f"The 'model' parameter must be of type 'str', but got {type(model).__name__}.")


        request_id = uuid.uuid4()

        url = f"{self._azure_endpoint.rstrip('/')}/voice-agent/realtime?api-version={self._api_version}&model={model}&agent_id={agent_id or self._agent_id}&agent-project-name={self._project_name}&agent_access_token={self._foundry_token}&Authorization=Bearer+{self._token}"
        url = url.replace("https://", "wss://")
        # print(f"Connecting to Azure Voice Agent at {url}")

        auth_header = {"Authorization": f"Bearer {self._token}"} if self._token else {"api-key": self._api_key}        
        headers = {"x-ms-client-request-id": str(request_id), **auth_header}

        self._connection = AsyncVoiceLiveConnection(
            url,
            additional_headers=headers,
        )
        return self._connection


# --- End of Embedded Code ---

class AudioPlayerAsync:
    def __init__(self):
        self.queue = []
        self.lock = threading.Lock()
        self.stream = sd.OutputStream(
            callback=self.callback,
            samplerate=AUDIO_SAMPLE_RATE,
            channels=1,
            dtype=np.int16,
            blocksize=1200,
        )
        self.playing = False

    def callback(self, outdata, frames, time, status):
        with self.lock:
            data = np.empty(0, dtype=np.int16)
            while len(data) < frames and len(self.queue) > 0:
                item = self.queue.pop(0)
                frames_needed = frames - len(data)
                data = np.concatenate((data, item[:frames_needed]))
                if len(item) > frames_needed:
                    self.queue.insert(0, item[frames_needed:])
            if len(data) < frames:
                data = np.concatenate((data, np.zeros(frames - len(data), dtype=np.int16)))
        outdata[:] = data.reshape(-1, 1)

    def add_data(self, data: bytes):
        with self.lock:
            np_data = np.frombuffer(data, dtype=np.int16)
            self.queue.append(np_data)
            if not self.playing:
                self.start()

    def start(self):
        self.playing = True
        self.stream.start()

    def stop(self):
        with self.lock:
            self.queue = []
        self.playing = False
        self.stream.stop()

    def terminate(self):
        self.stream.close()

async def listen_and_send_audio(connection: AsyncVoiceLiveConnection) -> None:
    logger.info("Starting audio stream ...")

    stream = sd.InputStream(channels=1, samplerate=AUDIO_SAMPLE_RATE, dtype="int16")
    try:
        stream.start()
        read_size = int(AUDIO_SAMPLE_RATE * 0.02)
        while True:
            if stream.read_available < read_size:
                continue
            data, _ = stream.read(read_size)
            audio = base64.b64encode(data).decode("utf-8")
            param = {"type": "input_audio_buffer.append", "audio": audio, "event_id": ""}
            data_json = json.dumps(param)
            try:
                await connection.send(data_json)
            except (ConnectionResetError, WebSocketException) as e:
                logger.error(f"WebSocket error while sending audio: {e}")
                break
    except Exception as e:
        logger.debug(f"Audio stream interrupted. {e}")
    finally:
        stream.stop()
        stream.close()
        logger.info("Audio stream closed.")



async def receive_audio_and_playback(connection: AsyncVoiceLiveConnection) -> None:
    last_audio_item_id = None
    audio_player = AudioPlayerAsync()

    logger.info("Starting audio playback ...")
    try:
        while True:
            transcript = ""
            async for raw_event in connection:
                try:
                    event = json.loads(raw_event)
                except json.JSONDecodeError as e:
                    logger.error(f"Failed to decode event: {e}")
                    break

                if event.get("type") == "response.audio.delta":
                    if event.get("item_id") != last_audio_item_id:
                        last_audio_item_id = event.get("item_id")
                    bytes_data = base64.b64decode(event.get("delta", ""))
                    audio_player.add_data(bytes_data)
                elif event.get("type") == "response.audio_transcript.done":
                    transcript = event.get("transcript", "")
                    print(f"Final Transcript: {transcript}")
                elif event.get("type") == "conversation.item.created":
                    item = event.get("item", None)
                    if item is not None:
                        content = item.get("content", [])
                        if len(content) > 0:
                            for c in content:
                                if item.get("role", "") == "user":
                                    print(f"User Transcript: {c.get('transcript', '')}")

                elif event.get("type") == "response.done":                    
                    break
    except (ConnectionResetError, WebSocketException) as e:
        logger.error(f"WebSocket error in audio playback: {e}")
    except Exception as e:
        logger.error(f"Error in audio playback: {e}")
    finally:
        audio_player.terminate()
        logger.info("Playback done.")

async def read_keyboard_and_quit() -> None:
    print("Press 'q' and Enter to quit the chat.")
    while True:
        # Run input() in a thread to avoid blocking the event loop
        user_input = await asyncio.to_thread(input) 
        if user_input.strip().lower() == 'q':
            print("Quitting the chat...")
            break




class AgentVoice():

    def __init__(self, 
                agent_id: str = None, 
                project_name: str = None,
                endpoint: str = None,
                deployment: str = None,
                api_key: str = None
            ) -> None:
        
        self.agent_id = agent_id or os.environ.get("AZURE_VOICE_LIVE_AGENT_ID") 
        self.project_name = project_name or os.environ.get("AZURE_FOUNDRY_PROJECT_NAME") 

        self.endpoint = endpoint or os.environ.get("AZURE_VOICE_LIVE_ENDPOINT")
        self.deployment = deployment or os.environ.get("AZURE_VOICE_LIVE_DEPLOYMENT")
        self.api_key = api_key or os.environ.get("AZURE_VOICE_LIVE_API_KEY")
        print(f"Using agent_id: {self.agent_id}")

        if not self.endpoint or not self.deployment:
            raise ValueError("Both AZURE_VOICE_LIVE_ENDPOINT and AZURE_VOICE_LIVE_DEPLOYMENT environment variables must be set.")
    

    def __repr__(self) -> str:
        return f"AgentVoice(agent_id={self.agent_id}, project_name={self.project_name})"

    async def connect(self) -> None:
        client = AsyncAzureVoiceLive(
            azure_endpoint = self.endpoint,
            # api_key = self.api_key,
            azure_ad_token_credential=DefaultAzureCredential(),
            foundry_credential=DefaultAzureCredential(),
            project_name = self.project_name,
            agent_id = self.agent_id,
        )

        async with client.connect(model = self.deployment) as connection:
            await connection.session.update(
                session={
                    "turn_detection": {
                        "create_response": True,
                        "interrupt_response": True,
                        "type": "azure_semantic_vad",
                        "threshold": 0.5,
                        "prefix_padding_ms": 400,
                        "silence_duration_ms": 400,
                        "remove_filler_words": True,
                        "end_of_utterance_detection": {
                            "model": "semantic_detection_v1",
                            "threshold": 0.01,
                            "timeout": 3,
                        },
                    },
                    "input_audio_transcription": {"model": "azure-fast-transcription"},     
                    "input_audio_noise_reduction": {"type": "azure_deep_noise_suppression"},
                    "input_audio_echo_cancellation": {"type": "server_echo_cancellation"},
                    "voice": {
                        "name": "en-US-Aria:DragonHDLatestNeural",
                        "type": "azure-standard",
                        "temperature": 0.3,
                    },      
                    # "model": "gpt-4.1",
                    "modalities": ["audio", "text"],
                    "tool_choice": "auto",
                    # "agent":{
                    #     "type": "agent",
                    #     "name": "test_research_agent",
                    #     "description": "Research agent for testing purposes",
                    #     "agent_id": agent_id,
                    #     "thread_id": ""
                    # }
                }
            )

            send_task = asyncio.create_task(listen_and_send_audio(connection))
            receive_task = asyncio.create_task(receive_audio_and_playback(connection))
            keyboard_task = asyncio.create_task(read_keyboard_and_quit())

            print("Starting the chat ...")
            await asyncio.wait([send_task, receive_task, keyboard_task], return_when=asyncio.FIRST_COMPLETED)

            send_task.cancel()
            receive_task.cancel()
        print("Chat done.")

if __name__ == "__main__":
    try:
        load_dotenv()
        av = AgentVoice(agent_id="asst_bEgFu4ATuu5XvMjHBP3y85ac")
        asyncio.run(av.connect())
    except Exception as e:
        print(f"Error: {e}")
        

################################################################################  exercises\solutions\exercise_2\voice_stock_agent.py  ################################################################################
import asyncio
import os
import json
from typing import Annotated

from azure.ai.agents import AgentsClient
from azure.ai.agents.models import OpenApiTool, OpenApiAnonymousAuthDetails
from azure.identity import DefaultAzureCredential

# Import voice module
from voice import AgentVoice


# Alpha Vantage API key for stock market data
# Replace with your actual API key
# You can get a free API key from https://www.alphavantage.co/support/#api-key
alphavantage_api_key = "<you_need_to_replace_with_your_api_key>"


async def create_stock_agent():
    model_deployment_name = os.environ.get("MODEL_DEPLOYMENT_NAME")
    endpoint = os.environ.get("PROJECT_ENDPOINT")
    
    credential = DefaultAzureCredential()
    agents_client = AgentsClient(endpoint=endpoint, credential=credential)
    
    # Load the stock market OpenAPI specification
    stock_spec_path = os.path.join("openapi_files", "stock_market.json")
    
    with open(stock_spec_path, "r") as f:
        stock_openapi_spec = json.loads(f.read())
    
    # Create OpenAPI tool for stock market data
    auth = OpenApiAnonymousAuthDetails()
    
    stock_tool = OpenApiTool(
        name="stock_market",
        spec=stock_openapi_spec,
        description="Get real-time stock market data from Alpha Vantage API",
        auth=auth
    )
    
    print("📈 Stock market OpenAPI tool created")
    print(f"Available operations: {len(stock_tool.definitions)}")
    
    with agents_client:
        agent = agents_client.create_agent(
            model=model_deployment_name,
            name="voice_stock_agent",
            instructions=f"You are a voice-controlled stock market assistant. Use the stock market API to get real-time stock prices and data. Always provide clear explanations of the stock information. Your responses are SUPER concise. Please use the Alpha Vantage API key: {alphavantage_api_key} for authentication. Use 'TIME_SERIES_DAILY' as the default function for daily stock data.",
            tools=stock_tool.definitions
        )
        
        print(f"🤖 Created voice stock agent: {agent.name}")
        print(f"🔧 Agent has stock market capabilities")
        print(f"🆔 Agent ID: {agent.id}")
    
    return agent, agents_client

async def main():
    print("🎙️ Starting Voice-Enabled Stock Market Agent Demo")
    print("=" * 60)
    
    # Create the stock agent
    print("Creating voice stock agent with market data integration...")
    agent, agents_client = await create_stock_agent()
    
    # Create voice interface with the agent
    print("\n🎤 Setting up voice interface...")
    av = AgentVoice(agent_id=agent.id)
    
    print("\n🗣️ Voice interface ready!")
    print("Sample voice commands you can try:")
    print("• 'What's the current price of Apple stock?'")
    print("• 'Show me Microsoft's stock performance this week'")
    print("• 'Compare Tesla and Ford stock prices'")
    print("• 'Get IBM stock history'")
    print("\nPress 'q' and Enter anytime to quit.")
    print("=" * 60)
    
    # Start the voice conversation
    await av.connect()
    
    print("\n👋 Demo completed!")

if __name__ == "__main__":
    asyncio.run(main())

################################################################################  LOCAL_CONFIG.MD  ################################################################################
# ⚙️ Local Environment Setup Guide for Workshop

Follow these step-by-step instructions to get your local development environment ready for the workshop! 🚀

---

## ✅ Step 1: Provision Azure Resources ☁️

Let’s set up everything you need in Azure to run your code with **Azure AI Foundry**.

---

### 1️⃣ Create a Resource Group

1. Go to the [Azure Portal](https://portal.azure.com).
2. Search for and select **Resource Groups**.
3. Click **+ Create** and fill out the form:
   - **Subscription**: Your active subscription
   - **Resource Group name**: `workshop-rg` (or a name of your choice)
   - **Region**: Preferably **East US 2**
4. Click **Review + Create** → **Create**.

---

### 2️⃣ Create an Azure AI Foundry Project 🧠

🔗 **Direct link**: [Create Azure AI Foundry Project](https://portal.azure.com/#create/Microsoft.CognitiveServicesAIFoundry)

1. Open the link above, or in the Azure Portal search for **Azure AI Foundry**.
2. Click **+ Create**, then:
   - Choose **East US 2** as the region.  
     ✅ *Required for service and model availability*
   - Select **Project** (*not Hub-based!*)
   - Leave all other fields at their default values.
3. Click **Review + Create** → **Create**.

> ⚠️ **Important:** Do **not** use a **hub-based** Foundry project. This workshop requires a **project-based** setup.

---

### 🔐 Fix Permissions

After the project is deployed:

- Navigate to your Foundry resource.
- You’ll likely see this message:
  > **"Insufficient permissions: Please assign the Azure AI User role to your user principal."**
- Click the **"Fix me"** button. This assigns the **Azure AI User** role to your account so you can deploy and use models.

---

### 🤖 Deploy Models

In your Azure AI Foundry resource:

1. Open the **Models** section.
2. Click **+ Add** or **Deploy**.
3. Deploy the following models (all **Global Standard** tier):
   - `gpt-4.1`
   - `o1`
   - `o3-mini`
4. Wait for all model deployments to finish before continuing.
 
---

# ⚙️ Local Environment Setup Guide for Workshop

Follow these step-by-step instructions to get your local development environment ready for the workshop!  🚀

---

## 💻 Step 2: Install / Update Azure CLI 🔧

The **Azure CLI (`az`)** is a command-line tool to interact with Azure services from your local terminal.

---

## 📦 Step 3: Clone the Repository 🔁

## 🐍 Step 4: Set Up a Virtual Environment & Install Dependencies

## 🛠️ Step 5: Configure Local Environment Variables 📁

################################################################################  NOTEBOOK_TEST_RUNNER.md  ################################################################################
# Notebook Test Runner

This script executes all Jupyter notebooks in the workspace and tracks their success/failure status. It's designed to be the first piece in a CI/CD pipeline that can be triggered nightly with GitHub Actions.

## Features

- 🔍 **Auto-discovery**: Automatically finds all `.ipynb` files in the workspace
- ⚡ **Parallel execution**: Executes notebooks in a controlled manner
- 📊 **Detailed reporting**: Provides comprehensive execution reports
- 🎯 **CI/CD ready**: Returns appropriate exit codes for automation
- 📝 **Multiple output formats**: Console, JSON, and HTML reports
- ⏱️ **Timeout protection**: Prevents hanging notebooks from blocking the pipeline
- 📋 **Execution tracking**: Tracks cells executed, timing, and error details

## Usage

### Basic Usage

```bash
# Run all notebooks with default settings
python notebook_test_runner.py

# Run with custom timeout (10 minutes)
python notebook_test_runner.py --timeout 600

# Generate JSON report
python notebook_test_runner.py --output-format json

# Generate HTML report
python notebook_test_runner.py --output-format html
```

### Command Line Options

- `--timeout SECONDS`: Maximum time to wait for each notebook (default: 600 seconds)
- `--output-format FORMAT`: Output format - `console`, `json`, or `html` (default: console)
- `--root-path PATH`: Root path to search for notebooks (default: current directory)

## Output Formats

### Console Output
Human-readable summary with status icons and detailed results.

### JSON Output
Machine-readable format perfect for CI/CD integration. Creates `notebook_test_results.json`.

### HTML Output
Beautiful HTML report with styling. Creates `notebook_test_results.html`.

## Exit Codes

- `0`: All notebooks executed successfully
- `1`: Some notebooks failed or had errors
- `2`: No notebooks found to execute
- `130`: Interrupted by user (Ctrl+C)

## CI/CD Integration

The script is designed for CI/CD pipelines. It will:

1. Return appropriate exit codes
2. Generate detailed logs
3. Create test artifacts (JSON/HTML reports)
4. Handle timeouts gracefully
5. Skip problematic files (checkpoints, build directories)

## Example GitHub Actions Integration

```yaml
name: Nightly Notebook Tests

on:
  schedule:
    - cron: '0 2 * * *'  # Run at 2 AM daily
  workflow_dispatch:      # Allow manual triggers

jobs:
  test-notebooks:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run notebook tests
      run: |
        python notebook_test_runner.py --output-format json --timeout 900
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: notebook-test-results
        path: |
          notebook_test_results.json
          notebook_test_runner.log
```

## Logs

The script generates detailed logs in `notebook_test_runner.log` with timestamps and execution details.

## Discovered Notebooks

The script will automatically discover and execute these notebooks:

- `01-agent-basics/01.1-azure_ai_agents_foundry_sdk_tutorial.ipynb`
- `01-agent-basics/01.2-azure_ai_agents_semantic_kernel_tutorial.ipynb`
- `01-agent-basics/01.3-python_with_statement_agents_tutorial.ipynb`
- `02-agent-custom-functions/02.1-azure_ai_agents_functions_foundry_sdk_tutorial.ipynb`
- `02-agent-custom-functions/02.2-azure_ai_agents_semantic_kernel_plugins_tutorial.ipynb`
- `03-orchestrated-agents/03.1-concurrent_and_sequential_orchestration_tutorial.ipynb`
- `03-orchestrated-agents/03.2-connected_agents_tutorial.ipynb`
- `04-orchestrated-agents-with-tools/04.1-openapi_currency_exchange_tutorial.ipynb`
- `04-orchestrated-agents-with-tools/04.2-hybrid_openapi_and_plugins_tutorial.ipynb`
- `04-orchestrated-agents-with-tools/04.3-logic_apps_hybrid_tutorial.ipynb`
- `05-orchestrated-agents-with-custom-openapi-tools/05.1-fastapi_openapi_tutorial.ipynb`
- `06-magentic-one-orchestration/06.1-magentic_creative_writing_tutorial.ipynb`
- `06-magentic-one-orchestration/06.2-magentic_bing_search_orchestration_tutorial.ipynb`

## Error Handling

The script handles various error scenarios:

- **Cell execution errors**: Captures and reports failed cells
- **Timeout errors**: Prevents hanging notebooks
- **Missing dependencies**: Reports import errors
- **File access errors**: Handles permission issues
- **Keyboard interrupts**: Graceful shutdown on Ctrl+C

################################################################################  notebook_test_runner.py  ################################################################################
#!/usr/bin/env python3
"""
Notebook Test Runner for CI/CD Pipeline

This script executes all Jupyter notebooks in the workspace and tracks their
success/failure status. It's designed to be the first piece in a CI/CD pipeline
that can be triggered nightly with GitHub Actions.

Usage:
    python notebook_test_runner.py [--timeout SECONDS] [--output-format FORMAT]

The script will:
1. Discover all .ipynb files in the workspace
2. Execute each notebook in order
3. Track execution time and success/failure status
4. Generate a detailed report
5. Exit with appropriate status code for CI/CD integration
"""

import argparse
import json
import logging
import os
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import nbformat
from nbconvert.preprocessors import ExecutePreprocessor
from nbconvert.preprocessors.execute import CellExecutionError


class NotebookTestRunner:
    """Main class for running notebook tests."""
    
    def __init__(self, timeout: int = 600, output_format: str = "console"):
        """
        Initialize the notebook test runner.
        
        Args:
            timeout: Maximum time in seconds to wait for each notebook to complete
            output_format: Output format for results ("console", "json", "html")
        """
        self.timeout = timeout
        self.output_format = output_format
        self.results = []
        self.start_time = datetime.now()
        
        # Setup logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('notebook_test_runner.log'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def discover_notebooks(self, root_path: str = ".") -> List[Path]:
        """
        Discover all Jupyter notebooks in the workspace.
        
        Args:
            root_path: Root path to search for notebooks
            
        Returns:
            List of notebook file paths
        """
        notebook_paths = []
        root = Path(root_path).resolve()
        
        # Find all .ipynb files, excluding checkpoints and build directories
        for notebook_path in root.rglob("*.ipynb"):
            # Skip checkpoint files and build directories
            if ".ipynb_checkpoints" in str(notebook_path):
                continue
            if "build" in notebook_path.parts:
                continue
            
            notebook_paths.append(notebook_path)
        
        # Sort notebooks by path for consistent execution order
        notebook_paths.sort()
        
        self.logger.info(f"Discovered {len(notebook_paths)} notebooks")
        for nb_path in notebook_paths:
            self.logger.info(f"  - {nb_path.relative_to(root)}")
        
        return notebook_paths
    
    def execute_notebook(self, notebook_path: Path) -> Dict:
        """
        Execute a single notebook and return execution results.
        
        Args:
            notebook_path: Path to the notebook file
            
        Returns:
            Dictionary containing execution results
        """
        result = {
            "notebook": str(notebook_path.relative_to(Path.cwd())),
            "status": "unknown",
            "execution_time": 0,
            "start_time": datetime.now().isoformat(),
            "end_time": None,
            "error_message": None,
            "cells_executed": 0,
            "total_cells": 0
        }
        
        start_time = time.time()
        
        try:
            self.logger.info(f"Executing notebook: {result['notebook']}")
            
            # Read the notebook
            with open(notebook_path, "r", encoding="utf-8") as f:
                notebook = nbformat.read(f, as_version=4)
            
            # Count total cells
            result["total_cells"] = len([cell for cell in notebook.cells if cell.cell_type == "code"])
            
            # Create executor
            executor = ExecutePreprocessor(
                timeout=self.timeout,
                kernel_name="python3",
                allow_errors=False  # Stop on first error
            )
            
            # Execute the notebook
            executor.preprocess(notebook, {"metadata": {"path": str(notebook_path.parent)}})
            
            # Count executed cells
            result["cells_executed"] = len([
                cell for cell in notebook.cells 
                if cell.cell_type == "code" and cell.get("execution_count") is not None
            ])
            
            result["status"] = "success"
            self.logger.info(f"✅ Successfully executed: {result['notebook']}")
            
        except CellExecutionError as e:
            result["status"] = "failed"
            result["error_message"] = str(e)
            self.logger.error(f"❌ Cell execution error in {result['notebook']}: {e}")
            
        except Exception as e:
            result["status"] = "error"
            result["error_message"] = str(e)
            self.logger.error(f"💥 Unexpected error in {result['notebook']}: {e}")
        
        finally:
            end_time = time.time()
            result["execution_time"] = round(end_time - start_time, 2)
            result["end_time"] = datetime.now().isoformat()
        
        return result
    
    def run_all_notebooks(self, root_path: str = ".") -> List[Dict]:
        """
        Run all discovered notebooks and return results.
        
        Args:
            root_path: Root path to search for notebooks
            
        Returns:
            List of execution results for each notebook
        """
        notebooks = self.discover_notebooks(root_path)
        
        if not notebooks:
            self.logger.warning("No notebooks found to execute")
            return []
        
        self.logger.info(f"Starting execution of {len(notebooks)} notebooks")
        
        for notebook_path in notebooks:
            result = self.execute_notebook(notebook_path)
            self.results.append(result)
            
            # Add some spacing between notebook executions
            time.sleep(1)
        
        return self.results
    
    def generate_summary(self) -> Dict:
        """Generate a summary of all test results."""
        if not self.results:
            return {
                "total_notebooks": 0,
                "successful": 0,
                "failed": 0,
                "errors": 0,
                "total_execution_time": 0,
                "overall_status": "no_notebooks"
            }
        
        successful = len([r for r in self.results if r["status"] == "success"])
        failed = len([r for r in self.results if r["status"] == "failed"])
        errors = len([r for r in self.results if r["status"] == "error"])
        total_time = sum(r["execution_time"] for r in self.results)
        
        overall_status = "success" if failed == 0 and errors == 0 else "failed"
        
        return {
            "total_notebooks": len(self.results),
            "successful": successful,
            "failed": failed,
            "errors": errors,
            "total_execution_time": round(total_time, 2),
            "overall_status": overall_status,
            "test_run_start": self.start_time.isoformat(),
            "test_run_end": datetime.now().isoformat()
        }
    
    def output_results(self):
        """Output results in the specified format."""
        summary = self.generate_summary()
        
        if self.output_format == "json":
            self._output_json(summary)
        elif self.output_format == "html":
            self._output_html(summary)
        else:
            self._output_console(summary)
    
    def _output_console(self, summary: Dict):
        """Output results to console in a human-readable format."""
        print("\n" + "="*80)
        print("📊 NOTEBOOK TEST RUNNER RESULTS")
        print("="*80)
        
        print(f"📝 Total notebooks: {summary['total_notebooks']}")
        print(f"✅ Successful: {summary['successful']}")
        print(f"❌ Failed: {summary['failed']}")
        print(f"💥 Errors: {summary['errors']}")
        print(f"⏱️  Total execution time: {summary['total_execution_time']} seconds")
        print(f"🎯 Overall status: {summary['overall_status'].upper()}")
        
        print("\n📋 DETAILED RESULTS:")
        print("-" * 80)
        
        for result in self.results:
            status_icon = "✅" if result["status"] == "success" else "❌" if result["status"] == "failed" else "💥"
            print(f"{status_icon} {result['notebook']}")
            print(f"   Status: {result['status']}")
            print(f"   Execution time: {result['execution_time']}s")
            print(f"   Cells executed: {result['cells_executed']}/{result['total_cells']}")
            
            if result["error_message"]:
                print(f"   Error: {result['error_message'][:100]}...")
            print()
    
    def _output_json(self, summary: Dict):
        """Output results in JSON format."""
        output = {
            "summary": summary,
            "results": self.results
        }
        
        with open("notebook_test_results.json", "w") as f:
            json.dump(output, f, indent=2)
        
        print(json.dumps(output, indent=2))
    
    def _output_html(self, summary: Dict):
        """Output results in HTML format."""
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Notebook Test Results</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .summary {{ background: #f5f5f5; padding: 15px; border-radius: 5px; margin-bottom: 20px; }}
        .success {{ color: green; }}
        .failed {{ color: red; }}
        .error {{ color: orange; }}
        table {{ border-collapse: collapse; width: 100%; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
    </style>
</head>
<body>
    <h1>📊 Notebook Test Results</h1>
    
    <div class="summary">
        <h2>Summary</h2>
        <p><strong>Total notebooks:</strong> {summary['total_notebooks']}</p>
        <p><strong>Successful:</strong> <span class="success">{summary['successful']}</span></p>
        <p><strong>Failed:</strong> <span class="failed">{summary['failed']}</span></p>
        <p><strong>Errors:</strong> <span class="error">{summary['errors']}</span></p>
        <p><strong>Total execution time:</strong> {summary['total_execution_time']} seconds</p>
        <p><strong>Overall status:</strong> {summary['overall_status'].upper()}</p>
    </div>
    
    <h2>Detailed Results</h2>
    <table>
        <tr>
            <th>Notebook</th>
            <th>Status</th>
            <th>Execution Time (s)</th>
            <th>Cells Executed</th>
            <th>Error Message</th>
        </tr>
"""
        
        for result in self.results:
            status_class = result["status"]
            error_msg = result["error_message"][:100] + "..." if result["error_message"] else ""
            
            html_content += f"""
        <tr>
            <td>{result['notebook']}</td>
            <td class="{status_class}">{result['status']}</td>
            <td>{result['execution_time']}</td>
            <td>{result['cells_executed']}/{result['total_cells']}</td>
            <td>{error_msg}</td>
        </tr>
"""
        
        html_content += """
    </table>
</body>
</html>
"""
        
        with open("notebook_test_results.html", "w") as f:
            f.write(html_content)
        
        print("HTML report generated: notebook_test_results.html")
    
    def get_exit_code(self) -> int:
        """Get appropriate exit code for CI/CD systems."""
        summary = self.generate_summary()
        
        if summary["overall_status"] == "success":
            return 0  # Success
        elif summary["overall_status"] == "no_notebooks":
            return 2  # No notebooks found
        else:
            return 1  # Failures or errors


def main():
    """Main entry point for the script."""
    parser = argparse.ArgumentParser(
        description="Execute Jupyter notebooks and generate test reports for CI/CD pipelines"
    )
    parser.add_argument(
        "--timeout",
        type=int,
        default=600,
        help="Maximum time in seconds to wait for each notebook (default: 600)"
    )
    parser.add_argument(
        "--output-format",
        choices=["console", "json", "html"],
        default="console",
        help="Output format for results (default: console)"
    )
    parser.add_argument(
        "--root-path",
        default=".",
        help="Root path to search for notebooks (default: current directory)"
    )
    
    args = parser.parse_args()
    
    # Create and run the test runner
    runner = NotebookTestRunner(
        timeout=args.timeout,
        output_format=args.output_format
    )
    
    try:
        runner.run_all_notebooks(args.root_path)
        runner.output_results()
        exit_code = runner.get_exit_code()
        
        if exit_code == 0:
            runner.logger.info("🎉 All notebooks executed successfully!")
        elif exit_code == 1:
            runner.logger.error("❌ Some notebooks failed to execute")
        else:
            runner.logger.warning("⚠️  No notebooks found to execute")
        
        sys.exit(exit_code)
        
    except KeyboardInterrupt:
        runner.logger.info("🛑 Test run interrupted by user")
        sys.exit(130)
    except Exception as e:
        runner.logger.error(f"💥 Unexpected error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

################################################################################  README.md  ################################################################################
# Azure AI Agents Orchestration Playbook

A comprehensive collection of tutorials for building production-ready Azure AI Agents, from basic conversations to complex multi-agent orchestration systems with voice capabilities and external API integrations.

> **Note:** Check out our **animated** PowerPoint presentation for an overview: [Azure AI Agents Orchestration Playbook Presentation](./Azure%20AI%20Agent%20Orchestration.pptx)

## Tutorial Structure

### Foundational Concepts
- **[01-agent-basics](01-agent-basics/)** - Core Azure AI Agents fundamentals using Foundry SDK and Semantic Kernel
- **[02-agent-custom-functions](02-agent-custom-functions/)** - Extend agent capabilities with custom functions and plugins

### Multi-Agent Systems
- **[03-orchestrated-agents](03-orchestrated-agents/)** - Coordinate multiple agents for complex workflows
- **[04-orchestrated-agents-with-tools](04-orchestrated-agents-with-tools/)** - Integrate external APIs and Azure Logic Apps
- **[05-orchestrated-agents-with-custom-openapi-tools](05-orchestrated-agents-with-custom-openapi-tools/)** - Connect agents to custom FastAPI services
- **[06-magentic-one-orchestration](06-magentic-one-orchestration/)** - Advanced orchestration with Magentic-One framework

### Advanced Capabilities
- **[07-voice-orchestration](07-voice-orchestration/)** - Voice-enabled agents with real-time audio processing
- **[08-agent-routing](08-agent-routing/)** - Hierarchical routing design pattern for multi-agent systems


![Agent Router](08-agent-routing/images/router.gif)



## Getting Started

### Prerequisites
- Azure subscription with AI services
- Azure AI Foundry project with deployed models
- Python 3.8+ with Jupyter support
 
### Quick Setup
1. **Clone the repository**
   ```bash
   git clone https://github.com/Azure-Samples/azure-ai-agents-playbook.git
   cd azure-ai-agents-playbook
   ```

2. **Configure environment**
   - Update `.env` file with your Azure AI project details
   - Install dependencies: `pip install -r requirements.txt`

3. **Start learning**
   - Begin with [01-agent-basics](01-agent-basics/) for fundamentals
   - Progress through tutorials in numerical order

For detailed instructions, please follow the step by step guide [here](LOCAL_CONFIG.MD) .

## Learning Path

**Recommended progression:**

1. **Basics** → Learn core Azure AI Agents concepts and development patterns
2. **Functions** → Add custom capabilities to extend agent functionality  
3. **Orchestration** → Coordinate multiple agents for complex workflows
4. **Tools** → Integrate external services and automation workflows
5. **Custom APIs** → Connect agents to your own business services
6. **Advanced** → Master sophisticated orchestration frameworks
7. **Voice** → Add voice interaction capabilities

## What You'll Build

By completing this playbook, you'll master:

- **Conversational AI Agents** with persistent context and memory
- **Multi-Agent Systems** that collaborate intelligently
- **Tool-Enhanced Agents** connected to external APIs and services  
- **Voice-Enabled Agents** with real-time audio processing
- **Enterprise Workflows** combining AI with business automation
- **Production Patterns** for scalable and reliable agent systems

## 🔧 Key Technologies

- **Azure AI Agents** - Core agent development platform
- **Azure AI Foundry SDK** - Official Microsoft agent framework
- **Semantic Kernel** - Advanced orchestration and plugin system
- **Azure Speech Services** - Voice recognition and synthesis
- **Azure Logic Apps** - Workflow automation and integration
- **FastAPI** - Custom API development and OpenAPI integration

## 📋 Environment Configuration

Each tutorial folder contains specific setup instructions. The main environment variables needed:

- `PROJECT_ENDPOINT` - Your Azure AI Foundry project endpoint
- `MODEL_DEPLOYMENT_NAME` - Your deployed AI model name
- `AZURE_OPENAI_*` - Azure OpenAI configuration for Semantic Kernel
- `AZURE_VOICE_*` - Speech services for voice tutorials

## 🎪 Tutorial Highlights

**Real-world scenarios you'll implement:**
- Financial assistants analyzing bank transactions
- Research agents conducting web searches and fact-checking
- Creative content pipelines with multi-agent collaboration
- Email automation through voice commands
- Currency exchange agents with live API data
- Complex business workflows with AI decision-making

## 🔗 Additional Resources

- [Azure AI Agents Documentation](https://docs.microsoft.com/azure/ai-services/agents/)
- [Semantic Kernel Documentation](https://learn.microsoft.com/semantic-kernel/)
- [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/)

---

**Ready to build the future of AI agents?** 🚀🤖

################################################################################  scenarios.md  ################################################################################


1. Simple connected agents - foundry sdk
1. Simple connected agents - SK
1. Connected agents with functions - openapi - foundry sdk
1. Connected agents with functions - openapi - SK
1. Connected agents with MCP - foundry SDK
1. Connected agents with MCP - SK
1. SK Orchestrator with plugins and cloud functions - SK
1. SK Magenetic Orchestrator with plugins and cloud functions - SK 




1. have a section on best practices recommendations- ie what is our POV on start small and grow
2. M365 Copilot + Azure AI Agents

################################################################################  sk-foundry-agents.ipynb  ################################################################################
# %% [markdown]
## Semantic Kernel with AI Foundry Agents
### Setup AI Foundry client

# %% [code]
import os
from azure.identity.aio import DefaultAzureCredential
from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings, AzureAIAgentThread
from dotenv import load_dotenv

load_dotenv()

creds = DefaultAzureCredential()

endpoint = os.environ["PROJECT_ENDPOINT"]

client = AzureAIAgent.create_client(
    credential=creds, 
    endpoint=endpoint,
)

# %% [markdown]
### Create new agents

# %% [code]
agent_definition_1 = await client.agents.create_agent(
    model="gpt-4.1",
    name="JokeStarter",
    description="Initiates knock-knock jokes",
    instructions="""You are a knock-knock joke initiator. Your role is to:
1. Start with "Knock knock"
2. Wait for "Who's there?" response
3. Provide the setup (e.g., "Lettuce")
4. Wait for "[setup] who?" response
5. Deliver the punchline
6. After completing the joke, say 'TERMINATE'

Always check message history to continue from where the conversation left off.""",
)

print(f"🤖 Agent definition created: {agent_definition_1.name}")
print(f"🤖 Agent ID: {agent_definition_1.id}")

agent_definition_2 = await client.agents.create_agent(
    model="gpt-4.1",
    name="JokeResponder",
    description="Responds to knock-knock jokes",
    instructions="""You are responding to knock-knock jokes. Your role is to:
1. When you see "Knock knock", respond with "Who's there?"
2. When you see a name/word (like "Lettuce"), respond with "[that word] who?"
3. After the previous two points, listen to the punchline and laugh or react appropriately
4. DO NOT REPEAT THE PREVIOUS LINE or INITIATE A NEW JOKE or REPEAT THE JOKE SETUP
4. Never say 'TERMINATE' - only the joke starter does that

Always check message history to continue from where the conversation left off.""",
)

print(f"🤖 Agent definition created: {agent_definition_2.name}")
print(f"🤖 Agent ID: {agent_definition_2.id}")

# %% [markdown]
### Group Chat between AI Foundry Agents

# %% [code]
from semantic_kernel.agents.open_ai.run_polling_options import RunPollingOptions
from datetime import timedelta

agents = []

agent_1 = AzureAIAgent(
    client=client,
    definition=agent_definition_1,
    polling_options=RunPollingOptions(default_polling_interval=timedelta(milliseconds=1000))
)

agent_2 = AzureAIAgent(
    client=client,
    definition=agent_definition_2,
    polling_options=RunPollingOptions(default_polling_interval=timedelta(milliseconds=1000))
)


agents = [agent_1, agent_2] 

# %% [code]
from semantic_kernel.agents import GroupChatOrchestration, RoundRobinGroupChatManager, AzureAIAgentThread
from semantic_kernel.contents import ChatMessageContent
from semantic_kernel.agents import (
    Agent,
    AzureAIAgent,
    ConcurrentOrchestration,
    SequentialOrchestration
)

from semantic_kernel.agents.runtime import InProcessRuntime

def agent_response_callback(message: ChatMessageContent) -> None:
    """Observer function to print the messages from the agents."""
    print(f"**{message.name}**\n{message.content}")

thread = AzureAIAgentThread(client=client)

group_chat_orchestration = GroupChatOrchestration(
    members=agents,
    # max_rounds is odd, so that the writer gets the last round
    manager=RoundRobinGroupChatManager(max_rounds=6),
    agent_response_callback=agent_response_callback,
)

# 2. Create a runtime and start it
runtime = InProcessRuntime()
runtime.start()

# 3. Invoke the orchestration with a task and the runtime
orchestration_result = await group_chat_orchestration.invoke(
    task="Start a knock-knock joke.",
    runtime=runtime,
)

result = await orchestration_result.get()

# 5. Stop the runtime after the invocation is complete
await runtime.stop_when_idle()

# %% [code]

################################################################################  xtest.ipynb  ################################################################################
# %% [code]
%load_ext autoreload
%autoreload 2

import os
import glob
import yaml
import shutil
import importlib.util
import logging

from pydantic import BaseModel

from semantic_kernel.agents import Agent, ChatCompletionAgent
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings
from semantic_kernel.agents import ChatHistoryAgentThread
from semantic_kernel.functions.kernel_arguments import KernelArguments


from rich.console import Console
console = Console()

from dotenv import load_dotenv
load_dotenv(override=True)

# %% [code]
import json
import os
from pathlib import Path
from typing import Iterable


def _read_notebook(src: Path, encoding: str = "utf-8") -> str:
    """
    Return a text representation of the notebook at *src* containing only
    markdown and code cells, in their original order.
    """
    with src.open("r", encoding=encoding) as f:
        nb = json.load(f)

    lines: list[str] = []
    for cell in nb.get("cells", []):
        cell_type = cell.get("cell_type")
        if cell_type not in {"markdown", "code"}:
            continue  # skip raw or unknown cells

        tag = f"# %% [{cell_type}]"
        lines.append(tag)

        # ipynb spec: cell["source"] is a list of strings OR a single string
        src_lines = cell.get("source", [])
        if isinstance(src_lines, str):
            src_lines = [src_lines]

        # Ensure newline handling is consistent
        lines.extend(line.rstrip("\n") for line in src_lines)
        lines.append("")  # blank line between cells

    return "\n".join(lines)


def bundle_source_tree(
    root_dir: str | os.PathLike,
    output_file: str | os.PathLike,
    extensions: Iterable[str] = (".ipynb", ".md", ".py"),
    header_prefix: str = "#" * 80,
    encoding: str = "utf-8",
) -> None:
    """
    Concatenate the contents of every file with suffix in *extensions* found
    under *root_dir* (recursively) into *output_file*.

    For *.ipynb* files, only the markdown and code cells are kept.
    Every file is separated by a banner:

        ########  relative/path/to/file  ########
    """
    root_path = Path(root_dir).expanduser().resolve()
    out_path = Path(output_file).expanduser().resolve()
    exts = tuple(ext.lower() for ext in extensions)

    print(f"Bundling source tree from {root_path} to {out_path} with extensions {exts}")

    with out_path.open("w", encoding=encoding) as out_f:
        for file_path in sorted(root_path.rglob("*")):
            if ".git" in str(file_path): continue
            if ".venv" in str(file_path): continue
            if "__pycache__" in str(file_path): continue
            if "do_not_commit" in str(file_path): continue

            if not (file_path.is_file() and file_path.suffix.lower() in exts):
                print(f"Skipping {file_path} (not a file or unsupported extension)")
                continue

            
            rel_path = file_path.relative_to(root_path)
            print(f"Processing {file_path} (as {rel_path})")
            banner = f"{header_prefix}  {rel_path}  {header_prefix}"
            out_f.write(banner + "\n")

            try:
                if file_path.suffix.lower() == ".ipynb":
                    content = _read_notebook(file_path, encoding)
                else:
                    content = file_path.read_text(encoding=encoding)
            except UnicodeDecodeError:
                # fall back to binary decode with replacement chars
                with file_path.open("rb") as bin_f:
                    content = bin_f.read().decode(encoding, errors="replace")

            out_f.write(content.rstrip("\n") + "\n\n")  # two newlines between files


if __name__ == "__main__":
    # Example usage:
    bundle_source_tree("./", "llm_agents_playbook.txt")
    

# %% [code]

# %% [code]

# %% [code]

# %% [code]
import os
import time
from azure.ai.agents import AgentsClient
from azure.ai.agents.models import (
    AgentThreadCreationOptions, 
    ThreadMessageOptions, 
    ListSortOrder
)
from azure.identity import DefaultAzureCredential
from azure.core.credentials import AzureKeyCredential

from azure.core.credentials_async import AsyncTokenCredential

def get_foundry_token(credential) -> str:
    scopes = "https://ai.azure.com/.default"
    token = credential.get_token(scopes)
    return token.token



# Create our Azure AI Agents client
# This is our main interface to the Azure AI Agents service
 
def create_agents_client():
    try:

        DefaultAzureCredential()
       
        credential = AzureKeyCredential(os.environ["AZURE_VOICE_LIVE_API_KEY"])
        token = get_foundry_token(credential)


        agents_client = AgentsClient(
            endpoint=os.environ["PROJECT_ENDPOINT"],
            credential=token
        )
        print("🎉 Successfully connected to Azure AI Agents!")
        print("Your client is ready to create and manage AI agents.")
        return agents_client
       
    except Exception as e:
        print(f"❌ Error creating client: {e}")
        print("Please check your environment variables and Azure credentials.")
        return None
   
# Create the client
agents_client = create_agents_client()    

# %% [code]
# Create the agent
agent = agents_client.create_agent(
    model=os.environ["MODEL_DEPLOYMENT_NAME"],  # The AI model to use
    name="joke-master-3000",                     # A friendly name
    instructions="You are a helpful and funny assistant that loves telling programming jokes and general jokes. Keep responses light and entertaining!"
)

print(f"🎉 Agent created successfully!")
print(f"🆔 Agent ID: {agent.id}")
print(f"📝 Agent Name: {agent.name}")
print(f"🧠 Model: {agent.model}")

# Store the agent ID for later use
agent_id = agent.id

# %% [code]

# %% [code]
import os

from semantic_kernel.agents import (
    ChatCompletionAgent,
    MagenticOrchestration,
    StandardMagenticManager,
)
from semantic_kernel.agents.runtime import InProcessRuntime
from semantic_kernel.contents import ChatMessageContent
from semantic_kernel.contents.chat_message_content import ChatMessageContent
from semantic_kernel.agents import ChatHistoryAgentThread
from azure.identity import DefaultAzureCredential
from azure.ai.projects.aio import AIProjectClient
from azure.ai.agents import AgentsClient

from dotenv import load_dotenv
load_dotenv(override=True)

from rich.console import Console
console = Console()


AZURE_FOUNDRY_PROJECT_DEPLOYMENT_NAME = os.getenv("AZURE_FOUNDRY_PROJECT_DEPLOYMENT_NAME", "o3-mini")
AZURE_FOUNDRY_PROJECT_ENDPOINT = os.getenv("AZURE_FOUNDRY_PROJECT_ENDPOINT", "")
AZURE_FOUNDRY_PROJECT_API_VERSION = os.getenv("AZURE_FOUNDRY_PROJECT_API_VERSION", "2024-12-01-preview")    


# %% [code]

# Initialize the AgentsClient with the Azure Foundry project endpoint and credentials
agents_client = AgentsClient(
    endpoint=AZURE_FOUNDRY_PROJECT_ENDPOINT,
    credential=DefaultAzureCredential(),
    api_version="2025-05-15-preview"
)

project_client = AIProjectClient(
    endpoint=AZURE_FOUNDRY_PROJECT_ENDPOINT,
    credential=DefaultAzureCredential(),
    api_version="2025-05-15-preview"
)

# %% [code]
for agent in agents_client.list_agents():
    console.print(f"Agent ID: {agent.id}")
    console.print(f"Agent Name: {agent.name}")
    console.print(f"Agent Instruction: {agent.instructions}")
    console.print(f"Agent Description: {agent.description}")
    console.print("-" * 40)

# %% [code]
import json
import datetime
from typing import Any, Callable, Set, Dict, List, Optional

from semantic_kernel.functions import kernel_function
from azure.ai.agents.telemetry import trace_function



class WeatherPlugin:
    """
    Description: Generate character names.
    """

    @trace_function()
    @kernel_function(description="Fetches weather", name="fetch_weather")
    def fetch_weather(self, location: str) -> str:
        """
        Fetches the weather information for the specified location.

        :param location: The location to fetch weather for.
        :return: Weather information as a JSON string.
        """
        # Mock weather data for demonstration purposes
        mock_weather_data = {"New York": "Sunny, 25°C", "London": "Cloudy, 18°C", "Tokyo": "Rainy, 22°C"}
        weather = mock_weather_data.get(location, "Weather data not available for this location.")
        return json.dumps({"weather": weather})

# Define user functions
user_functions = {WeatherPlugin.fetch_weather}

# %% [code]
from azure.ai.agents.models import FunctionTool

functions = FunctionTool(functions=user_functions)
agent.tools + functions.definitions

# %% [code]
# agents_client.update_agent(
#     agent_id=agent.id,
#     tools=agent.tools + functions.definitions
# )

# %% [code]
agent_definition = agents_client.get_agent(
    agent_id=agent.id,
)

agent_definition

# %% [code]
from semantic_kernel.agents.azure_ai.azure_ai_agent import AzureAIAgent

from opentelemetry import trace
from azure.monitor.opentelemetry import configure_azure_monitor

from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter
from azure.ai.agents.telemetry import AIAgentsInstrumentor

# Enable Azure Monitor tracing

AZURE_FOUNDRY_PROJECT_APPLICATIONINSIGHTS_CONNECTION_STRING="InstrumentationKey=9282de1a-3aa2-4d74-8b73-207eaeac2a38;IngestionEndpoint=https://eastus2-3.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus2.livediagnostics.monitor.azure.com/;ApplicationId=197fa35b-acaf-44b2-a8e0-14489d055e73"
application_insights_connection_string = os.environ["AZURE_FOUNDRY_PROJECT_APPLICATIONINSIGHTS_CONNECTION_STRING"]
configure_azure_monitor(connection_string=application_insights_connection_string)

scenario = os.path.basename("augmented-agent")

span_exporter = ConsoleSpanExporter()
tracer_provider = TracerProvider()
tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter))
trace.set_tracer_provider(tracer_provider)
tracer = trace.get_tracer(__name__)

AIAgentsInstrumentor().instrument()



with tracer.start_as_current_span(scenario):
    sk_agent = AzureAIAgent(
        client=project_client,
        definition=agent_definition,
        plugins=[WeatherPlugin()],
    )

    response = await sk_agent.get_response(messages="what is the weather in tokyo now?", thread=None)
    console.print(f"Response: {response.content}")

# %% [code]
%%python 
print("hi")

# %% [code]
# pylint: disable=line-too-long,useless-suppression
# ------------------------------------
# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.
# ------------------------------------

"""
DESCRIPTION:
    This sample demonstrates how to use agent operations with the Bing grounding tool from
    the Azure Agents service using a synchronous client.

USAGE:
    python sample_agents_bing_grounding.py

    Before running the sample:

    pip install azure-ai-agents azure-identity

    Set these environment variables with your own values:
    1) PROJECT_ENDPOINT - The Azure AI Project endpoint, as found in the Overview
                          page of your Azure AI Foundry portal.
    2) MODEL_DEPLOYMENT_NAME - The deployment name of the AI model, as found under the "Name" column in
       the "Models + endpoints" tab in your Azure AI Foundry project.
    3) AZURE_BING_CONNECTION_ID - The ID of the Bing connection, in the format of:
       /subscriptions/{subscription-id}/resourceGroups/{resource-group-name}/providers/Microsoft.MachineLearningServices/workspaces/{workspace-name}/connections/{connection-name}
"""

import os
from azure.ai.agents import AgentsClient
from azure.ai.agents.models import MessageRole, BingGroundingTool
from azure.identity import DefaultAzureCredential


project_client = AIProjectClient(
    endpoint=AZURE_FOUNDRY_PROJECT_ENDPOINT,
    credential=DefaultAzureCredential(),
    api_version="2025-05-15-preview"
)

async for c in project_client.connections.list():
    if c.type == "GroundingWithBingSearch":
        print(c.id)
        conn_id = c.id


agents_client = AgentsClient(
    endpoint=os.environ["PROJECT_ENDPOINT"],
    credential=DefaultAzureCredential(),
)

# [START create_agent_with_bing_grounding_tool]
# conn_id = os.environ["AZURE_BING_CONNECTION_ID"]


# Initialize agent bing tool and add the connection id
bing = BingGroundingTool(connection_id=conn_id)

# Create agent with the bing tool and process agent run
with agents_client:
    agent = agents_client.create_agent(
        model=os.environ["MODEL_DEPLOYMENT_NAME"],
        name="my-agent",
        instructions="You are a helpful agent",
        tools=bing.definitions,
    )
    # [END create_agent_with_bing_grounding_tool]

    print(f"Created agent, ID: {agent.id}")

    # Create thread for communication
    thread = agents_client.threads.create()
    print(f"Created thread, ID: {thread.id}")

    # Create message to thread
    message = agents_client.messages.create(
        thread_id=thread.id,
        role=MessageRole.USER,
        content="How does wikipedia explain Euler's Identity?",
    )
    print(f"Created message, ID: {message.id}")

    # Create and process agent run in thread with tools
    run = agents_client.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)
    print(f"Run finished with status: {run.status}")

    if run.status == "failed":
        print(f"Run failed: {run.last_error}")

    # Fetch run steps to get the details of the agent run
    run_steps = agents_client.run_steps.list(thread_id=thread.id, run_id=run.id)
    for step in run_steps:
        print(f"Step {step['id']} status: {step['status']}")
        step_details = step.get("step_details", {})
        tool_calls = step_details.get("tool_calls", [])

        if tool_calls:
            print("  Tool calls:")
            for call in tool_calls:
                print(f"    Tool Call ID: {call.get('id')}")
                print(f"    Type: {call.get('type')}")

                bing_grounding_details = call.get("bing_grounding", {})
                if bing_grounding_details:
                    print(f"    Bing Grounding ID: {bing_grounding_details.get('requesturl')}")

        print()  # add an extra newline between steps

    # Delete the agent when done
    agents_client.delete_agent(agent.id)
    print("Deleted agent")

    # Print the Agent's response message with optional citation
    response_message = agents_client.messages.get_last_message_by_role(thread_id=thread.id, role=MessageRole.AGENT)
    if response_message:
        for text_message in response_message.text_messages:
            print(f"Agent response: {text_message.text.value}")
        for annotation in response_message.url_citation_annotations:
            print(f"URL Citation: [{annotation.url_citation.title}]({annotation.url_citation.url})")

# %% [code]
project_client = AIProjectClient(
    endpoint=AZURE_FOUNDRY_PROJECT_ENDPOINT,
    credential=DefaultAzureCredential(),
    api_version="2025-05-15-preview"
)

async for c in project_client.connections.list():
    if c.type == "GroundingWithBingSearch":
        print(c.id)

# %% [code]

